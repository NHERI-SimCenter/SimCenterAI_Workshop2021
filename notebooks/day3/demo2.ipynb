{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Networks Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hand-written digit classification with convolutional neural networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this demo, we will show how to build a convolutional neural networks for hand-written digit classification. We will use MNIST as the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set random seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fdc767f9d68>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_seed = 9999\n",
    "torch.backends.cudnn.enabled = False\n",
    "torch.manual_seed(random_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the dataset using Pytorch API. First we load the training set. The training set contains 60000 images and the test set contains 10000 images. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000\n"
     ]
    }
   ],
   "source": [
    "batch_size_train = 64\n",
    "batch_size_test = 1000\n",
    "\n",
    "\n",
    "trainset = torchvision.datasets.MNIST('./', train=True, download=True,\n",
    "                             transform=torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor(),\n",
    "                               torchvision.transforms.Normalize(\n",
    "                                 (0.1307,), (0.3081,))\n",
    "                             ]))\n",
    "\n",
    "print (len(trainset))\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size_train, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n"
     ]
    }
   ],
   "source": [
    "testset = torchvision.datasets.MNIST('./', train=False, download=True,\n",
    "                             transform=torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor(),\n",
    "                               torchvision.transforms.Normalize(\n",
    "                                 (0.1307,), (0.3081,))\n",
    "                             ]))\n",
    "\n",
    "print (len(testset))\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(testset, batch_size=batch_size_test, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's show some example images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = enumerate(test_loader)\n",
    "batch_idx, (example_data, example_targets) = next(examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig = plt.figure()\n",
    "\n",
    "for i in range(5):\n",
    "  plt.subplot(1,5,i+1)\n",
    "  plt.tight_layout()\n",
    "  plt.imshow(example_data[i][0], cmap='gray', interpolation='none')\n",
    "  plt.xticks([])\n",
    "  plt.yticks([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's build a convolutional neural network (CNN) with Pytorch. In this demo, we build a LeNet-like convolutional neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.pool1 = nn.MaxPool2d(2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.pool2 = nn.MaxPool2d(2)\n",
    "        self.fc1 = nn.Linear(256, 120)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.relu4 = nn.ReLU()\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "        self.relu5 = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        y = self.conv1(x)\n",
    "        y = self.relu1(y)\n",
    "        y = self.pool1(y)\n",
    "        y = self.conv2(y)\n",
    "        y = self.relu2(y)\n",
    "        y = self.pool2(y)\n",
    "        y = y.view(y.shape[0], -1)\n",
    "        y = self.fc1(y)\n",
    "        y = self.relu3(y)\n",
    "        y = self.fc2(y)\n",
    "        y = self.relu4(y)\n",
    "        y = self.fc3(y)\n",
    "        y = self.relu5(y)\n",
    "        return F.log_softmax(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN(\n",
      "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (relu1): ReLU()\n",
      "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (relu2): ReLU()\n",
      "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (fc1): Linear(in_features=256, out_features=120, bias=True)\n",
      "  (relu3): ReLU()\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (relu4): ReLU()\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "  (relu5): ReLU()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "network = CNN()\n",
    "\n",
    "#\n",
    "print (network)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For training the network, we need to specify the optimizer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 10\n",
    "learning_rate = 0.01\n",
    "momentum = 0.9\n",
    "log_interval = 10\n",
    "\n",
    "optimizer = optim.SGD(network.parameters(), lr=learning_rate,\n",
    "                      momentum=momentum)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses = []\n",
    "test_losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "  network.train()\n",
    "   \n",
    "  train_loss = 0\n",
    "\n",
    "  for batch_idx, (data, target) in enumerate(train_loader):\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    output = network(data)\n",
    "    loss = F.nll_loss(output, target)\n",
    "    \n",
    "    train_loss += loss.item()\n",
    "    \n",
    "    loss.backward()\n",
    "    \n",
    "    optimizer.step()\n",
    "    \n",
    "    if batch_idx % log_interval == 0:\n",
    "      print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "        epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "        100. * batch_idx / len(train_loader), loss.item()))\n",
    "    \n",
    "  \n",
    "  train_loss /= len(train_loader.dataset)\n",
    "  train_losses.append(train_loss)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "  network.eval()\n",
    "\n",
    "  test_loss = 0\n",
    "  correct = 0\n",
    "  with torch.no_grad():\n",
    "    for data, target in test_loader:\n",
    "      output = network(data)\n",
    "      test_loss += F.nll_loss(output, target, size_average=False).item()\n",
    "      pred = output.data.max(1, keepdim=True)[1]\n",
    "      correct += pred.eq(target.data.view_as(pred)).sum()\n",
    "  \n",
    "  test_loss /= len(test_loader.dataset)\n",
    "  test_losses.append(test_loss)\n",
    "\n",
    "  print('\\nTest set: Avg. loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "    test_loss, correct, len(test_loader.dataset),\n",
    "    100. * correct / len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yunhui.guo/.local/lib/python3.6/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  ../c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n",
      "/usr/local/anaconda3/envs/env_pytorch/lib/python3.6/site-packages/ipykernel_launcher.py:31: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.305847\n",
      "Train Epoch: 1 [640/60000 (1%)]\tLoss: 2.305976\n",
      "Train Epoch: 1 [1280/60000 (2%)]\tLoss: 2.293512\n",
      "Train Epoch: 1 [1920/60000 (3%)]\tLoss: 2.266896\n",
      "Train Epoch: 1 [2560/60000 (4%)]\tLoss: 2.275547\n",
      "Train Epoch: 1 [3200/60000 (5%)]\tLoss: 2.251894\n",
      "Train Epoch: 1 [3840/60000 (6%)]\tLoss: 2.200465\n",
      "Train Epoch: 1 [4480/60000 (7%)]\tLoss: 2.180280\n",
      "Train Epoch: 1 [5120/60000 (9%)]\tLoss: 1.875957\n",
      "Train Epoch: 1 [5760/60000 (10%)]\tLoss: 1.831398\n",
      "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 1.352021\n",
      "Train Epoch: 1 [7040/60000 (12%)]\tLoss: 1.420869\n",
      "Train Epoch: 1 [7680/60000 (13%)]\tLoss: 1.222429\n",
      "Train Epoch: 1 [8320/60000 (14%)]\tLoss: 1.052010\n",
      "Train Epoch: 1 [8960/60000 (15%)]\tLoss: 0.941905\n",
      "Train Epoch: 1 [9600/60000 (16%)]\tLoss: 0.802751\n",
      "Train Epoch: 1 [10240/60000 (17%)]\tLoss: 0.972403\n",
      "Train Epoch: 1 [10880/60000 (18%)]\tLoss: 0.996732\n",
      "Train Epoch: 1 [11520/60000 (19%)]\tLoss: 0.838029\n",
      "Train Epoch: 1 [12160/60000 (20%)]\tLoss: 0.800605\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.602748\n",
      "Train Epoch: 1 [13440/60000 (22%)]\tLoss: 0.707407\n",
      "Train Epoch: 1 [14080/60000 (23%)]\tLoss: 0.791246\n",
      "Train Epoch: 1 [14720/60000 (25%)]\tLoss: 1.061379\n",
      "Train Epoch: 1 [15360/60000 (26%)]\tLoss: 0.809748\n",
      "Train Epoch: 1 [16000/60000 (27%)]\tLoss: 0.737046\n",
      "Train Epoch: 1 [16640/60000 (28%)]\tLoss: 0.663496\n",
      "Train Epoch: 1 [17280/60000 (29%)]\tLoss: 0.721841\n",
      "Train Epoch: 1 [17920/60000 (30%)]\tLoss: 0.754786\n",
      "Train Epoch: 1 [18560/60000 (31%)]\tLoss: 0.637909\n",
      "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 0.506635\n",
      "Train Epoch: 1 [19840/60000 (33%)]\tLoss: 0.591980\n",
      "Train Epoch: 1 [20480/60000 (34%)]\tLoss: 0.603538\n",
      "Train Epoch: 1 [21120/60000 (35%)]\tLoss: 0.496202\n",
      "Train Epoch: 1 [21760/60000 (36%)]\tLoss: 0.615251\n",
      "Train Epoch: 1 [22400/60000 (37%)]\tLoss: 0.757576\n",
      "Train Epoch: 1 [23040/60000 (38%)]\tLoss: 0.384277\n",
      "Train Epoch: 1 [23680/60000 (39%)]\tLoss: 0.285920\n",
      "Train Epoch: 1 [24320/60000 (41%)]\tLoss: 0.354708\n",
      "Train Epoch: 1 [24960/60000 (42%)]\tLoss: 0.526138\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.341965\n",
      "Train Epoch: 1 [26240/60000 (44%)]\tLoss: 0.505532\n",
      "Train Epoch: 1 [26880/60000 (45%)]\tLoss: 0.353500\n",
      "Train Epoch: 1 [27520/60000 (46%)]\tLoss: 0.323155\n",
      "Train Epoch: 1 [28160/60000 (47%)]\tLoss: 0.329799\n",
      "Train Epoch: 1 [28800/60000 (48%)]\tLoss: 0.180898\n",
      "Train Epoch: 1 [29440/60000 (49%)]\tLoss: 0.267759\n",
      "Train Epoch: 1 [30080/60000 (50%)]\tLoss: 0.201630\n",
      "Train Epoch: 1 [30720/60000 (51%)]\tLoss: 0.523837\n",
      "Train Epoch: 1 [31360/60000 (52%)]\tLoss: 0.578720\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.321467\n",
      "Train Epoch: 1 [32640/60000 (54%)]\tLoss: 0.443617\n",
      "Train Epoch: 1 [33280/60000 (55%)]\tLoss: 0.472845\n",
      "Train Epoch: 1 [33920/60000 (57%)]\tLoss: 0.359121\n",
      "Train Epoch: 1 [34560/60000 (58%)]\tLoss: 0.458518\n",
      "Train Epoch: 1 [35200/60000 (59%)]\tLoss: 0.158345\n",
      "Train Epoch: 1 [35840/60000 (60%)]\tLoss: 0.410490\n",
      "Train Epoch: 1 [36480/60000 (61%)]\tLoss: 0.505351\n",
      "Train Epoch: 1 [37120/60000 (62%)]\tLoss: 0.246346\n",
      "Train Epoch: 1 [37760/60000 (63%)]\tLoss: 0.105818\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.204366\n",
      "Train Epoch: 1 [39040/60000 (65%)]\tLoss: 0.184344\n",
      "Train Epoch: 1 [39680/60000 (66%)]\tLoss: 0.110264\n",
      "Train Epoch: 1 [40320/60000 (67%)]\tLoss: 0.067931\n",
      "Train Epoch: 1 [40960/60000 (68%)]\tLoss: 0.169383\n",
      "Train Epoch: 1 [41600/60000 (69%)]\tLoss: 0.167384\n",
      "Train Epoch: 1 [42240/60000 (70%)]\tLoss: 0.166654\n",
      "Train Epoch: 1 [42880/60000 (71%)]\tLoss: 0.153159\n",
      "Train Epoch: 1 [43520/60000 (72%)]\tLoss: 0.220395\n",
      "Train Epoch: 1 [44160/60000 (74%)]\tLoss: 0.065188\n",
      "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.081202\n",
      "Train Epoch: 1 [45440/60000 (76%)]\tLoss: 0.029187\n",
      "Train Epoch: 1 [46080/60000 (77%)]\tLoss: 0.026044\n",
      "Train Epoch: 1 [46720/60000 (78%)]\tLoss: 0.104446\n",
      "Train Epoch: 1 [47360/60000 (79%)]\tLoss: 0.034770\n",
      "Train Epoch: 1 [48000/60000 (80%)]\tLoss: 0.140153\n",
      "Train Epoch: 1 [48640/60000 (81%)]\tLoss: 0.129855\n",
      "Train Epoch: 1 [49280/60000 (82%)]\tLoss: 0.120110\n",
      "Train Epoch: 1 [49920/60000 (83%)]\tLoss: 0.069998\n",
      "Train Epoch: 1 [50560/60000 (84%)]\tLoss: 0.062381\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.215017\n",
      "Train Epoch: 1 [51840/60000 (86%)]\tLoss: 0.183481\n",
      "Train Epoch: 1 [52480/60000 (87%)]\tLoss: 0.195998\n",
      "Train Epoch: 1 [53120/60000 (88%)]\tLoss: 0.130164\n",
      "Train Epoch: 1 [53760/60000 (90%)]\tLoss: 0.054592\n",
      "Train Epoch: 1 [54400/60000 (91%)]\tLoss: 0.084204\n",
      "Train Epoch: 1 [55040/60000 (92%)]\tLoss: 0.058708\n",
      "Train Epoch: 1 [55680/60000 (93%)]\tLoss: 0.133273\n",
      "Train Epoch: 1 [56320/60000 (94%)]\tLoss: 0.027083\n",
      "Train Epoch: 1 [56960/60000 (95%)]\tLoss: 0.013445\n",
      "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.015102\n",
      "Train Epoch: 1 [58240/60000 (97%)]\tLoss: 0.011030\n",
      "Train Epoch: 1 [58880/60000 (98%)]\tLoss: 0.023200\n",
      "Train Epoch: 1 [59520/60000 (99%)]\tLoss: 0.031187\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yunhui.guo/.local/lib/python3.6/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.0591, Accuracy: 9815/10000 (98%)\n",
      "\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.055578\n",
      "Train Epoch: 2 [640/60000 (1%)]\tLoss: 0.084668\n",
      "Train Epoch: 2 [1280/60000 (2%)]\tLoss: 0.201046\n",
      "Train Epoch: 2 [1920/60000 (3%)]\tLoss: 0.181355\n",
      "Train Epoch: 2 [2560/60000 (4%)]\tLoss: 0.014325\n",
      "Train Epoch: 2 [3200/60000 (5%)]\tLoss: 0.039115\n",
      "Train Epoch: 2 [3840/60000 (6%)]\tLoss: 0.095788\n",
      "Train Epoch: 2 [4480/60000 (7%)]\tLoss: 0.043468\n",
      "Train Epoch: 2 [5120/60000 (9%)]\tLoss: 0.040865\n",
      "Train Epoch: 2 [5760/60000 (10%)]\tLoss: 0.035970\n",
      "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 0.074925\n",
      "Train Epoch: 2 [7040/60000 (12%)]\tLoss: 0.064337\n",
      "Train Epoch: 2 [7680/60000 (13%)]\tLoss: 0.048477\n",
      "Train Epoch: 2 [8320/60000 (14%)]\tLoss: 0.232246\n",
      "Train Epoch: 2 [8960/60000 (15%)]\tLoss: 0.097910\n",
      "Train Epoch: 2 [9600/60000 (16%)]\tLoss: 0.138614\n",
      "Train Epoch: 2 [10240/60000 (17%)]\tLoss: 0.050940\n",
      "Train Epoch: 2 [10880/60000 (18%)]\tLoss: 0.122982\n",
      "Train Epoch: 2 [11520/60000 (19%)]\tLoss: 0.020022\n",
      "Train Epoch: 2 [12160/60000 (20%)]\tLoss: 0.073245\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.093353\n",
      "Train Epoch: 2 [13440/60000 (22%)]\tLoss: 0.234013\n",
      "Train Epoch: 2 [14080/60000 (23%)]\tLoss: 0.004020\n",
      "Train Epoch: 2 [14720/60000 (25%)]\tLoss: 0.183513\n",
      "Train Epoch: 2 [15360/60000 (26%)]\tLoss: 0.084401\n",
      "Train Epoch: 2 [16000/60000 (27%)]\tLoss: 0.124132\n",
      "Train Epoch: 2 [16640/60000 (28%)]\tLoss: 0.115820\n",
      "Train Epoch: 2 [17280/60000 (29%)]\tLoss: 0.041290\n",
      "Train Epoch: 2 [17920/60000 (30%)]\tLoss: 0.048670\n",
      "Train Epoch: 2 [18560/60000 (31%)]\tLoss: 0.033446\n",
      "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 0.048834\n",
      "Train Epoch: 2 [19840/60000 (33%)]\tLoss: 0.065570\n",
      "Train Epoch: 2 [20480/60000 (34%)]\tLoss: 0.064312\n",
      "Train Epoch: 2 [21120/60000 (35%)]\tLoss: 0.016776\n",
      "Train Epoch: 2 [21760/60000 (36%)]\tLoss: 0.018280\n",
      "Train Epoch: 2 [22400/60000 (37%)]\tLoss: 0.018970\n",
      "Train Epoch: 2 [23040/60000 (38%)]\tLoss: 0.173797\n",
      "Train Epoch: 2 [23680/60000 (39%)]\tLoss: 0.067418\n",
      "Train Epoch: 2 [24320/60000 (41%)]\tLoss: 0.200087\n",
      "Train Epoch: 2 [24960/60000 (42%)]\tLoss: 0.115526\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.326540\n",
      "Train Epoch: 2 [26240/60000 (44%)]\tLoss: 0.133088\n",
      "Train Epoch: 2 [26880/60000 (45%)]\tLoss: 0.161796\n",
      "Train Epoch: 2 [27520/60000 (46%)]\tLoss: 0.153842\n",
      "Train Epoch: 2 [28160/60000 (47%)]\tLoss: 0.060370\n",
      "Train Epoch: 2 [28800/60000 (48%)]\tLoss: 0.050974\n",
      "Train Epoch: 2 [29440/60000 (49%)]\tLoss: 0.051011\n",
      "Train Epoch: 2 [30080/60000 (50%)]\tLoss: 0.040270\n",
      "Train Epoch: 2 [30720/60000 (51%)]\tLoss: 0.152783\n",
      "Train Epoch: 2 [31360/60000 (52%)]\tLoss: 0.002454\n",
      "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.027137\n",
      "Train Epoch: 2 [32640/60000 (54%)]\tLoss: 0.057668\n",
      "Train Epoch: 2 [33280/60000 (55%)]\tLoss: 0.058963\n",
      "Train Epoch: 2 [33920/60000 (57%)]\tLoss: 0.040256\n",
      "Train Epoch: 2 [34560/60000 (58%)]\tLoss: 0.037840\n",
      "Train Epoch: 2 [35200/60000 (59%)]\tLoss: 0.032658\n",
      "Train Epoch: 2 [35840/60000 (60%)]\tLoss: 0.061618\n",
      "Train Epoch: 2 [36480/60000 (61%)]\tLoss: 0.087815\n",
      "Train Epoch: 2 [37120/60000 (62%)]\tLoss: 0.035617\n",
      "Train Epoch: 2 [37760/60000 (63%)]\tLoss: 0.050208\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.120323\n",
      "Train Epoch: 2 [39040/60000 (65%)]\tLoss: 0.018136\n",
      "Train Epoch: 2 [39680/60000 (66%)]\tLoss: 0.120744\n",
      "Train Epoch: 2 [40320/60000 (67%)]\tLoss: 0.146342\n",
      "Train Epoch: 2 [40960/60000 (68%)]\tLoss: 0.042841\n",
      "Train Epoch: 2 [41600/60000 (69%)]\tLoss: 0.138281\n",
      "Train Epoch: 2 [42240/60000 (70%)]\tLoss: 0.031012\n",
      "Train Epoch: 2 [42880/60000 (71%)]\tLoss: 0.073356\n",
      "Train Epoch: 2 [43520/60000 (72%)]\tLoss: 0.029125\n",
      "Train Epoch: 2 [44160/60000 (74%)]\tLoss: 0.021668\n",
      "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 0.003860\n",
      "Train Epoch: 2 [45440/60000 (76%)]\tLoss: 0.012252\n",
      "Train Epoch: 2 [46080/60000 (77%)]\tLoss: 0.010851\n",
      "Train Epoch: 2 [46720/60000 (78%)]\tLoss: 0.014314\n",
      "Train Epoch: 2 [47360/60000 (79%)]\tLoss: 0.054928\n",
      "Train Epoch: 2 [48000/60000 (80%)]\tLoss: 0.076833\n",
      "Train Epoch: 2 [48640/60000 (81%)]\tLoss: 0.116826\n",
      "Train Epoch: 2 [49280/60000 (82%)]\tLoss: 0.083574\n",
      "Train Epoch: 2 [49920/60000 (83%)]\tLoss: 0.008134\n",
      "Train Epoch: 2 [50560/60000 (84%)]\tLoss: 0.026986\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.020771\n",
      "Train Epoch: 2 [51840/60000 (86%)]\tLoss: 0.050326\n",
      "Train Epoch: 2 [52480/60000 (87%)]\tLoss: 0.015180\n",
      "Train Epoch: 2 [53120/60000 (88%)]\tLoss: 0.100555\n",
      "Train Epoch: 2 [53760/60000 (90%)]\tLoss: 0.048691\n",
      "Train Epoch: 2 [54400/60000 (91%)]\tLoss: 0.047406\n",
      "Train Epoch: 2 [55040/60000 (92%)]\tLoss: 0.026244\n",
      "Train Epoch: 2 [55680/60000 (93%)]\tLoss: 0.084801\n",
      "Train Epoch: 2 [56320/60000 (94%)]\tLoss: 0.005427\n",
      "Train Epoch: 2 [56960/60000 (95%)]\tLoss: 0.004737\n",
      "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 0.028989\n",
      "Train Epoch: 2 [58240/60000 (97%)]\tLoss: 0.015462\n",
      "Train Epoch: 2 [58880/60000 (98%)]\tLoss: 0.032761\n",
      "Train Epoch: 2 [59520/60000 (99%)]\tLoss: 0.021064\n",
      "\n",
      "Test set: Avg. loss: 0.0408, Accuracy: 9873/10000 (99%)\n",
      "\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.025737\n",
      "Train Epoch: 3 [640/60000 (1%)]\tLoss: 0.028415\n",
      "Train Epoch: 3 [1280/60000 (2%)]\tLoss: 0.036831\n",
      "Train Epoch: 3 [1920/60000 (3%)]\tLoss: 0.098870\n",
      "Train Epoch: 3 [2560/60000 (4%)]\tLoss: 0.014534\n",
      "Train Epoch: 3 [3200/60000 (5%)]\tLoss: 0.025236\n",
      "Train Epoch: 3 [3840/60000 (6%)]\tLoss: 0.015930\n",
      "Train Epoch: 3 [4480/60000 (7%)]\tLoss: 0.030776\n",
      "Train Epoch: 3 [5120/60000 (9%)]\tLoss: 0.040416\n",
      "Train Epoch: 3 [5760/60000 (10%)]\tLoss: 0.067644\n",
      "Train Epoch: 3 [6400/60000 (11%)]\tLoss: 0.031248\n",
      "Train Epoch: 3 [7040/60000 (12%)]\tLoss: 0.008309\n",
      "Train Epoch: 3 [7680/60000 (13%)]\tLoss: 0.003962\n",
      "Train Epoch: 3 [8320/60000 (14%)]\tLoss: 0.028930\n",
      "Train Epoch: 3 [8960/60000 (15%)]\tLoss: 0.012541\n",
      "Train Epoch: 3 [9600/60000 (16%)]\tLoss: 0.025226\n",
      "Train Epoch: 3 [10240/60000 (17%)]\tLoss: 0.017958\n",
      "Train Epoch: 3 [10880/60000 (18%)]\tLoss: 0.036661\n",
      "Train Epoch: 3 [11520/60000 (19%)]\tLoss: 0.028250\n",
      "Train Epoch: 3 [12160/60000 (20%)]\tLoss: 0.009434\n",
      "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.007176\n",
      "Train Epoch: 3 [13440/60000 (22%)]\tLoss: 0.009176\n",
      "Train Epoch: 3 [14080/60000 (23%)]\tLoss: 0.054167\n",
      "Train Epoch: 3 [14720/60000 (25%)]\tLoss: 0.028386\n",
      "Train Epoch: 3 [15360/60000 (26%)]\tLoss: 0.039425\n",
      "Train Epoch: 3 [16000/60000 (27%)]\tLoss: 0.100947\n",
      "Train Epoch: 3 [16640/60000 (28%)]\tLoss: 0.004795\n",
      "Train Epoch: 3 [17280/60000 (29%)]\tLoss: 0.039136\n",
      "Train Epoch: 3 [17920/60000 (30%)]\tLoss: 0.064926\n",
      "Train Epoch: 3 [18560/60000 (31%)]\tLoss: 0.035391\n",
      "Train Epoch: 3 [19200/60000 (32%)]\tLoss: 0.104380\n",
      "Train Epoch: 3 [19840/60000 (33%)]\tLoss: 0.006707\n",
      "Train Epoch: 3 [20480/60000 (34%)]\tLoss: 0.016654\n",
      "Train Epoch: 3 [21120/60000 (35%)]\tLoss: 0.008958\n",
      "Train Epoch: 3 [21760/60000 (36%)]\tLoss: 0.025315\n",
      "Train Epoch: 3 [22400/60000 (37%)]\tLoss: 0.037040\n",
      "Train Epoch: 3 [23040/60000 (38%)]\tLoss: 0.007061\n",
      "Train Epoch: 3 [23680/60000 (39%)]\tLoss: 0.041940\n",
      "Train Epoch: 3 [24320/60000 (41%)]\tLoss: 0.063989\n",
      "Train Epoch: 3 [24960/60000 (42%)]\tLoss: 0.002572\n",
      "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.039725\n",
      "Train Epoch: 3 [26240/60000 (44%)]\tLoss: 0.017931\n",
      "Train Epoch: 3 [26880/60000 (45%)]\tLoss: 0.161093\n",
      "Train Epoch: 3 [27520/60000 (46%)]\tLoss: 0.051237\n",
      "Train Epoch: 3 [28160/60000 (47%)]\tLoss: 0.096026\n",
      "Train Epoch: 3 [28800/60000 (48%)]\tLoss: 0.082043\n",
      "Train Epoch: 3 [29440/60000 (49%)]\tLoss: 0.063835\n",
      "Train Epoch: 3 [30080/60000 (50%)]\tLoss: 0.011425\n",
      "Train Epoch: 3 [30720/60000 (51%)]\tLoss: 0.099358\n",
      "Train Epoch: 3 [31360/60000 (52%)]\tLoss: 0.011755\n",
      "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.099781\n",
      "Train Epoch: 3 [32640/60000 (54%)]\tLoss: 0.060459\n",
      "Train Epoch: 3 [33280/60000 (55%)]\tLoss: 0.007716\n",
      "Train Epoch: 3 [33920/60000 (57%)]\tLoss: 0.054961\n",
      "Train Epoch: 3 [34560/60000 (58%)]\tLoss: 0.019675\n",
      "Train Epoch: 3 [35200/60000 (59%)]\tLoss: 0.068149\n",
      "Train Epoch: 3 [35840/60000 (60%)]\tLoss: 0.032896\n",
      "Train Epoch: 3 [36480/60000 (61%)]\tLoss: 0.019374\n",
      "Train Epoch: 3 [37120/60000 (62%)]\tLoss: 0.096567\n",
      "Train Epoch: 3 [37760/60000 (63%)]\tLoss: 0.014144\n",
      "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.002515\n",
      "Train Epoch: 3 [39040/60000 (65%)]\tLoss: 0.013506\n",
      "Train Epoch: 3 [39680/60000 (66%)]\tLoss: 0.004499\n",
      "Train Epoch: 3 [40320/60000 (67%)]\tLoss: 0.008199\n",
      "Train Epoch: 3 [40960/60000 (68%)]\tLoss: 0.012247\n",
      "Train Epoch: 3 [41600/60000 (69%)]\tLoss: 0.040713\n",
      "Train Epoch: 3 [42240/60000 (70%)]\tLoss: 0.064235\n",
      "Train Epoch: 3 [42880/60000 (71%)]\tLoss: 0.082893\n",
      "Train Epoch: 3 [43520/60000 (72%)]\tLoss: 0.104628\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 3 [44160/60000 (74%)]\tLoss: 0.081261\n",
      "Train Epoch: 3 [44800/60000 (75%)]\tLoss: 0.043705\n",
      "Train Epoch: 3 [45440/60000 (76%)]\tLoss: 0.019956\n",
      "Train Epoch: 3 [46080/60000 (77%)]\tLoss: 0.013281\n",
      "Train Epoch: 3 [46720/60000 (78%)]\tLoss: 0.009919\n",
      "Train Epoch: 3 [47360/60000 (79%)]\tLoss: 0.004667\n",
      "Train Epoch: 3 [48000/60000 (80%)]\tLoss: 0.047890\n",
      "Train Epoch: 3 [48640/60000 (81%)]\tLoss: 0.003100\n",
      "Train Epoch: 3 [49280/60000 (82%)]\tLoss: 0.106849\n",
      "Train Epoch: 3 [49920/60000 (83%)]\tLoss: 0.065596\n",
      "Train Epoch: 3 [50560/60000 (84%)]\tLoss: 0.022606\n",
      "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.020438\n",
      "Train Epoch: 3 [51840/60000 (86%)]\tLoss: 0.029711\n",
      "Train Epoch: 3 [52480/60000 (87%)]\tLoss: 0.038800\n",
      "Train Epoch: 3 [53120/60000 (88%)]\tLoss: 0.109081\n",
      "Train Epoch: 3 [53760/60000 (90%)]\tLoss: 0.124377\n",
      "Train Epoch: 3 [54400/60000 (91%)]\tLoss: 0.034435\n",
      "Train Epoch: 3 [55040/60000 (92%)]\tLoss: 0.003665\n",
      "Train Epoch: 3 [55680/60000 (93%)]\tLoss: 0.059225\n",
      "Train Epoch: 3 [56320/60000 (94%)]\tLoss: 0.030098\n",
      "Train Epoch: 3 [56960/60000 (95%)]\tLoss: 0.010820\n",
      "Train Epoch: 3 [57600/60000 (96%)]\tLoss: 0.004194\n",
      "Train Epoch: 3 [58240/60000 (97%)]\tLoss: 0.015162\n",
      "Train Epoch: 3 [58880/60000 (98%)]\tLoss: 0.073147\n",
      "Train Epoch: 3 [59520/60000 (99%)]\tLoss: 0.016504\n",
      "\n",
      "Test set: Avg. loss: 0.0369, Accuracy: 9869/10000 (99%)\n",
      "\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.034305\n",
      "Train Epoch: 4 [640/60000 (1%)]\tLoss: 0.006291\n",
      "Train Epoch: 4 [1280/60000 (2%)]\tLoss: 0.036595\n",
      "Train Epoch: 4 [1920/60000 (3%)]\tLoss: 0.008621\n",
      "Train Epoch: 4 [2560/60000 (4%)]\tLoss: 0.002907\n",
      "Train Epoch: 4 [3200/60000 (5%)]\tLoss: 0.037465\n",
      "Train Epoch: 4 [3840/60000 (6%)]\tLoss: 0.016810\n",
      "Train Epoch: 4 [4480/60000 (7%)]\tLoss: 0.005496\n",
      "Train Epoch: 4 [5120/60000 (9%)]\tLoss: 0.003851\n",
      "Train Epoch: 4 [5760/60000 (10%)]\tLoss: 0.138425\n",
      "Train Epoch: 4 [6400/60000 (11%)]\tLoss: 0.012493\n",
      "Train Epoch: 4 [7040/60000 (12%)]\tLoss: 0.014966\n",
      "Train Epoch: 4 [7680/60000 (13%)]\tLoss: 0.006229\n",
      "Train Epoch: 4 [8320/60000 (14%)]\tLoss: 0.006959\n",
      "Train Epoch: 4 [8960/60000 (15%)]\tLoss: 0.002918\n",
      "Train Epoch: 4 [9600/60000 (16%)]\tLoss: 0.015674\n",
      "Train Epoch: 4 [10240/60000 (17%)]\tLoss: 0.044909\n",
      "Train Epoch: 4 [10880/60000 (18%)]\tLoss: 0.065801\n",
      "Train Epoch: 4 [11520/60000 (19%)]\tLoss: 0.042880\n",
      "Train Epoch: 4 [12160/60000 (20%)]\tLoss: 0.023176\n",
      "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 0.035571\n",
      "Train Epoch: 4 [13440/60000 (22%)]\tLoss: 0.010392\n",
      "Train Epoch: 4 [14080/60000 (23%)]\tLoss: 0.035562\n",
      "Train Epoch: 4 [14720/60000 (25%)]\tLoss: 0.036963\n",
      "Train Epoch: 4 [15360/60000 (26%)]\tLoss: 0.053850\n",
      "Train Epoch: 4 [16000/60000 (27%)]\tLoss: 0.005322\n",
      "Train Epoch: 4 [16640/60000 (28%)]\tLoss: 0.011788\n",
      "Train Epoch: 4 [17280/60000 (29%)]\tLoss: 0.083732\n",
      "Train Epoch: 4 [17920/60000 (30%)]\tLoss: 0.030021\n",
      "Train Epoch: 4 [18560/60000 (31%)]\tLoss: 0.003348\n",
      "Train Epoch: 4 [19200/60000 (32%)]\tLoss: 0.036338\n",
      "Train Epoch: 4 [19840/60000 (33%)]\tLoss: 0.018949\n",
      "Train Epoch: 4 [20480/60000 (34%)]\tLoss: 0.001937\n",
      "Train Epoch: 4 [21120/60000 (35%)]\tLoss: 0.083780\n",
      "Train Epoch: 4 [21760/60000 (36%)]\tLoss: 0.110774\n",
      "Train Epoch: 4 [22400/60000 (37%)]\tLoss: 0.003548\n",
      "Train Epoch: 4 [23040/60000 (38%)]\tLoss: 0.051263\n",
      "Train Epoch: 4 [23680/60000 (39%)]\tLoss: 0.020873\n",
      "Train Epoch: 4 [24320/60000 (41%)]\tLoss: 0.095072\n",
      "Train Epoch: 4 [24960/60000 (42%)]\tLoss: 0.010824\n",
      "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 0.003244\n",
      "Train Epoch: 4 [26240/60000 (44%)]\tLoss: 0.003313\n",
      "Train Epoch: 4 [26880/60000 (45%)]\tLoss: 0.044801\n",
      "Train Epoch: 4 [27520/60000 (46%)]\tLoss: 0.005292\n",
      "Train Epoch: 4 [28160/60000 (47%)]\tLoss: 0.001113\n",
      "Train Epoch: 4 [28800/60000 (48%)]\tLoss: 0.000845\n",
      "Train Epoch: 4 [29440/60000 (49%)]\tLoss: 0.038016\n",
      "Train Epoch: 4 [30080/60000 (50%)]\tLoss: 0.035416\n",
      "Train Epoch: 4 [30720/60000 (51%)]\tLoss: 0.011907\n",
      "Train Epoch: 4 [31360/60000 (52%)]\tLoss: 0.203456\n",
      "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 0.131393\n",
      "Train Epoch: 4 [32640/60000 (54%)]\tLoss: 0.000831\n",
      "Train Epoch: 4 [33280/60000 (55%)]\tLoss: 0.003825\n",
      "Train Epoch: 4 [33920/60000 (57%)]\tLoss: 0.038488\n",
      "Train Epoch: 4 [34560/60000 (58%)]\tLoss: 0.008089\n",
      "Train Epoch: 4 [35200/60000 (59%)]\tLoss: 0.026983\n",
      "Train Epoch: 4 [35840/60000 (60%)]\tLoss: 0.033368\n",
      "Train Epoch: 4 [36480/60000 (61%)]\tLoss: 0.005231\n",
      "Train Epoch: 4 [37120/60000 (62%)]\tLoss: 0.069274\n",
      "Train Epoch: 4 [37760/60000 (63%)]\tLoss: 0.131312\n",
      "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 0.023861\n",
      "Train Epoch: 4 [39040/60000 (65%)]\tLoss: 0.041281\n",
      "Train Epoch: 4 [39680/60000 (66%)]\tLoss: 0.095630\n",
      "Train Epoch: 4 [40320/60000 (67%)]\tLoss: 0.029499\n",
      "Train Epoch: 4 [40960/60000 (68%)]\tLoss: 0.045451\n",
      "Train Epoch: 4 [41600/60000 (69%)]\tLoss: 0.017149\n",
      "Train Epoch: 4 [42240/60000 (70%)]\tLoss: 0.041498\n",
      "Train Epoch: 4 [42880/60000 (71%)]\tLoss: 0.001559\n",
      "Train Epoch: 4 [43520/60000 (72%)]\tLoss: 0.039763\n",
      "Train Epoch: 4 [44160/60000 (74%)]\tLoss: 0.053923\n",
      "Train Epoch: 4 [44800/60000 (75%)]\tLoss: 0.011934\n",
      "Train Epoch: 4 [45440/60000 (76%)]\tLoss: 0.030196\n",
      "Train Epoch: 4 [46080/60000 (77%)]\tLoss: 0.028902\n",
      "Train Epoch: 4 [46720/60000 (78%)]\tLoss: 0.010187\n",
      "Train Epoch: 4 [47360/60000 (79%)]\tLoss: 0.006976\n",
      "Train Epoch: 4 [48000/60000 (80%)]\tLoss: 0.037679\n",
      "Train Epoch: 4 [48640/60000 (81%)]\tLoss: 0.092017\n",
      "Train Epoch: 4 [49280/60000 (82%)]\tLoss: 0.034238\n",
      "Train Epoch: 4 [49920/60000 (83%)]\tLoss: 0.011964\n",
      "Train Epoch: 4 [50560/60000 (84%)]\tLoss: 0.056915\n",
      "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.130912\n",
      "Train Epoch: 4 [51840/60000 (86%)]\tLoss: 0.003831\n",
      "Train Epoch: 4 [52480/60000 (87%)]\tLoss: 0.060672\n",
      "Train Epoch: 4 [53120/60000 (88%)]\tLoss: 0.070848\n",
      "Train Epoch: 4 [53760/60000 (90%)]\tLoss: 0.018032\n",
      "Train Epoch: 4 [54400/60000 (91%)]\tLoss: 0.008966\n",
      "Train Epoch: 4 [55040/60000 (92%)]\tLoss: 0.041649\n",
      "Train Epoch: 4 [55680/60000 (93%)]\tLoss: 0.005698\n",
      "Train Epoch: 4 [56320/60000 (94%)]\tLoss: 0.012589\n",
      "Train Epoch: 4 [56960/60000 (95%)]\tLoss: 0.044247\n",
      "Train Epoch: 4 [57600/60000 (96%)]\tLoss: 0.019287\n",
      "Train Epoch: 4 [58240/60000 (97%)]\tLoss: 0.030385\n",
      "Train Epoch: 4 [58880/60000 (98%)]\tLoss: 0.199844\n",
      "Train Epoch: 4 [59520/60000 (99%)]\tLoss: 0.004859\n",
      "\n",
      "Test set: Avg. loss: 0.0366, Accuracy: 9889/10000 (99%)\n",
      "\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.014987\n",
      "Train Epoch: 5 [640/60000 (1%)]\tLoss: 0.003777\n",
      "Train Epoch: 5 [1280/60000 (2%)]\tLoss: 0.040654\n",
      "Train Epoch: 5 [1920/60000 (3%)]\tLoss: 0.013581\n",
      "Train Epoch: 5 [2560/60000 (4%)]\tLoss: 0.028654\n",
      "Train Epoch: 5 [3200/60000 (5%)]\tLoss: 0.007048\n",
      "Train Epoch: 5 [3840/60000 (6%)]\tLoss: 0.014090\n",
      "Train Epoch: 5 [4480/60000 (7%)]\tLoss: 0.019879\n",
      "Train Epoch: 5 [5120/60000 (9%)]\tLoss: 0.009272\n",
      "Train Epoch: 5 [5760/60000 (10%)]\tLoss: 0.004295\n",
      "Train Epoch: 5 [6400/60000 (11%)]\tLoss: 0.022509\n",
      "Train Epoch: 5 [7040/60000 (12%)]\tLoss: 0.011147\n",
      "Train Epoch: 5 [7680/60000 (13%)]\tLoss: 0.012141\n",
      "Train Epoch: 5 [8320/60000 (14%)]\tLoss: 0.009885\n",
      "Train Epoch: 5 [8960/60000 (15%)]\tLoss: 0.007501\n",
      "Train Epoch: 5 [9600/60000 (16%)]\tLoss: 0.002266\n",
      "Train Epoch: 5 [10240/60000 (17%)]\tLoss: 0.021872\n",
      "Train Epoch: 5 [10880/60000 (18%)]\tLoss: 0.027905\n",
      "Train Epoch: 5 [11520/60000 (19%)]\tLoss: 0.008868\n",
      "Train Epoch: 5 [12160/60000 (20%)]\tLoss: 0.004952\n",
      "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 0.128095\n",
      "Train Epoch: 5 [13440/60000 (22%)]\tLoss: 0.020732\n",
      "Train Epoch: 5 [14080/60000 (23%)]\tLoss: 0.001813\n",
      "Train Epoch: 5 [14720/60000 (25%)]\tLoss: 0.023580\n",
      "Train Epoch: 5 [15360/60000 (26%)]\tLoss: 0.224715\n",
      "Train Epoch: 5 [16000/60000 (27%)]\tLoss: 0.020876\n",
      "Train Epoch: 5 [16640/60000 (28%)]\tLoss: 0.095984\n",
      "Train Epoch: 5 [17280/60000 (29%)]\tLoss: 0.126784\n",
      "Train Epoch: 5 [17920/60000 (30%)]\tLoss: 0.031843\n",
      "Train Epoch: 5 [18560/60000 (31%)]\tLoss: 0.026103\n",
      "Train Epoch: 5 [19200/60000 (32%)]\tLoss: 0.005755\n",
      "Train Epoch: 5 [19840/60000 (33%)]\tLoss: 0.001916\n",
      "Train Epoch: 5 [20480/60000 (34%)]\tLoss: 0.088809\n",
      "Train Epoch: 5 [21120/60000 (35%)]\tLoss: 0.029682\n",
      "Train Epoch: 5 [21760/60000 (36%)]\tLoss: 0.001005\n",
      "Train Epoch: 5 [22400/60000 (37%)]\tLoss: 0.095687\n",
      "Train Epoch: 5 [23040/60000 (38%)]\tLoss: 0.028891\n",
      "Train Epoch: 5 [23680/60000 (39%)]\tLoss: 0.013709\n",
      "Train Epoch: 5 [24320/60000 (41%)]\tLoss: 0.003480\n",
      "Train Epoch: 5 [24960/60000 (42%)]\tLoss: 0.065747\n",
      "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 0.015844\n",
      "Train Epoch: 5 [26240/60000 (44%)]\tLoss: 0.015968\n",
      "Train Epoch: 5 [26880/60000 (45%)]\tLoss: 0.002232\n",
      "Train Epoch: 5 [27520/60000 (46%)]\tLoss: 0.082078\n",
      "Train Epoch: 5 [28160/60000 (47%)]\tLoss: 0.009860\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 5 [28800/60000 (48%)]\tLoss: 0.000621\n",
      "Train Epoch: 5 [29440/60000 (49%)]\tLoss: 0.029039\n",
      "Train Epoch: 5 [30080/60000 (50%)]\tLoss: 0.019613\n",
      "Train Epoch: 5 [30720/60000 (51%)]\tLoss: 0.011123\n",
      "Train Epoch: 5 [31360/60000 (52%)]\tLoss: 0.111283\n",
      "Train Epoch: 5 [32000/60000 (53%)]\tLoss: 0.092748\n",
      "Train Epoch: 5 [32640/60000 (54%)]\tLoss: 0.294645\n",
      "Train Epoch: 5 [33280/60000 (55%)]\tLoss: 0.038194\n",
      "Train Epoch: 5 [33920/60000 (57%)]\tLoss: 0.003316\n",
      "Train Epoch: 5 [34560/60000 (58%)]\tLoss: 0.013902\n",
      "Train Epoch: 5 [35200/60000 (59%)]\tLoss: 0.014347\n",
      "Train Epoch: 5 [35840/60000 (60%)]\tLoss: 0.029614\n",
      "Train Epoch: 5 [36480/60000 (61%)]\tLoss: 0.000887\n",
      "Train Epoch: 5 [37120/60000 (62%)]\tLoss: 0.006633\n",
      "Train Epoch: 5 [37760/60000 (63%)]\tLoss: 0.053783\n",
      "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 0.203209\n",
      "Train Epoch: 5 [39040/60000 (65%)]\tLoss: 0.044636\n",
      "Train Epoch: 5 [39680/60000 (66%)]\tLoss: 0.004071\n",
      "Train Epoch: 5 [40320/60000 (67%)]\tLoss: 0.008292\n",
      "Train Epoch: 5 [40960/60000 (68%)]\tLoss: 0.011789\n",
      "Train Epoch: 5 [41600/60000 (69%)]\tLoss: 0.033022\n",
      "Train Epoch: 5 [42240/60000 (70%)]\tLoss: 0.006796\n",
      "Train Epoch: 5 [42880/60000 (71%)]\tLoss: 0.014690\n",
      "Train Epoch: 5 [43520/60000 (72%)]\tLoss: 0.001511\n",
      "Train Epoch: 5 [44160/60000 (74%)]\tLoss: 0.137862\n",
      "Train Epoch: 5 [44800/60000 (75%)]\tLoss: 0.030717\n",
      "Train Epoch: 5 [45440/60000 (76%)]\tLoss: 0.019252\n",
      "Train Epoch: 5 [46080/60000 (77%)]\tLoss: 0.012629\n",
      "Train Epoch: 5 [46720/60000 (78%)]\tLoss: 0.013643\n",
      "Train Epoch: 5 [47360/60000 (79%)]\tLoss: 0.072104\n",
      "Train Epoch: 5 [48000/60000 (80%)]\tLoss: 0.032637\n",
      "Train Epoch: 5 [48640/60000 (81%)]\tLoss: 0.014429\n",
      "Train Epoch: 5 [49280/60000 (82%)]\tLoss: 0.013635\n",
      "Train Epoch: 5 [49920/60000 (83%)]\tLoss: 0.003606\n",
      "Train Epoch: 5 [50560/60000 (84%)]\tLoss: 0.022250\n",
      "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 0.018708\n",
      "Train Epoch: 5 [51840/60000 (86%)]\tLoss: 0.008470\n",
      "Train Epoch: 5 [52480/60000 (87%)]\tLoss: 0.000651\n",
      "Train Epoch: 5 [53120/60000 (88%)]\tLoss: 0.088922\n",
      "Train Epoch: 5 [53760/60000 (90%)]\tLoss: 0.006934\n",
      "Train Epoch: 5 [54400/60000 (91%)]\tLoss: 0.047778\n",
      "Train Epoch: 5 [55040/60000 (92%)]\tLoss: 0.000491\n",
      "Train Epoch: 5 [55680/60000 (93%)]\tLoss: 0.032543\n",
      "Train Epoch: 5 [56320/60000 (94%)]\tLoss: 0.040905\n",
      "Train Epoch: 5 [56960/60000 (95%)]\tLoss: 0.006134\n",
      "Train Epoch: 5 [57600/60000 (96%)]\tLoss: 0.021281\n",
      "Train Epoch: 5 [58240/60000 (97%)]\tLoss: 0.051426\n",
      "Train Epoch: 5 [58880/60000 (98%)]\tLoss: 0.056082\n",
      "Train Epoch: 5 [59520/60000 (99%)]\tLoss: 0.000841\n",
      "\n",
      "Test set: Avg. loss: 0.0311, Accuracy: 9898/10000 (99%)\n",
      "\n",
      "Train Epoch: 6 [0/60000 (0%)]\tLoss: 0.005181\n",
      "Train Epoch: 6 [640/60000 (1%)]\tLoss: 0.009620\n",
      "Train Epoch: 6 [1280/60000 (2%)]\tLoss: 0.026687\n",
      "Train Epoch: 6 [1920/60000 (3%)]\tLoss: 0.002026\n",
      "Train Epoch: 6 [2560/60000 (4%)]\tLoss: 0.005108\n",
      "Train Epoch: 6 [3200/60000 (5%)]\tLoss: 0.067891\n",
      "Train Epoch: 6 [3840/60000 (6%)]\tLoss: 0.061599\n",
      "Train Epoch: 6 [4480/60000 (7%)]\tLoss: 0.047006\n",
      "Train Epoch: 6 [5120/60000 (9%)]\tLoss: 0.134112\n",
      "Train Epoch: 6 [5760/60000 (10%)]\tLoss: 0.049996\n",
      "Train Epoch: 6 [6400/60000 (11%)]\tLoss: 0.007696\n",
      "Train Epoch: 6 [7040/60000 (12%)]\tLoss: 0.053399\n",
      "Train Epoch: 6 [7680/60000 (13%)]\tLoss: 0.018183\n",
      "Train Epoch: 6 [8320/60000 (14%)]\tLoss: 0.029327\n",
      "Train Epoch: 6 [8960/60000 (15%)]\tLoss: 0.001655\n",
      "Train Epoch: 6 [9600/60000 (16%)]\tLoss: 0.002225\n",
      "Train Epoch: 6 [10240/60000 (17%)]\tLoss: 0.015250\n",
      "Train Epoch: 6 [10880/60000 (18%)]\tLoss: 0.003428\n",
      "Train Epoch: 6 [11520/60000 (19%)]\tLoss: 0.013592\n",
      "Train Epoch: 6 [12160/60000 (20%)]\tLoss: 0.048877\n",
      "Train Epoch: 6 [12800/60000 (21%)]\tLoss: 0.053191\n",
      "Train Epoch: 6 [13440/60000 (22%)]\tLoss: 0.083575\n",
      "Train Epoch: 6 [14080/60000 (23%)]\tLoss: 0.062701\n",
      "Train Epoch: 6 [14720/60000 (25%)]\tLoss: 0.007978\n",
      "Train Epoch: 6 [15360/60000 (26%)]\tLoss: 0.002028\n",
      "Train Epoch: 6 [16000/60000 (27%)]\tLoss: 0.032577\n",
      "Train Epoch: 6 [16640/60000 (28%)]\tLoss: 0.001302\n",
      "Train Epoch: 6 [17280/60000 (29%)]\tLoss: 0.038650\n",
      "Train Epoch: 6 [17920/60000 (30%)]\tLoss: 0.008137\n",
      "Train Epoch: 6 [18560/60000 (31%)]\tLoss: 0.029497\n",
      "Train Epoch: 6 [19200/60000 (32%)]\tLoss: 0.003298\n",
      "Train Epoch: 6 [19840/60000 (33%)]\tLoss: 0.013983\n",
      "Train Epoch: 6 [20480/60000 (34%)]\tLoss: 0.002253\n",
      "Train Epoch: 6 [21120/60000 (35%)]\tLoss: 0.089512\n",
      "Train Epoch: 6 [21760/60000 (36%)]\tLoss: 0.174252\n",
      "Train Epoch: 6 [22400/60000 (37%)]\tLoss: 0.004609\n",
      "Train Epoch: 6 [23040/60000 (38%)]\tLoss: 0.007256\n",
      "Train Epoch: 6 [23680/60000 (39%)]\tLoss: 0.004537\n",
      "Train Epoch: 6 [24320/60000 (41%)]\tLoss: 0.035637\n",
      "Train Epoch: 6 [24960/60000 (42%)]\tLoss: 0.025870\n",
      "Train Epoch: 6 [25600/60000 (43%)]\tLoss: 0.001219\n",
      "Train Epoch: 6 [26240/60000 (44%)]\tLoss: 0.022961\n",
      "Train Epoch: 6 [26880/60000 (45%)]\tLoss: 0.014130\n",
      "Train Epoch: 6 [27520/60000 (46%)]\tLoss: 0.001065\n",
      "Train Epoch: 6 [28160/60000 (47%)]\tLoss: 0.017884\n",
      "Train Epoch: 6 [28800/60000 (48%)]\tLoss: 0.084870\n",
      "Train Epoch: 6 [29440/60000 (49%)]\tLoss: 0.001586\n",
      "Train Epoch: 6 [30080/60000 (50%)]\tLoss: 0.006411\n",
      "Train Epoch: 6 [30720/60000 (51%)]\tLoss: 0.092920\n",
      "Train Epoch: 6 [31360/60000 (52%)]\tLoss: 0.018196\n",
      "Train Epoch: 6 [32000/60000 (53%)]\tLoss: 0.033219\n",
      "Train Epoch: 6 [32640/60000 (54%)]\tLoss: 0.131064\n",
      "Train Epoch: 6 [33280/60000 (55%)]\tLoss: 0.001221\n",
      "Train Epoch: 6 [33920/60000 (57%)]\tLoss: 0.002425\n",
      "Train Epoch: 6 [34560/60000 (58%)]\tLoss: 0.071799\n",
      "Train Epoch: 6 [35200/60000 (59%)]\tLoss: 0.060077\n",
      "Train Epoch: 6 [35840/60000 (60%)]\tLoss: 0.038822\n",
      "Train Epoch: 6 [36480/60000 (61%)]\tLoss: 0.019104\n",
      "Train Epoch: 6 [37120/60000 (62%)]\tLoss: 0.001785\n",
      "Train Epoch: 6 [37760/60000 (63%)]\tLoss: 0.001928\n",
      "Train Epoch: 6 [38400/60000 (64%)]\tLoss: 0.082694\n",
      "Train Epoch: 6 [39040/60000 (65%)]\tLoss: 0.005669\n",
      "Train Epoch: 6 [39680/60000 (66%)]\tLoss: 0.015134\n",
      "Train Epoch: 6 [40320/60000 (67%)]\tLoss: 0.041995\n",
      "Train Epoch: 6 [40960/60000 (68%)]\tLoss: 0.011205\n",
      "Train Epoch: 6 [41600/60000 (69%)]\tLoss: 0.016680\n",
      "Train Epoch: 6 [42240/60000 (70%)]\tLoss: 0.048467\n",
      "Train Epoch: 6 [42880/60000 (71%)]\tLoss: 0.042159\n",
      "Train Epoch: 6 [43520/60000 (72%)]\tLoss: 0.051474\n",
      "Train Epoch: 6 [44160/60000 (74%)]\tLoss: 0.015476\n",
      "Train Epoch: 6 [44800/60000 (75%)]\tLoss: 0.026521\n",
      "Train Epoch: 6 [45440/60000 (76%)]\tLoss: 0.002076\n",
      "Train Epoch: 6 [46080/60000 (77%)]\tLoss: 0.005925\n",
      "Train Epoch: 6 [46720/60000 (78%)]\tLoss: 0.006071\n",
      "Train Epoch: 6 [47360/60000 (79%)]\tLoss: 0.002563\n",
      "Train Epoch: 6 [48000/60000 (80%)]\tLoss: 0.053637\n",
      "Train Epoch: 6 [48640/60000 (81%)]\tLoss: 0.005312\n",
      "Train Epoch: 6 [49280/60000 (82%)]\tLoss: 0.000776\n",
      "Train Epoch: 6 [49920/60000 (83%)]\tLoss: 0.013185\n",
      "Train Epoch: 6 [50560/60000 (84%)]\tLoss: 0.131398\n",
      "Train Epoch: 6 [51200/60000 (85%)]\tLoss: 0.010917\n",
      "Train Epoch: 6 [51840/60000 (86%)]\tLoss: 0.004615\n",
      "Train Epoch: 6 [52480/60000 (87%)]\tLoss: 0.081209\n",
      "Train Epoch: 6 [53120/60000 (88%)]\tLoss: 0.000951\n",
      "Train Epoch: 6 [53760/60000 (90%)]\tLoss: 0.001049\n",
      "Train Epoch: 6 [54400/60000 (91%)]\tLoss: 0.044280\n",
      "Train Epoch: 6 [55040/60000 (92%)]\tLoss: 0.096942\n",
      "Train Epoch: 6 [55680/60000 (93%)]\tLoss: 0.000466\n",
      "Train Epoch: 6 [56320/60000 (94%)]\tLoss: 0.003739\n",
      "Train Epoch: 6 [56960/60000 (95%)]\tLoss: 0.022149\n",
      "Train Epoch: 6 [57600/60000 (96%)]\tLoss: 0.022197\n",
      "Train Epoch: 6 [58240/60000 (97%)]\tLoss: 0.071742\n",
      "Train Epoch: 6 [58880/60000 (98%)]\tLoss: 0.016604\n",
      "Train Epoch: 6 [59520/60000 (99%)]\tLoss: 0.073676\n",
      "\n",
      "Test set: Avg. loss: 0.0404, Accuracy: 9877/10000 (99%)\n",
      "\n",
      "Train Epoch: 7 [0/60000 (0%)]\tLoss: 0.001773\n",
      "Train Epoch: 7 [640/60000 (1%)]\tLoss: 0.051348\n",
      "Train Epoch: 7 [1280/60000 (2%)]\tLoss: 0.009278\n",
      "Train Epoch: 7 [1920/60000 (3%)]\tLoss: 0.027709\n",
      "Train Epoch: 7 [2560/60000 (4%)]\tLoss: 0.003227\n",
      "Train Epoch: 7 [3200/60000 (5%)]\tLoss: 0.000250\n",
      "Train Epoch: 7 [3840/60000 (6%)]\tLoss: 0.003374\n",
      "Train Epoch: 7 [4480/60000 (7%)]\tLoss: 0.029910\n",
      "Train Epoch: 7 [5120/60000 (9%)]\tLoss: 0.110639\n",
      "Train Epoch: 7 [5760/60000 (10%)]\tLoss: 0.005541\n",
      "Train Epoch: 7 [6400/60000 (11%)]\tLoss: 0.079140\n",
      "Train Epoch: 7 [7040/60000 (12%)]\tLoss: 0.002166\n",
      "Train Epoch: 7 [7680/60000 (13%)]\tLoss: 0.002201\n",
      "Train Epoch: 7 [8320/60000 (14%)]\tLoss: 0.006235\n",
      "Train Epoch: 7 [8960/60000 (15%)]\tLoss: 0.003908\n",
      "Train Epoch: 7 [9600/60000 (16%)]\tLoss: 0.001875\n",
      "Train Epoch: 7 [10240/60000 (17%)]\tLoss: 0.001292\n",
      "Train Epoch: 7 [10880/60000 (18%)]\tLoss: 0.007209\n",
      "Train Epoch: 7 [11520/60000 (19%)]\tLoss: 0.013181\n",
      "Train Epoch: 7 [12160/60000 (20%)]\tLoss: 0.013013\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 7 [12800/60000 (21%)]\tLoss: 0.012264\n",
      "Train Epoch: 7 [13440/60000 (22%)]\tLoss: 0.021894\n",
      "Train Epoch: 7 [14080/60000 (23%)]\tLoss: 0.029812\n",
      "Train Epoch: 7 [14720/60000 (25%)]\tLoss: 0.028452\n",
      "Train Epoch: 7 [15360/60000 (26%)]\tLoss: 0.031699\n",
      "Train Epoch: 7 [16000/60000 (27%)]\tLoss: 0.003681\n",
      "Train Epoch: 7 [16640/60000 (28%)]\tLoss: 0.001780\n",
      "Train Epoch: 7 [17280/60000 (29%)]\tLoss: 0.013492\n",
      "Train Epoch: 7 [17920/60000 (30%)]\tLoss: 0.015646\n",
      "Train Epoch: 7 [18560/60000 (31%)]\tLoss: 0.000909\n",
      "Train Epoch: 7 [19200/60000 (32%)]\tLoss: 0.007987\n",
      "Train Epoch: 7 [19840/60000 (33%)]\tLoss: 0.009458\n",
      "Train Epoch: 7 [20480/60000 (34%)]\tLoss: 0.142578\n",
      "Train Epoch: 7 [21120/60000 (35%)]\tLoss: 0.001646\n",
      "Train Epoch: 7 [21760/60000 (36%)]\tLoss: 0.002627\n",
      "Train Epoch: 7 [22400/60000 (37%)]\tLoss: 0.001660\n",
      "Train Epoch: 7 [23040/60000 (38%)]\tLoss: 0.005783\n",
      "Train Epoch: 7 [23680/60000 (39%)]\tLoss: 0.005346\n",
      "Train Epoch: 7 [24320/60000 (41%)]\tLoss: 0.027005\n",
      "Train Epoch: 7 [24960/60000 (42%)]\tLoss: 0.002098\n",
      "Train Epoch: 7 [25600/60000 (43%)]\tLoss: 0.008575\n",
      "Train Epoch: 7 [26240/60000 (44%)]\tLoss: 0.001004\n",
      "Train Epoch: 7 [26880/60000 (45%)]\tLoss: 0.012545\n",
      "Train Epoch: 7 [27520/60000 (46%)]\tLoss: 0.003645\n",
      "Train Epoch: 7 [28160/60000 (47%)]\tLoss: 0.028646\n",
      "Train Epoch: 7 [28800/60000 (48%)]\tLoss: 0.055447\n",
      "Train Epoch: 7 [29440/60000 (49%)]\tLoss: 0.002744\n",
      "Train Epoch: 7 [30080/60000 (50%)]\tLoss: 0.003186\n",
      "Train Epoch: 7 [30720/60000 (51%)]\tLoss: 0.003922\n",
      "Train Epoch: 7 [31360/60000 (52%)]\tLoss: 0.059373\n",
      "Train Epoch: 7 [32000/60000 (53%)]\tLoss: 0.035440\n",
      "Train Epoch: 7 [32640/60000 (54%)]\tLoss: 0.000352\n",
      "Train Epoch: 7 [33280/60000 (55%)]\tLoss: 0.001338\n",
      "Train Epoch: 7 [33920/60000 (57%)]\tLoss: 0.028134\n",
      "Train Epoch: 7 [34560/60000 (58%)]\tLoss: 0.002980\n",
      "Train Epoch: 7 [35200/60000 (59%)]\tLoss: 0.002367\n",
      "Train Epoch: 7 [35840/60000 (60%)]\tLoss: 0.006691\n",
      "Train Epoch: 7 [36480/60000 (61%)]\tLoss: 0.011474\n",
      "Train Epoch: 7 [37120/60000 (62%)]\tLoss: 0.000984\n",
      "Train Epoch: 7 [37760/60000 (63%)]\tLoss: 0.063581\n",
      "Train Epoch: 7 [38400/60000 (64%)]\tLoss: 0.001893\n",
      "Train Epoch: 7 [39040/60000 (65%)]\tLoss: 0.069562\n",
      "Train Epoch: 7 [39680/60000 (66%)]\tLoss: 0.002260\n",
      "Train Epoch: 7 [40320/60000 (67%)]\tLoss: 0.010930\n",
      "Train Epoch: 7 [40960/60000 (68%)]\tLoss: 0.009610\n",
      "Train Epoch: 7 [41600/60000 (69%)]\tLoss: 0.033436\n",
      "Train Epoch: 7 [42240/60000 (70%)]\tLoss: 0.016573\n",
      "Train Epoch: 7 [42880/60000 (71%)]\tLoss: 0.082704\n",
      "Train Epoch: 7 [43520/60000 (72%)]\tLoss: 0.003105\n",
      "Train Epoch: 7 [44160/60000 (74%)]\tLoss: 0.006928\n",
      "Train Epoch: 7 [44800/60000 (75%)]\tLoss: 0.001012\n",
      "Train Epoch: 7 [45440/60000 (76%)]\tLoss: 0.030706\n",
      "Train Epoch: 7 [46080/60000 (77%)]\tLoss: 0.023171\n",
      "Train Epoch: 7 [46720/60000 (78%)]\tLoss: 0.005251\n",
      "Train Epoch: 7 [47360/60000 (79%)]\tLoss: 0.006749\n",
      "Train Epoch: 7 [48000/60000 (80%)]\tLoss: 0.046833\n",
      "Train Epoch: 7 [48640/60000 (81%)]\tLoss: 0.024389\n",
      "Train Epoch: 7 [49280/60000 (82%)]\tLoss: 0.003544\n",
      "Train Epoch: 7 [49920/60000 (83%)]\tLoss: 0.041747\n",
      "Train Epoch: 7 [50560/60000 (84%)]\tLoss: 0.000670\n",
      "Train Epoch: 7 [51200/60000 (85%)]\tLoss: 0.008747\n",
      "Train Epoch: 7 [51840/60000 (86%)]\tLoss: 0.025285\n",
      "Train Epoch: 7 [52480/60000 (87%)]\tLoss: 0.076277\n",
      "Train Epoch: 7 [53120/60000 (88%)]\tLoss: 0.004803\n",
      "Train Epoch: 7 [53760/60000 (90%)]\tLoss: 0.010545\n",
      "Train Epoch: 7 [54400/60000 (91%)]\tLoss: 0.071991\n",
      "Train Epoch: 7 [55040/60000 (92%)]\tLoss: 0.028276\n",
      "Train Epoch: 7 [55680/60000 (93%)]\tLoss: 0.058645\n",
      "Train Epoch: 7 [56320/60000 (94%)]\tLoss: 0.079705\n",
      "Train Epoch: 7 [56960/60000 (95%)]\tLoss: 0.001079\n",
      "Train Epoch: 7 [57600/60000 (96%)]\tLoss: 0.002242\n",
      "Train Epoch: 7 [58240/60000 (97%)]\tLoss: 0.059431\n",
      "Train Epoch: 7 [58880/60000 (98%)]\tLoss: 0.001410\n",
      "Train Epoch: 7 [59520/60000 (99%)]\tLoss: 0.006433\n",
      "\n",
      "Test set: Avg. loss: 0.0313, Accuracy: 9906/10000 (99%)\n",
      "\n",
      "Train Epoch: 8 [0/60000 (0%)]\tLoss: 0.003494\n",
      "Train Epoch: 8 [640/60000 (1%)]\tLoss: 0.004303\n",
      "Train Epoch: 8 [1280/60000 (2%)]\tLoss: 0.036903\n",
      "Train Epoch: 8 [1920/60000 (3%)]\tLoss: 0.005667\n",
      "Train Epoch: 8 [2560/60000 (4%)]\tLoss: 0.036175\n",
      "Train Epoch: 8 [3200/60000 (5%)]\tLoss: 0.002027\n",
      "Train Epoch: 8 [3840/60000 (6%)]\tLoss: 0.000388\n",
      "Train Epoch: 8 [4480/60000 (7%)]\tLoss: 0.002201\n",
      "Train Epoch: 8 [5120/60000 (9%)]\tLoss: 0.000803\n",
      "Train Epoch: 8 [5760/60000 (10%)]\tLoss: 0.001053\n",
      "Train Epoch: 8 [6400/60000 (11%)]\tLoss: 0.000871\n",
      "Train Epoch: 8 [7040/60000 (12%)]\tLoss: 0.008871\n",
      "Train Epoch: 8 [7680/60000 (13%)]\tLoss: 0.007245\n",
      "Train Epoch: 8 [8320/60000 (14%)]\tLoss: 0.052027\n",
      "Train Epoch: 8 [8960/60000 (15%)]\tLoss: 0.000954\n",
      "Train Epoch: 8 [9600/60000 (16%)]\tLoss: 0.001000\n",
      "Train Epoch: 8 [10240/60000 (17%)]\tLoss: 0.005095\n",
      "Train Epoch: 8 [10880/60000 (18%)]\tLoss: 0.006492\n",
      "Train Epoch: 8 [11520/60000 (19%)]\tLoss: 0.006984\n",
      "Train Epoch: 8 [12160/60000 (20%)]\tLoss: 0.002052\n",
      "Train Epoch: 8 [12800/60000 (21%)]\tLoss: 0.001298\n",
      "Train Epoch: 8 [13440/60000 (22%)]\tLoss: 0.002619\n",
      "Train Epoch: 8 [14080/60000 (23%)]\tLoss: 0.001976\n",
      "Train Epoch: 8 [14720/60000 (25%)]\tLoss: 0.020541\n",
      "Train Epoch: 8 [15360/60000 (26%)]\tLoss: 0.018371\n",
      "Train Epoch: 8 [16000/60000 (27%)]\tLoss: 0.006644\n",
      "Train Epoch: 8 [16640/60000 (28%)]\tLoss: 0.006518\n",
      "Train Epoch: 8 [17280/60000 (29%)]\tLoss: 0.019470\n",
      "Train Epoch: 8 [17920/60000 (30%)]\tLoss: 0.003727\n",
      "Train Epoch: 8 [18560/60000 (31%)]\tLoss: 0.020047\n",
      "Train Epoch: 8 [19200/60000 (32%)]\tLoss: 0.008888\n",
      "Train Epoch: 8 [19840/60000 (33%)]\tLoss: 0.006585\n",
      "Train Epoch: 8 [20480/60000 (34%)]\tLoss: 0.017109\n",
      "Train Epoch: 8 [21120/60000 (35%)]\tLoss: 0.004839\n",
      "Train Epoch: 8 [21760/60000 (36%)]\tLoss: 0.001544\n",
      "Train Epoch: 8 [22400/60000 (37%)]\tLoss: 0.006474\n",
      "Train Epoch: 8 [23040/60000 (38%)]\tLoss: 0.007466\n",
      "Train Epoch: 8 [23680/60000 (39%)]\tLoss: 0.000848\n",
      "Train Epoch: 8 [24320/60000 (41%)]\tLoss: 0.019019\n",
      "Train Epoch: 8 [24960/60000 (42%)]\tLoss: 0.158889\n",
      "Train Epoch: 8 [25600/60000 (43%)]\tLoss: 0.016835\n",
      "Train Epoch: 8 [26240/60000 (44%)]\tLoss: 0.005982\n",
      "Train Epoch: 8 [26880/60000 (45%)]\tLoss: 0.000374\n",
      "Train Epoch: 8 [27520/60000 (46%)]\tLoss: 0.000388\n",
      "Train Epoch: 8 [28160/60000 (47%)]\tLoss: 0.007412\n",
      "Train Epoch: 8 [28800/60000 (48%)]\tLoss: 0.002689\n",
      "Train Epoch: 8 [29440/60000 (49%)]\tLoss: 0.000437\n",
      "Train Epoch: 8 [30080/60000 (50%)]\tLoss: 0.003226\n",
      "Train Epoch: 8 [30720/60000 (51%)]\tLoss: 0.004472\n",
      "Train Epoch: 8 [31360/60000 (52%)]\tLoss: 0.002031\n",
      "Train Epoch: 8 [32000/60000 (53%)]\tLoss: 0.003633\n",
      "Train Epoch: 8 [32640/60000 (54%)]\tLoss: 0.001227\n",
      "Train Epoch: 8 [33280/60000 (55%)]\tLoss: 0.005259\n",
      "Train Epoch: 8 [33920/60000 (57%)]\tLoss: 0.003577\n",
      "Train Epoch: 8 [34560/60000 (58%)]\tLoss: 0.034989\n",
      "Train Epoch: 8 [35200/60000 (59%)]\tLoss: 0.006704\n",
      "Train Epoch: 8 [35840/60000 (60%)]\tLoss: 0.017890\n",
      "Train Epoch: 8 [36480/60000 (61%)]\tLoss: 0.008300\n",
      "Train Epoch: 8 [37120/60000 (62%)]\tLoss: 0.003106\n",
      "Train Epoch: 8 [37760/60000 (63%)]\tLoss: 0.000301\n",
      "Train Epoch: 8 [38400/60000 (64%)]\tLoss: 0.000677\n",
      "Train Epoch: 8 [39040/60000 (65%)]\tLoss: 0.001979\n",
      "Train Epoch: 8 [39680/60000 (66%)]\tLoss: 0.007399\n",
      "Train Epoch: 8 [40320/60000 (67%)]\tLoss: 0.005098\n",
      "Train Epoch: 8 [40960/60000 (68%)]\tLoss: 0.007613\n",
      "Train Epoch: 8 [41600/60000 (69%)]\tLoss: 0.001274\n",
      "Train Epoch: 8 [42240/60000 (70%)]\tLoss: 0.000737\n",
      "Train Epoch: 8 [42880/60000 (71%)]\tLoss: 0.041975\n",
      "Train Epoch: 8 [43520/60000 (72%)]\tLoss: 0.004422\n",
      "Train Epoch: 8 [44160/60000 (74%)]\tLoss: 0.025346\n",
      "Train Epoch: 8 [44800/60000 (75%)]\tLoss: 0.012291\n",
      "Train Epoch: 8 [45440/60000 (76%)]\tLoss: 0.000259\n",
      "Train Epoch: 8 [46080/60000 (77%)]\tLoss: 0.008129\n",
      "Train Epoch: 8 [46720/60000 (78%)]\tLoss: 0.000190\n",
      "Train Epoch: 8 [47360/60000 (79%)]\tLoss: 0.001230\n",
      "Train Epoch: 8 [48000/60000 (80%)]\tLoss: 0.004935\n",
      "Train Epoch: 8 [48640/60000 (81%)]\tLoss: 0.001916\n",
      "Train Epoch: 8 [49280/60000 (82%)]\tLoss: 0.019475\n",
      "Train Epoch: 8 [49920/60000 (83%)]\tLoss: 0.002205\n",
      "Train Epoch: 8 [50560/60000 (84%)]\tLoss: 0.000521\n",
      "Train Epoch: 8 [51200/60000 (85%)]\tLoss: 0.099250\n",
      "Train Epoch: 8 [51840/60000 (86%)]\tLoss: 0.000320\n",
      "Train Epoch: 8 [52480/60000 (87%)]\tLoss: 0.002008\n",
      "Train Epoch: 8 [53120/60000 (88%)]\tLoss: 0.003902\n",
      "Train Epoch: 8 [53760/60000 (90%)]\tLoss: 0.005260\n",
      "Train Epoch: 8 [54400/60000 (91%)]\tLoss: 0.007999\n",
      "Train Epoch: 8 [55040/60000 (92%)]\tLoss: 0.045335\n",
      "Train Epoch: 8 [55680/60000 (93%)]\tLoss: 0.065108\n",
      "Train Epoch: 8 [56320/60000 (94%)]\tLoss: 0.001722\n",
      "Train Epoch: 8 [56960/60000 (95%)]\tLoss: 0.002475\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 8 [57600/60000 (96%)]\tLoss: 0.039958\n",
      "Train Epoch: 8 [58240/60000 (97%)]\tLoss: 0.000757\n",
      "Train Epoch: 8 [58880/60000 (98%)]\tLoss: 0.000315\n",
      "Train Epoch: 8 [59520/60000 (99%)]\tLoss: 0.003817\n",
      "\n",
      "Test set: Avg. loss: 0.0351, Accuracy: 9894/10000 (99%)\n",
      "\n",
      "Train Epoch: 9 [0/60000 (0%)]\tLoss: 0.001203\n",
      "Train Epoch: 9 [640/60000 (1%)]\tLoss: 0.001702\n",
      "Train Epoch: 9 [1280/60000 (2%)]\tLoss: 0.006835\n",
      "Train Epoch: 9 [1920/60000 (3%)]\tLoss: 0.003360\n",
      "Train Epoch: 9 [2560/60000 (4%)]\tLoss: 0.020107\n",
      "Train Epoch: 9 [3200/60000 (5%)]\tLoss: 0.114815\n",
      "Train Epoch: 9 [3840/60000 (6%)]\tLoss: 0.027489\n",
      "Train Epoch: 9 [4480/60000 (7%)]\tLoss: 0.003741\n",
      "Train Epoch: 9 [5120/60000 (9%)]\tLoss: 0.024776\n",
      "Train Epoch: 9 [5760/60000 (10%)]\tLoss: 0.000524\n",
      "Train Epoch: 9 [6400/60000 (11%)]\tLoss: 0.000546\n",
      "Train Epoch: 9 [7040/60000 (12%)]\tLoss: 0.019681\n",
      "Train Epoch: 9 [7680/60000 (13%)]\tLoss: 0.005357\n",
      "Train Epoch: 9 [8320/60000 (14%)]\tLoss: 0.000982\n",
      "Train Epoch: 9 [8960/60000 (15%)]\tLoss: 0.009459\n",
      "Train Epoch: 9 [9600/60000 (16%)]\tLoss: 0.007662\n",
      "Train Epoch: 9 [10240/60000 (17%)]\tLoss: 0.006393\n",
      "Train Epoch: 9 [10880/60000 (18%)]\tLoss: 0.036804\n",
      "Train Epoch: 9 [11520/60000 (19%)]\tLoss: 0.012429\n",
      "Train Epoch: 9 [12160/60000 (20%)]\tLoss: 0.018876\n",
      "Train Epoch: 9 [12800/60000 (21%)]\tLoss: 0.057049\n",
      "Train Epoch: 9 [13440/60000 (22%)]\tLoss: 0.018529\n",
      "Train Epoch: 9 [14080/60000 (23%)]\tLoss: 0.002878\n",
      "Train Epoch: 9 [14720/60000 (25%)]\tLoss: 0.003156\n",
      "Train Epoch: 9 [15360/60000 (26%)]\tLoss: 0.006465\n",
      "Train Epoch: 9 [16000/60000 (27%)]\tLoss: 0.008852\n",
      "Train Epoch: 9 [16640/60000 (28%)]\tLoss: 0.000734\n",
      "Train Epoch: 9 [17280/60000 (29%)]\tLoss: 0.000598\n",
      "Train Epoch: 9 [17920/60000 (30%)]\tLoss: 0.001560\n",
      "Train Epoch: 9 [18560/60000 (31%)]\tLoss: 0.011484\n",
      "Train Epoch: 9 [19200/60000 (32%)]\tLoss: 0.001136\n",
      "Train Epoch: 9 [19840/60000 (33%)]\tLoss: 0.001993\n",
      "Train Epoch: 9 [20480/60000 (34%)]\tLoss: 0.040002\n",
      "Train Epoch: 9 [21120/60000 (35%)]\tLoss: 0.008026\n",
      "Train Epoch: 9 [21760/60000 (36%)]\tLoss: 0.004551\n",
      "Train Epoch: 9 [22400/60000 (37%)]\tLoss: 0.001563\n",
      "Train Epoch: 9 [23040/60000 (38%)]\tLoss: 0.007789\n",
      "Train Epoch: 9 [23680/60000 (39%)]\tLoss: 0.089642\n",
      "Train Epoch: 9 [24320/60000 (41%)]\tLoss: 0.000984\n",
      "Train Epoch: 9 [24960/60000 (42%)]\tLoss: 0.006350\n",
      "Train Epoch: 9 [25600/60000 (43%)]\tLoss: 0.007212\n",
      "Train Epoch: 9 [26240/60000 (44%)]\tLoss: 0.030620\n",
      "Train Epoch: 9 [26880/60000 (45%)]\tLoss: 0.002047\n",
      "Train Epoch: 9 [27520/60000 (46%)]\tLoss: 0.002237\n",
      "Train Epoch: 9 [28160/60000 (47%)]\tLoss: 0.000992\n",
      "Train Epoch: 9 [28800/60000 (48%)]\tLoss: 0.000664\n",
      "Train Epoch: 9 [29440/60000 (49%)]\tLoss: 0.003996\n",
      "Train Epoch: 9 [30080/60000 (50%)]\tLoss: 0.069636\n",
      "Train Epoch: 9 [30720/60000 (51%)]\tLoss: 0.000446\n",
      "Train Epoch: 9 [31360/60000 (52%)]\tLoss: 0.000433\n",
      "Train Epoch: 9 [32000/60000 (53%)]\tLoss: 0.019498\n",
      "Train Epoch: 9 [32640/60000 (54%)]\tLoss: 0.000246\n",
      "Train Epoch: 9 [33280/60000 (55%)]\tLoss: 0.005600\n",
      "Train Epoch: 9 [33920/60000 (57%)]\tLoss: 0.001890\n",
      "Train Epoch: 9 [34560/60000 (58%)]\tLoss: 0.000881\n",
      "Train Epoch: 9 [35200/60000 (59%)]\tLoss: 0.002387\n",
      "Train Epoch: 9 [35840/60000 (60%)]\tLoss: 0.000175\n",
      "Train Epoch: 9 [36480/60000 (61%)]\tLoss: 0.004189\n",
      "Train Epoch: 9 [37120/60000 (62%)]\tLoss: 0.006011\n",
      "Train Epoch: 9 [37760/60000 (63%)]\tLoss: 0.009952\n",
      "Train Epoch: 9 [38400/60000 (64%)]\tLoss: 0.005281\n",
      "Train Epoch: 9 [39040/60000 (65%)]\tLoss: 0.000247\n",
      "Train Epoch: 9 [39680/60000 (66%)]\tLoss: 0.072903\n",
      "Train Epoch: 9 [40320/60000 (67%)]\tLoss: 0.010274\n",
      "Train Epoch: 9 [40960/60000 (68%)]\tLoss: 0.002215\n",
      "Train Epoch: 9 [41600/60000 (69%)]\tLoss: 0.002034\n",
      "Train Epoch: 9 [42240/60000 (70%)]\tLoss: 0.006637\n",
      "Train Epoch: 9 [42880/60000 (71%)]\tLoss: 0.001734\n",
      "Train Epoch: 9 [43520/60000 (72%)]\tLoss: 0.049270\n",
      "Train Epoch: 9 [44160/60000 (74%)]\tLoss: 0.010943\n",
      "Train Epoch: 9 [44800/60000 (75%)]\tLoss: 0.004900\n",
      "Train Epoch: 9 [45440/60000 (76%)]\tLoss: 0.011474\n",
      "Train Epoch: 9 [46080/60000 (77%)]\tLoss: 0.001659\n",
      "Train Epoch: 9 [46720/60000 (78%)]\tLoss: 0.001239\n",
      "Train Epoch: 9 [47360/60000 (79%)]\tLoss: 0.003250\n",
      "Train Epoch: 9 [48000/60000 (80%)]\tLoss: 0.003173\n",
      "Train Epoch: 9 [48640/60000 (81%)]\tLoss: 0.053954\n",
      "Train Epoch: 9 [49280/60000 (82%)]\tLoss: 0.017301\n",
      "Train Epoch: 9 [49920/60000 (83%)]\tLoss: 0.000308\n",
      "Train Epoch: 9 [50560/60000 (84%)]\tLoss: 0.012033\n",
      "Train Epoch: 9 [51200/60000 (85%)]\tLoss: 0.020716\n",
      "Train Epoch: 9 [51840/60000 (86%)]\tLoss: 0.011323\n",
      "Train Epoch: 9 [52480/60000 (87%)]\tLoss: 0.011844\n",
      "Train Epoch: 9 [53120/60000 (88%)]\tLoss: 0.007715\n",
      "Train Epoch: 9 [53760/60000 (90%)]\tLoss: 0.002612\n",
      "Train Epoch: 9 [54400/60000 (91%)]\tLoss: 0.003839\n",
      "Train Epoch: 9 [55040/60000 (92%)]\tLoss: 0.044179\n",
      "Train Epoch: 9 [55680/60000 (93%)]\tLoss: 0.001921\n",
      "Train Epoch: 9 [56320/60000 (94%)]\tLoss: 0.017260\n",
      "Train Epoch: 9 [56960/60000 (95%)]\tLoss: 0.000809\n",
      "Train Epoch: 9 [57600/60000 (96%)]\tLoss: 0.006081\n",
      "Train Epoch: 9 [58240/60000 (97%)]\tLoss: 0.015003\n",
      "Train Epoch: 9 [58880/60000 (98%)]\tLoss: 0.024409\n",
      "Train Epoch: 9 [59520/60000 (99%)]\tLoss: 0.012273\n",
      "\n",
      "Test set: Avg. loss: 0.0443, Accuracy: 9866/10000 (99%)\n",
      "\n",
      "Train Epoch: 10 [0/60000 (0%)]\tLoss: 0.079274\n",
      "Train Epoch: 10 [640/60000 (1%)]\tLoss: 0.001184\n",
      "Train Epoch: 10 [1280/60000 (2%)]\tLoss: 0.060765\n",
      "Train Epoch: 10 [1920/60000 (3%)]\tLoss: 0.000367\n",
      "Train Epoch: 10 [2560/60000 (4%)]\tLoss: 0.016448\n",
      "Train Epoch: 10 [3200/60000 (5%)]\tLoss: 0.000147\n",
      "Train Epoch: 10 [3840/60000 (6%)]\tLoss: 0.000394\n",
      "Train Epoch: 10 [4480/60000 (7%)]\tLoss: 0.000519\n",
      "Train Epoch: 10 [5120/60000 (9%)]\tLoss: 0.030863\n",
      "Train Epoch: 10 [5760/60000 (10%)]\tLoss: 0.000606\n",
      "Train Epoch: 10 [6400/60000 (11%)]\tLoss: 0.007994\n",
      "Train Epoch: 10 [7040/60000 (12%)]\tLoss: 0.000266\n",
      "Train Epoch: 10 [7680/60000 (13%)]\tLoss: 0.000043\n",
      "Train Epoch: 10 [8320/60000 (14%)]\tLoss: 0.021523\n",
      "Train Epoch: 10 [8960/60000 (15%)]\tLoss: 0.050241\n",
      "Train Epoch: 10 [9600/60000 (16%)]\tLoss: 0.015623\n",
      "Train Epoch: 10 [10240/60000 (17%)]\tLoss: 0.013997\n",
      "Train Epoch: 10 [10880/60000 (18%)]\tLoss: 0.001072\n",
      "Train Epoch: 10 [11520/60000 (19%)]\tLoss: 0.019564\n",
      "Train Epoch: 10 [12160/60000 (20%)]\tLoss: 0.007209\n",
      "Train Epoch: 10 [12800/60000 (21%)]\tLoss: 0.003578\n",
      "Train Epoch: 10 [13440/60000 (22%)]\tLoss: 0.008707\n",
      "Train Epoch: 10 [14080/60000 (23%)]\tLoss: 0.003063\n",
      "Train Epoch: 10 [14720/60000 (25%)]\tLoss: 0.003265\n",
      "Train Epoch: 10 [15360/60000 (26%)]\tLoss: 0.000962\n",
      "Train Epoch: 10 [16000/60000 (27%)]\tLoss: 0.013556\n",
      "Train Epoch: 10 [16640/60000 (28%)]\tLoss: 0.000394\n",
      "Train Epoch: 10 [17280/60000 (29%)]\tLoss: 0.011400\n",
      "Train Epoch: 10 [17920/60000 (30%)]\tLoss: 0.004155\n",
      "Train Epoch: 10 [18560/60000 (31%)]\tLoss: 0.004933\n",
      "Train Epoch: 10 [19200/60000 (32%)]\tLoss: 0.005475\n",
      "Train Epoch: 10 [19840/60000 (33%)]\tLoss: 0.091010\n",
      "Train Epoch: 10 [20480/60000 (34%)]\tLoss: 0.003137\n",
      "Train Epoch: 10 [21120/60000 (35%)]\tLoss: 0.028026\n",
      "Train Epoch: 10 [21760/60000 (36%)]\tLoss: 0.115820\n",
      "Train Epoch: 10 [22400/60000 (37%)]\tLoss: 0.013333\n",
      "Train Epoch: 10 [23040/60000 (38%)]\tLoss: 0.000626\n",
      "Train Epoch: 10 [23680/60000 (39%)]\tLoss: 0.009221\n",
      "Train Epoch: 10 [24320/60000 (41%)]\tLoss: 0.002729\n",
      "Train Epoch: 10 [24960/60000 (42%)]\tLoss: 0.007564\n",
      "Train Epoch: 10 [25600/60000 (43%)]\tLoss: 0.010021\n",
      "Train Epoch: 10 [26240/60000 (44%)]\tLoss: 0.000368\n",
      "Train Epoch: 10 [26880/60000 (45%)]\tLoss: 0.001811\n",
      "Train Epoch: 10 [27520/60000 (46%)]\tLoss: 0.026860\n",
      "Train Epoch: 10 [28160/60000 (47%)]\tLoss: 0.000901\n",
      "Train Epoch: 10 [28800/60000 (48%)]\tLoss: 0.024090\n",
      "Train Epoch: 10 [29440/60000 (49%)]\tLoss: 0.001182\n",
      "Train Epoch: 10 [30080/60000 (50%)]\tLoss: 0.009863\n",
      "Train Epoch: 10 [30720/60000 (51%)]\tLoss: 0.002610\n",
      "Train Epoch: 10 [31360/60000 (52%)]\tLoss: 0.031999\n",
      "Train Epoch: 10 [32000/60000 (53%)]\tLoss: 0.003353\n",
      "Train Epoch: 10 [32640/60000 (54%)]\tLoss: 0.000049\n",
      "Train Epoch: 10 [33280/60000 (55%)]\tLoss: 0.016610\n",
      "Train Epoch: 10 [33920/60000 (57%)]\tLoss: 0.011968\n",
      "Train Epoch: 10 [34560/60000 (58%)]\tLoss: 0.000729\n",
      "Train Epoch: 10 [35200/60000 (59%)]\tLoss: 0.006083\n",
      "Train Epoch: 10 [35840/60000 (60%)]\tLoss: 0.000876\n",
      "Train Epoch: 10 [36480/60000 (61%)]\tLoss: 0.025361\n",
      "Train Epoch: 10 [37120/60000 (62%)]\tLoss: 0.015626\n",
      "Train Epoch: 10 [37760/60000 (63%)]\tLoss: 0.043619\n",
      "Train Epoch: 10 [38400/60000 (64%)]\tLoss: 0.000358\n",
      "Train Epoch: 10 [39040/60000 (65%)]\tLoss: 0.001811\n",
      "Train Epoch: 10 [39680/60000 (66%)]\tLoss: 0.000674\n",
      "Train Epoch: 10 [40320/60000 (67%)]\tLoss: 0.006316\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 10 [40960/60000 (68%)]\tLoss: 0.029844\n",
      "Train Epoch: 10 [41600/60000 (69%)]\tLoss: 0.003413\n",
      "Train Epoch: 10 [42240/60000 (70%)]\tLoss: 0.001004\n",
      "Train Epoch: 10 [42880/60000 (71%)]\tLoss: 0.001284\n",
      "Train Epoch: 10 [43520/60000 (72%)]\tLoss: 0.008435\n",
      "Train Epoch: 10 [44160/60000 (74%)]\tLoss: 0.000366\n",
      "Train Epoch: 10 [44800/60000 (75%)]\tLoss: 0.003186\n",
      "Train Epoch: 10 [45440/60000 (76%)]\tLoss: 0.031276\n",
      "Train Epoch: 10 [46080/60000 (77%)]\tLoss: 0.007551\n",
      "Train Epoch: 10 [46720/60000 (78%)]\tLoss: 0.004646\n",
      "Train Epoch: 10 [47360/60000 (79%)]\tLoss: 0.001402\n",
      "Train Epoch: 10 [48000/60000 (80%)]\tLoss: 0.008663\n",
      "Train Epoch: 10 [48640/60000 (81%)]\tLoss: 0.027820\n",
      "Train Epoch: 10 [49280/60000 (82%)]\tLoss: 0.002759\n",
      "Train Epoch: 10 [49920/60000 (83%)]\tLoss: 0.008343\n",
      "Train Epoch: 10 [50560/60000 (84%)]\tLoss: 0.076657\n",
      "Train Epoch: 10 [51200/60000 (85%)]\tLoss: 0.111776\n",
      "Train Epoch: 10 [51840/60000 (86%)]\tLoss: 0.125800\n",
      "Train Epoch: 10 [52480/60000 (87%)]\tLoss: 0.020978\n",
      "Train Epoch: 10 [53120/60000 (88%)]\tLoss: 0.073465\n",
      "Train Epoch: 10 [53760/60000 (90%)]\tLoss: 0.000659\n",
      "Train Epoch: 10 [54400/60000 (91%)]\tLoss: 0.053892\n",
      "Train Epoch: 10 [55040/60000 (92%)]\tLoss: 0.036875\n",
      "Train Epoch: 10 [55680/60000 (93%)]\tLoss: 0.001626\n",
      "Train Epoch: 10 [56320/60000 (94%)]\tLoss: 0.002156\n",
      "Train Epoch: 10 [56960/60000 (95%)]\tLoss: 0.013339\n",
      "Train Epoch: 10 [57600/60000 (96%)]\tLoss: 0.009662\n",
      "Train Epoch: 10 [58240/60000 (97%)]\tLoss: 0.004321\n",
      "Train Epoch: 10 [58880/60000 (98%)]\tLoss: 0.000857\n",
      "Train Epoch: 10 [59520/60000 (99%)]\tLoss: 0.000833\n",
      "\n",
      "Test set: Avg. loss: 0.0414, Accuracy: 9884/10000 (99%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, n_epochs + 1):\n",
    "  \n",
    "  train(epoch)\n",
    "  test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'negative log likelihood loss')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "plt.plot(train_losses, \"-*\", color='blue')\n",
    "plt.plot(test_losses, \"-^\", color='red')\n",
    "plt.legend(['Train Loss', 'Test Loss'], loc='upper right')\n",
    "plt.xlabel('number of training examples seen')\n",
    "plt.ylabel('negative log likelihood loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/envs/env_pytorch/lib/python3.6/site-packages/ipykernel_launcher.py:31: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "  output = network(example_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "for i in range(5):\n",
    "  plt.subplot(1,5,i+1)\n",
    "  plt.tight_layout()\n",
    "  plt.imshow(example_data[i][0], cmap='gray', interpolation='none')\n",
    "  plt.title(\"Prediction: {}\".format(\n",
    "    output.data.max(1, keepdim=True)[1][i].item()))\n",
    "  plt.xticks([])\n",
    "  plt.yticks([])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's show some examples that the network make wrong predictons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/envs/env_pytorch/lib/python3.6/site-packages/ipykernel_launcher.py:31: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "plt.tight_layout()\n",
    "\n",
    "for data, target in test_loader:\n",
    "      output = network(data)\n",
    "      pred = output.data.max(1, keepdim=True)[1].numpy()\n",
    "      \n",
    "      cnt = len(pred)\n",
    "      for i in range(cnt):\n",
    "            if pred[i].item() != target[i].item():\n",
    "                \n",
    "                plt.imshow(data[i][0], cmap='gray', interpolation='none')\n",
    "                plt.title(\"Prediction: {}, Label: {}\".format(pred[i].item(), target[i].item()))\n",
    "                break\n",
    "      break\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
