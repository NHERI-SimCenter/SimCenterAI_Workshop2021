{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attention Networks Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hand-written digit classification with attention networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this demo, we will show how to build a convolutional neural networks for hand-written digit classification. We will use MNIST as the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set random seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7ffe07131d68>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_seed = 9999\n",
    "torch.backends.cudnn.enabled = False\n",
    "torch.manual_seed(random_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the dataset using Pytorch API. First we load the training set. The training set contains 60000 images and the test set contains 10000 images. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000\n"
     ]
    }
   ],
   "source": [
    "batch_size_train = 64\n",
    "batch_size_test = 1000\n",
    "\n",
    "\n",
    "trainset = torchvision.datasets.MNIST('./', train=True, download=True,\n",
    "                             transform=torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor(),\n",
    "                               torchvision.transforms.Normalize(\n",
    "                                 (0.1307,), (0.3081,))\n",
    "                             ]))\n",
    "\n",
    "print (len(trainset))\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size_train, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n"
     ]
    }
   ],
   "source": [
    "testset = torchvision.datasets.MNIST('./', train=False, download=True,\n",
    "                             transform=torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor(),\n",
    "                               torchvision.transforms.Normalize(\n",
    "                                 (0.1307,), (0.3081,))\n",
    "                             ]))\n",
    "\n",
    "print (len(testset))\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(testset, batch_size=batch_size_test, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's show some example images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = enumerate(test_loader)\n",
    "batch_idx, (example_data, example_targets) = next(examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig = plt.figure()\n",
    "\n",
    "for i in range(5):\n",
    "  plt.subplot(1,5,i+1)\n",
    "  plt.tight_layout()\n",
    "  plt.imshow(example_data[i][0], cmap='gray', interpolation='none')\n",
    "  plt.xticks([])\n",
    "  plt.yticks([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's build a convolutional neural network (CNN) with attention mechanism. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class AttentionNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AttentionNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, padding=1, kernel_size=3)\n",
    "        self.attention1 = nn.Conv2d(1, 1, padding=1, kernel_size=3)\n",
    "        self.conv2 = nn.Conv2d(10, 20, padding=1, kernel_size=3)\n",
    "        self.attention2 = nn.Conv2d(10, 1, padding=1, kernel_size=3)\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(20, 40, padding=1, kernel_size=3)\n",
    "        self.attention3 = nn.Conv2d(20, 1, padding=1, kernel_size=3)\n",
    "        self.conv4 = nn.Conv2d(40, 80, padding=1, kernel_size=3)\n",
    "        self.attention4 = nn.Conv2d(40, 1, padding=1, kernel_size=3)\n",
    "        \n",
    "        self.fc1 = nn.Linear(80, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        attention = F.sigmoid(self.attention1(x))\n",
    "        x = self.conv1(x)\n",
    "        x = x * attention\n",
    "        x = F.relu(F.max_pool2d(x, 2))\n",
    "        \n",
    "        attention = F.sigmoid(self.attention2(x))\n",
    "        x = self.conv2(x)\n",
    "        x = x * attention\n",
    "        x = F.relu(F.max_pool2d(x, 2))\n",
    "        \n",
    "        attention = F.sigmoid(self.attention3(x))\n",
    "        x = self.conv3(x)\n",
    "        x = x * attention\n",
    "        x = F.relu(F.max_pool2d(x, 2))\n",
    "        \n",
    "        attention = F.sigmoid(self.attention4(x))\n",
    "        x = self.conv4(x)\n",
    "        x = x * attention\n",
    "        x = F.relu(F.max_pool2d(x, 2))\n",
    "      \n",
    "\n",
    "        x_ft = x.view(-1, x.size(1) * x.size(2) * x.size(3))\n",
    "        \n",
    "        \n",
    "        x_ft = F.relu(self.fc1(x_ft))\n",
    "        \n",
    "        logits = self.fc2(x_ft)\n",
    "        \n",
    "        return F.log_softmax(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AttentionNet(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (attention1): Conv2d(1, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (attention2): Conv2d(10, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv3): Conv2d(20, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (attention3): Conv2d(20, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv4): Conv2d(40, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (attention4): Conv2d(40, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (fc1): Linear(in_features=80, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "network = AttentionNet()\n",
    "\n",
    "print (network)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For training the network, we need to specify the optimizer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 10\n",
    "learning_rate = 0.01\n",
    "momentum = 0.9\n",
    "log_interval = 10\n",
    "\n",
    "optimizer = optim.SGD(network.parameters(), lr=learning_rate,\n",
    "                      momentum=momentum)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses = []\n",
    "test_losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "  network.train()\n",
    "   \n",
    "  train_loss = 0\n",
    "\n",
    "  for batch_idx, (data, target) in enumerate(train_loader):\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    output = network(data)\n",
    "    loss = F.nll_loss(output, target)\n",
    "    \n",
    "    train_loss += loss.item()\n",
    "    \n",
    "    loss.backward()\n",
    "    \n",
    "    optimizer.step()\n",
    "    \n",
    "    if batch_idx % log_interval == 0:\n",
    "      print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "        epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "        100. * batch_idx / len(train_loader), loss.item()))\n",
    "    \n",
    "  \n",
    "  train_loss /= len(train_loader.dataset)\n",
    "  train_losses.append(train_loss)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "  network.eval()\n",
    "\n",
    "  test_loss = 0\n",
    "  correct = 0\n",
    "  with torch.no_grad():\n",
    "    for data, target in test_loader:\n",
    "      output = network(data)\n",
    "      test_loss += F.nll_loss(output, target, size_average=False).item()\n",
    "      pred = output.data.max(1, keepdim=True)[1]\n",
    "      correct += pred.eq(target.data.view_as(pred)).sum()\n",
    "  \n",
    "  test_loss /= len(test_loader.dataset)\n",
    "  test_losses.append(test_loss)\n",
    "\n",
    "  print('\\nTest set: Avg. loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "    test_loss, correct, len(test_loader.dataset),\n",
    "    100. * correct / len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yunhui.guo/.local/lib/python3.6/site-packages/torch/nn/functional.py:1805: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
      "/Users/yunhui.guo/.local/lib/python3.6/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  ../c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n",
      "/usr/local/anaconda3/envs/env_pytorch/lib/python3.6/site-packages/ipykernel_launcher.py:47: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.307003\n",
      "Train Epoch: 1 [640/60000 (1%)]\tLoss: 2.303166\n",
      "Train Epoch: 1 [1280/60000 (2%)]\tLoss: 2.314470\n",
      "Train Epoch: 1 [1920/60000 (3%)]\tLoss: 2.295414\n",
      "Train Epoch: 1 [2560/60000 (4%)]\tLoss: 2.299490\n",
      "Train Epoch: 1 [3200/60000 (5%)]\tLoss: 2.302544\n",
      "Train Epoch: 1 [3840/60000 (6%)]\tLoss: 2.304816\n",
      "Train Epoch: 1 [4480/60000 (7%)]\tLoss: 2.310052\n",
      "Train Epoch: 1 [5120/60000 (9%)]\tLoss: 2.307564\n",
      "Train Epoch: 1 [5760/60000 (10%)]\tLoss: 2.310531\n",
      "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 2.295472\n",
      "Train Epoch: 1 [7040/60000 (12%)]\tLoss: 2.302694\n",
      "Train Epoch: 1 [7680/60000 (13%)]\tLoss: 2.298516\n",
      "Train Epoch: 1 [8320/60000 (14%)]\tLoss: 2.308739\n",
      "Train Epoch: 1 [8960/60000 (15%)]\tLoss: 2.297976\n",
      "Train Epoch: 1 [9600/60000 (16%)]\tLoss: 2.298272\n",
      "Train Epoch: 1 [10240/60000 (17%)]\tLoss: 2.301678\n",
      "Train Epoch: 1 [10880/60000 (18%)]\tLoss: 2.305990\n",
      "Train Epoch: 1 [11520/60000 (19%)]\tLoss: 2.289377\n",
      "Train Epoch: 1 [12160/60000 (20%)]\tLoss: 2.303491\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 2.305940\n",
      "Train Epoch: 1 [13440/60000 (22%)]\tLoss: 2.297874\n",
      "Train Epoch: 1 [14080/60000 (23%)]\tLoss: 2.309230\n",
      "Train Epoch: 1 [14720/60000 (25%)]\tLoss: 2.305332\n",
      "Train Epoch: 1 [15360/60000 (26%)]\tLoss: 2.307415\n",
      "Train Epoch: 1 [16000/60000 (27%)]\tLoss: 2.295276\n",
      "Train Epoch: 1 [16640/60000 (28%)]\tLoss: 2.300873\n",
      "Train Epoch: 1 [17280/60000 (29%)]\tLoss: 2.307125\n",
      "Train Epoch: 1 [17920/60000 (30%)]\tLoss: 2.301940\n",
      "Train Epoch: 1 [18560/60000 (31%)]\tLoss: 2.292106\n",
      "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 2.295089\n",
      "Train Epoch: 1 [19840/60000 (33%)]\tLoss: 2.298420\n",
      "Train Epoch: 1 [20480/60000 (34%)]\tLoss: 2.305959\n",
      "Train Epoch: 1 [21120/60000 (35%)]\tLoss: 2.300928\n",
      "Train Epoch: 1 [21760/60000 (36%)]\tLoss: 2.308806\n",
      "Train Epoch: 1 [22400/60000 (37%)]\tLoss: 2.302476\n",
      "Train Epoch: 1 [23040/60000 (38%)]\tLoss: 2.295760\n",
      "Train Epoch: 1 [23680/60000 (39%)]\tLoss: 2.301161\n",
      "Train Epoch: 1 [24320/60000 (41%)]\tLoss: 2.309997\n",
      "Train Epoch: 1 [24960/60000 (42%)]\tLoss: 2.305882\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 2.303034\n",
      "Train Epoch: 1 [26240/60000 (44%)]\tLoss: 2.299646\n",
      "Train Epoch: 1 [26880/60000 (45%)]\tLoss: 2.303022\n",
      "Train Epoch: 1 [27520/60000 (46%)]\tLoss: 2.301132\n",
      "Train Epoch: 1 [28160/60000 (47%)]\tLoss: 2.295521\n",
      "Train Epoch: 1 [28800/60000 (48%)]\tLoss: 2.294733\n",
      "Train Epoch: 1 [29440/60000 (49%)]\tLoss: 2.293258\n",
      "Train Epoch: 1 [30080/60000 (50%)]\tLoss: 2.296513\n",
      "Train Epoch: 1 [30720/60000 (51%)]\tLoss: 2.300264\n",
      "Train Epoch: 1 [31360/60000 (52%)]\tLoss: 2.282398\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 2.290173\n",
      "Train Epoch: 1 [32640/60000 (54%)]\tLoss: 2.295632\n",
      "Train Epoch: 1 [33280/60000 (55%)]\tLoss: 2.291162\n",
      "Train Epoch: 1 [33920/60000 (57%)]\tLoss: 2.285161\n",
      "Train Epoch: 1 [34560/60000 (58%)]\tLoss: 2.304760\n",
      "Train Epoch: 1 [35200/60000 (59%)]\tLoss: 2.259935\n",
      "Train Epoch: 1 [35840/60000 (60%)]\tLoss: 2.229396\n",
      "Train Epoch: 1 [36480/60000 (61%)]\tLoss: 2.194709\n",
      "Train Epoch: 1 [37120/60000 (62%)]\tLoss: 2.103811\n",
      "Train Epoch: 1 [37760/60000 (63%)]\tLoss: 1.856299\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 1.411759\n",
      "Train Epoch: 1 [39040/60000 (65%)]\tLoss: 1.307515\n",
      "Train Epoch: 1 [39680/60000 (66%)]\tLoss: 0.889026\n",
      "Train Epoch: 1 [40320/60000 (67%)]\tLoss: 1.108271\n",
      "Train Epoch: 1 [40960/60000 (68%)]\tLoss: 0.893172\n",
      "Train Epoch: 1 [41600/60000 (69%)]\tLoss: 0.823537\n",
      "Train Epoch: 1 [42240/60000 (70%)]\tLoss: 0.335449\n",
      "Train Epoch: 1 [42880/60000 (71%)]\tLoss: 0.518755\n",
      "Train Epoch: 1 [43520/60000 (72%)]\tLoss: 0.467374\n",
      "Train Epoch: 1 [44160/60000 (74%)]\tLoss: 0.647445\n",
      "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.169541\n",
      "Train Epoch: 1 [45440/60000 (76%)]\tLoss: 0.272067\n",
      "Train Epoch: 1 [46080/60000 (77%)]\tLoss: 0.241624\n",
      "Train Epoch: 1 [46720/60000 (78%)]\tLoss: 0.497697\n",
      "Train Epoch: 1 [47360/60000 (79%)]\tLoss: 0.449603\n",
      "Train Epoch: 1 [48000/60000 (80%)]\tLoss: 0.157079\n",
      "Train Epoch: 1 [48640/60000 (81%)]\tLoss: 0.559467\n",
      "Train Epoch: 1 [49280/60000 (82%)]\tLoss: 0.253128\n",
      "Train Epoch: 1 [49920/60000 (83%)]\tLoss: 0.109485\n",
      "Train Epoch: 1 [50560/60000 (84%)]\tLoss: 0.123263\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.167175\n",
      "Train Epoch: 1 [51840/60000 (86%)]\tLoss: 0.126715\n",
      "Train Epoch: 1 [52480/60000 (87%)]\tLoss: 0.198310\n",
      "Train Epoch: 1 [53120/60000 (88%)]\tLoss: 0.158712\n",
      "Train Epoch: 1 [53760/60000 (90%)]\tLoss: 0.395457\n",
      "Train Epoch: 1 [54400/60000 (91%)]\tLoss: 0.172911\n",
      "Train Epoch: 1 [55040/60000 (92%)]\tLoss: 0.298931\n",
      "Train Epoch: 1 [55680/60000 (93%)]\tLoss: 0.144380\n",
      "Train Epoch: 1 [56320/60000 (94%)]\tLoss: 0.156287\n",
      "Train Epoch: 1 [56960/60000 (95%)]\tLoss: 0.176060\n",
      "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.201401\n",
      "Train Epoch: 1 [58240/60000 (97%)]\tLoss: 0.149235\n",
      "Train Epoch: 1 [58880/60000 (98%)]\tLoss: 0.116779\n",
      "Train Epoch: 1 [59520/60000 (99%)]\tLoss: 0.112743\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yunhui.guo/.local/lib/python3.6/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.1364, Accuracy: 9577/10000 (96%)\n",
      "\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.078946\n",
      "Train Epoch: 2 [640/60000 (1%)]\tLoss: 0.056543\n",
      "Train Epoch: 2 [1280/60000 (2%)]\tLoss: 0.193235\n",
      "Train Epoch: 2 [1920/60000 (3%)]\tLoss: 0.091801\n",
      "Train Epoch: 2 [2560/60000 (4%)]\tLoss: 0.349144\n",
      "Train Epoch: 2 [3200/60000 (5%)]\tLoss: 0.167716\n",
      "Train Epoch: 2 [3840/60000 (6%)]\tLoss: 0.209072\n",
      "Train Epoch: 2 [4480/60000 (7%)]\tLoss: 0.089207\n",
      "Train Epoch: 2 [5120/60000 (9%)]\tLoss: 0.232926\n",
      "Train Epoch: 2 [5760/60000 (10%)]\tLoss: 0.173032\n",
      "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 0.169245\n",
      "Train Epoch: 2 [7040/60000 (12%)]\tLoss: 0.049301\n",
      "Train Epoch: 2 [7680/60000 (13%)]\tLoss: 0.070981\n",
      "Train Epoch: 2 [8320/60000 (14%)]\tLoss: 0.136534\n",
      "Train Epoch: 2 [8960/60000 (15%)]\tLoss: 0.092960\n",
      "Train Epoch: 2 [9600/60000 (16%)]\tLoss: 0.046221\n",
      "Train Epoch: 2 [10240/60000 (17%)]\tLoss: 0.089420\n",
      "Train Epoch: 2 [10880/60000 (18%)]\tLoss: 0.247924\n",
      "Train Epoch: 2 [11520/60000 (19%)]\tLoss: 0.120276\n",
      "Train Epoch: 2 [12160/60000 (20%)]\tLoss: 0.053255\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.300353\n",
      "Train Epoch: 2 [13440/60000 (22%)]\tLoss: 0.142027\n",
      "Train Epoch: 2 [14080/60000 (23%)]\tLoss: 0.070555\n",
      "Train Epoch: 2 [14720/60000 (25%)]\tLoss: 0.232715\n",
      "Train Epoch: 2 [15360/60000 (26%)]\tLoss: 0.108347\n",
      "Train Epoch: 2 [16000/60000 (27%)]\tLoss: 0.042822\n",
      "Train Epoch: 2 [16640/60000 (28%)]\tLoss: 0.149815\n",
      "Train Epoch: 2 [17280/60000 (29%)]\tLoss: 0.394718\n",
      "Train Epoch: 2 [17920/60000 (30%)]\tLoss: 0.088312\n",
      "Train Epoch: 2 [18560/60000 (31%)]\tLoss: 0.071222\n",
      "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 0.024028\n",
      "Train Epoch: 2 [19840/60000 (33%)]\tLoss: 0.077572\n",
      "Train Epoch: 2 [20480/60000 (34%)]\tLoss: 0.141254\n",
      "Train Epoch: 2 [21120/60000 (35%)]\tLoss: 0.108234\n",
      "Train Epoch: 2 [21760/60000 (36%)]\tLoss: 0.099348\n",
      "Train Epoch: 2 [22400/60000 (37%)]\tLoss: 0.244848\n",
      "Train Epoch: 2 [23040/60000 (38%)]\tLoss: 0.052276\n",
      "Train Epoch: 2 [23680/60000 (39%)]\tLoss: 0.107275\n",
      "Train Epoch: 2 [24320/60000 (41%)]\tLoss: 0.093430\n",
      "Train Epoch: 2 [24960/60000 (42%)]\tLoss: 0.071619\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.035415\n",
      "Train Epoch: 2 [26240/60000 (44%)]\tLoss: 0.119467\n",
      "Train Epoch: 2 [26880/60000 (45%)]\tLoss: 0.027832\n",
      "Train Epoch: 2 [27520/60000 (46%)]\tLoss: 0.033677\n",
      "Train Epoch: 2 [28160/60000 (47%)]\tLoss: 0.068288\n",
      "Train Epoch: 2 [28800/60000 (48%)]\tLoss: 0.136292\n",
      "Train Epoch: 2 [29440/60000 (49%)]\tLoss: 0.069006\n",
      "Train Epoch: 2 [30080/60000 (50%)]\tLoss: 0.080265\n",
      "Train Epoch: 2 [30720/60000 (51%)]\tLoss: 0.055972\n",
      "Train Epoch: 2 [31360/60000 (52%)]\tLoss: 0.256638\n",
      "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.025119\n",
      "Train Epoch: 2 [32640/60000 (54%)]\tLoss: 0.175002\n",
      "Train Epoch: 2 [33280/60000 (55%)]\tLoss: 0.195943\n",
      "Train Epoch: 2 [33920/60000 (57%)]\tLoss: 0.136158\n",
      "Train Epoch: 2 [34560/60000 (58%)]\tLoss: 0.080009\n",
      "Train Epoch: 2 [35200/60000 (59%)]\tLoss: 0.041324\n",
      "Train Epoch: 2 [35840/60000 (60%)]\tLoss: 0.133479\n",
      "Train Epoch: 2 [36480/60000 (61%)]\tLoss: 0.102645\n",
      "Train Epoch: 2 [37120/60000 (62%)]\tLoss: 0.148486\n",
      "Train Epoch: 2 [37760/60000 (63%)]\tLoss: 0.048906\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.070744\n",
      "Train Epoch: 2 [39040/60000 (65%)]\tLoss: 0.072360\n",
      "Train Epoch: 2 [39680/60000 (66%)]\tLoss: 0.012731\n",
      "Train Epoch: 2 [40320/60000 (67%)]\tLoss: 0.050149\n",
      "Train Epoch: 2 [40960/60000 (68%)]\tLoss: 0.097482\n",
      "Train Epoch: 2 [41600/60000 (69%)]\tLoss: 0.145929\n",
      "Train Epoch: 2 [42240/60000 (70%)]\tLoss: 0.026577\n",
      "Train Epoch: 2 [42880/60000 (71%)]\tLoss: 0.092888\n",
      "Train Epoch: 2 [43520/60000 (72%)]\tLoss: 0.136378\n",
      "Train Epoch: 2 [44160/60000 (74%)]\tLoss: 0.084324\n",
      "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 0.088755\n",
      "Train Epoch: 2 [45440/60000 (76%)]\tLoss: 0.015934\n",
      "Train Epoch: 2 [46080/60000 (77%)]\tLoss: 0.006336\n",
      "Train Epoch: 2 [46720/60000 (78%)]\tLoss: 0.102871\n",
      "Train Epoch: 2 [47360/60000 (79%)]\tLoss: 0.042241\n",
      "Train Epoch: 2 [48000/60000 (80%)]\tLoss: 0.033211\n",
      "Train Epoch: 2 [48640/60000 (81%)]\tLoss: 0.014495\n",
      "Train Epoch: 2 [49280/60000 (82%)]\tLoss: 0.075586\n",
      "Train Epoch: 2 [49920/60000 (83%)]\tLoss: 0.102954\n",
      "Train Epoch: 2 [50560/60000 (84%)]\tLoss: 0.015624\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.082452\n",
      "Train Epoch: 2 [51840/60000 (86%)]\tLoss: 0.030942\n",
      "Train Epoch: 2 [52480/60000 (87%)]\tLoss: 0.020319\n",
      "Train Epoch: 2 [53120/60000 (88%)]\tLoss: 0.057249\n",
      "Train Epoch: 2 [53760/60000 (90%)]\tLoss: 0.037130\n",
      "Train Epoch: 2 [54400/60000 (91%)]\tLoss: 0.093793\n",
      "Train Epoch: 2 [55040/60000 (92%)]\tLoss: 0.072242\n",
      "Train Epoch: 2 [55680/60000 (93%)]\tLoss: 0.099795\n",
      "Train Epoch: 2 [56320/60000 (94%)]\tLoss: 0.026579\n",
      "Train Epoch: 2 [56960/60000 (95%)]\tLoss: 0.015712\n",
      "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 0.151391\n",
      "Train Epoch: 2 [58240/60000 (97%)]\tLoss: 0.092984\n",
      "Train Epoch: 2 [58880/60000 (98%)]\tLoss: 0.041683\n",
      "Train Epoch: 2 [59520/60000 (99%)]\tLoss: 0.015860\n",
      "\n",
      "Test set: Avg. loss: 0.0711, Accuracy: 9785/10000 (98%)\n",
      "\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.032247\n",
      "Train Epoch: 3 [640/60000 (1%)]\tLoss: 0.053489\n",
      "Train Epoch: 3 [1280/60000 (2%)]\tLoss: 0.015450\n",
      "Train Epoch: 3 [1920/60000 (3%)]\tLoss: 0.249020\n",
      "Train Epoch: 3 [2560/60000 (4%)]\tLoss: 0.082298\n",
      "Train Epoch: 3 [3200/60000 (5%)]\tLoss: 0.121479\n",
      "Train Epoch: 3 [3840/60000 (6%)]\tLoss: 0.046500\n",
      "Train Epoch: 3 [4480/60000 (7%)]\tLoss: 0.051485\n",
      "Train Epoch: 3 [5120/60000 (9%)]\tLoss: 0.035934\n",
      "Train Epoch: 3 [5760/60000 (10%)]\tLoss: 0.118655\n",
      "Train Epoch: 3 [6400/60000 (11%)]\tLoss: 0.217356\n",
      "Train Epoch: 3 [7040/60000 (12%)]\tLoss: 0.069066\n",
      "Train Epoch: 3 [7680/60000 (13%)]\tLoss: 0.003605\n",
      "Train Epoch: 3 [8320/60000 (14%)]\tLoss: 0.113753\n",
      "Train Epoch: 3 [8960/60000 (15%)]\tLoss: 0.108524\n",
      "Train Epoch: 3 [9600/60000 (16%)]\tLoss: 0.100480\n",
      "Train Epoch: 3 [10240/60000 (17%)]\tLoss: 0.063023\n",
      "Train Epoch: 3 [10880/60000 (18%)]\tLoss: 0.057568\n",
      "Train Epoch: 3 [11520/60000 (19%)]\tLoss: 0.127431\n",
      "Train Epoch: 3 [12160/60000 (20%)]\tLoss: 0.104638\n",
      "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.029072\n",
      "Train Epoch: 3 [13440/60000 (22%)]\tLoss: 0.031082\n",
      "Train Epoch: 3 [14080/60000 (23%)]\tLoss: 0.027945\n",
      "Train Epoch: 3 [14720/60000 (25%)]\tLoss: 0.125524\n",
      "Train Epoch: 3 [15360/60000 (26%)]\tLoss: 0.010157\n",
      "Train Epoch: 3 [16000/60000 (27%)]\tLoss: 0.172606\n",
      "Train Epoch: 3 [16640/60000 (28%)]\tLoss: 0.040744\n",
      "Train Epoch: 3 [17280/60000 (29%)]\tLoss: 0.052872\n",
      "Train Epoch: 3 [17920/60000 (30%)]\tLoss: 0.071517\n",
      "Train Epoch: 3 [18560/60000 (31%)]\tLoss: 0.084961\n",
      "Train Epoch: 3 [19200/60000 (32%)]\tLoss: 0.020949\n",
      "Train Epoch: 3 [19840/60000 (33%)]\tLoss: 0.017863\n",
      "Train Epoch: 3 [20480/60000 (34%)]\tLoss: 0.013361\n",
      "Train Epoch: 3 [21120/60000 (35%)]\tLoss: 0.058234\n",
      "Train Epoch: 3 [21760/60000 (36%)]\tLoss: 0.116996\n",
      "Train Epoch: 3 [22400/60000 (37%)]\tLoss: 0.027085\n",
      "Train Epoch: 3 [23040/60000 (38%)]\tLoss: 0.110002\n",
      "Train Epoch: 3 [23680/60000 (39%)]\tLoss: 0.011735\n",
      "Train Epoch: 3 [24320/60000 (41%)]\tLoss: 0.044638\n",
      "Train Epoch: 3 [24960/60000 (42%)]\tLoss: 0.006325\n",
      "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.011951\n",
      "Train Epoch: 3 [26240/60000 (44%)]\tLoss: 0.066120\n",
      "Train Epoch: 3 [26880/60000 (45%)]\tLoss: 0.036419\n",
      "Train Epoch: 3 [27520/60000 (46%)]\tLoss: 0.048576\n",
      "Train Epoch: 3 [28160/60000 (47%)]\tLoss: 0.077484\n",
      "Train Epoch: 3 [28800/60000 (48%)]\tLoss: 0.019494\n",
      "Train Epoch: 3 [29440/60000 (49%)]\tLoss: 0.041264\n",
      "Train Epoch: 3 [30080/60000 (50%)]\tLoss: 0.008716\n",
      "Train Epoch: 3 [30720/60000 (51%)]\tLoss: 0.065629\n",
      "Train Epoch: 3 [31360/60000 (52%)]\tLoss: 0.013833\n",
      "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.010879\n",
      "Train Epoch: 3 [32640/60000 (54%)]\tLoss: 0.005993\n",
      "Train Epoch: 3 [33280/60000 (55%)]\tLoss: 0.054590\n",
      "Train Epoch: 3 [33920/60000 (57%)]\tLoss: 0.141043\n",
      "Train Epoch: 3 [34560/60000 (58%)]\tLoss: 0.081887\n",
      "Train Epoch: 3 [35200/60000 (59%)]\tLoss: 0.165535\n",
      "Train Epoch: 3 [35840/60000 (60%)]\tLoss: 0.017509\n",
      "Train Epoch: 3 [36480/60000 (61%)]\tLoss: 0.117347\n",
      "Train Epoch: 3 [37120/60000 (62%)]\tLoss: 0.056888\n",
      "Train Epoch: 3 [37760/60000 (63%)]\tLoss: 0.036216\n",
      "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.148762\n",
      "Train Epoch: 3 [39040/60000 (65%)]\tLoss: 0.022032\n",
      "Train Epoch: 3 [39680/60000 (66%)]\tLoss: 0.091649\n",
      "Train Epoch: 3 [40320/60000 (67%)]\tLoss: 0.007502\n",
      "Train Epoch: 3 [40960/60000 (68%)]\tLoss: 0.200737\n",
      "Train Epoch: 3 [41600/60000 (69%)]\tLoss: 0.060785\n",
      "Train Epoch: 3 [42240/60000 (70%)]\tLoss: 0.005226\n",
      "Train Epoch: 3 [42880/60000 (71%)]\tLoss: 0.130883\n",
      "Train Epoch: 3 [43520/60000 (72%)]\tLoss: 0.023507\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 3 [44160/60000 (74%)]\tLoss: 0.040483\n",
      "Train Epoch: 3 [44800/60000 (75%)]\tLoss: 0.047835\n",
      "Train Epoch: 3 [45440/60000 (76%)]\tLoss: 0.019464\n",
      "Train Epoch: 3 [46080/60000 (77%)]\tLoss: 0.058639\n",
      "Train Epoch: 3 [46720/60000 (78%)]\tLoss: 0.043236\n",
      "Train Epoch: 3 [47360/60000 (79%)]\tLoss: 0.079186\n",
      "Train Epoch: 3 [48000/60000 (80%)]\tLoss: 0.021618\n",
      "Train Epoch: 3 [48640/60000 (81%)]\tLoss: 0.042534\n",
      "Train Epoch: 3 [49280/60000 (82%)]\tLoss: 0.007081\n",
      "Train Epoch: 3 [49920/60000 (83%)]\tLoss: 0.061085\n",
      "Train Epoch: 3 [50560/60000 (84%)]\tLoss: 0.078572\n",
      "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.114743\n",
      "Train Epoch: 3 [51840/60000 (86%)]\tLoss: 0.096931\n",
      "Train Epoch: 3 [52480/60000 (87%)]\tLoss: 0.033428\n",
      "Train Epoch: 3 [53120/60000 (88%)]\tLoss: 0.076544\n",
      "Train Epoch: 3 [53760/60000 (90%)]\tLoss: 0.073259\n",
      "Train Epoch: 3 [54400/60000 (91%)]\tLoss: 0.046346\n",
      "Train Epoch: 3 [55040/60000 (92%)]\tLoss: 0.024972\n",
      "Train Epoch: 3 [55680/60000 (93%)]\tLoss: 0.022198\n",
      "Train Epoch: 3 [56320/60000 (94%)]\tLoss: 0.123923\n",
      "Train Epoch: 3 [56960/60000 (95%)]\tLoss: 0.014705\n",
      "Train Epoch: 3 [57600/60000 (96%)]\tLoss: 0.060432\n",
      "Train Epoch: 3 [58240/60000 (97%)]\tLoss: 0.058158\n",
      "Train Epoch: 3 [58880/60000 (98%)]\tLoss: 0.035141\n",
      "Train Epoch: 3 [59520/60000 (99%)]\tLoss: 0.007421\n",
      "\n",
      "Test set: Avg. loss: 0.0422, Accuracy: 9855/10000 (99%)\n",
      "\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.017211\n",
      "Train Epoch: 4 [640/60000 (1%)]\tLoss: 0.100185\n",
      "Train Epoch: 4 [1280/60000 (2%)]\tLoss: 0.012642\n",
      "Train Epoch: 4 [1920/60000 (3%)]\tLoss: 0.013408\n",
      "Train Epoch: 4 [2560/60000 (4%)]\tLoss: 0.007456\n",
      "Train Epoch: 4 [3200/60000 (5%)]\tLoss: 0.020695\n",
      "Train Epoch: 4 [3840/60000 (6%)]\tLoss: 0.031134\n",
      "Train Epoch: 4 [4480/60000 (7%)]\tLoss: 0.017972\n",
      "Train Epoch: 4 [5120/60000 (9%)]\tLoss: 0.015381\n",
      "Train Epoch: 4 [5760/60000 (10%)]\tLoss: 0.020685\n",
      "Train Epoch: 4 [6400/60000 (11%)]\tLoss: 0.028535\n",
      "Train Epoch: 4 [7040/60000 (12%)]\tLoss: 0.006961\n",
      "Train Epoch: 4 [7680/60000 (13%)]\tLoss: 0.185183\n",
      "Train Epoch: 4 [8320/60000 (14%)]\tLoss: 0.091050\n",
      "Train Epoch: 4 [8960/60000 (15%)]\tLoss: 0.032936\n",
      "Train Epoch: 4 [9600/60000 (16%)]\tLoss: 0.090035\n",
      "Train Epoch: 4 [10240/60000 (17%)]\tLoss: 0.095664\n",
      "Train Epoch: 4 [10880/60000 (18%)]\tLoss: 0.029573\n",
      "Train Epoch: 4 [11520/60000 (19%)]\tLoss: 0.008799\n",
      "Train Epoch: 4 [12160/60000 (20%)]\tLoss: 0.004450\n",
      "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 0.033463\n",
      "Train Epoch: 4 [13440/60000 (22%)]\tLoss: 0.010067\n",
      "Train Epoch: 4 [14080/60000 (23%)]\tLoss: 0.123824\n",
      "Train Epoch: 4 [14720/60000 (25%)]\tLoss: 0.058162\n",
      "Train Epoch: 4 [15360/60000 (26%)]\tLoss: 0.078651\n",
      "Train Epoch: 4 [16000/60000 (27%)]\tLoss: 0.042900\n",
      "Train Epoch: 4 [16640/60000 (28%)]\tLoss: 0.107314\n",
      "Train Epoch: 4 [17280/60000 (29%)]\tLoss: 0.047516\n",
      "Train Epoch: 4 [17920/60000 (30%)]\tLoss: 0.063404\n",
      "Train Epoch: 4 [18560/60000 (31%)]\tLoss: 0.009635\n",
      "Train Epoch: 4 [19200/60000 (32%)]\tLoss: 0.026059\n",
      "Train Epoch: 4 [19840/60000 (33%)]\tLoss: 0.069707\n",
      "Train Epoch: 4 [20480/60000 (34%)]\tLoss: 0.025612\n",
      "Train Epoch: 4 [21120/60000 (35%)]\tLoss: 0.003161\n",
      "Train Epoch: 4 [21760/60000 (36%)]\tLoss: 0.003072\n",
      "Train Epoch: 4 [22400/60000 (37%)]\tLoss: 0.013415\n",
      "Train Epoch: 4 [23040/60000 (38%)]\tLoss: 0.026794\n",
      "Train Epoch: 4 [23680/60000 (39%)]\tLoss: 0.019497\n",
      "Train Epoch: 4 [24320/60000 (41%)]\tLoss: 0.073917\n",
      "Train Epoch: 4 [24960/60000 (42%)]\tLoss: 0.020226\n",
      "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 0.014316\n",
      "Train Epoch: 4 [26240/60000 (44%)]\tLoss: 0.045392\n",
      "Train Epoch: 4 [26880/60000 (45%)]\tLoss: 0.112447\n",
      "Train Epoch: 4 [27520/60000 (46%)]\tLoss: 0.034657\n",
      "Train Epoch: 4 [28160/60000 (47%)]\tLoss: 0.146426\n",
      "Train Epoch: 4 [28800/60000 (48%)]\tLoss: 0.211310\n",
      "Train Epoch: 4 [29440/60000 (49%)]\tLoss: 0.011960\n",
      "Train Epoch: 4 [30080/60000 (50%)]\tLoss: 0.028654\n",
      "Train Epoch: 4 [30720/60000 (51%)]\tLoss: 0.011397\n",
      "Train Epoch: 4 [31360/60000 (52%)]\tLoss: 0.002203\n",
      "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 0.095067\n",
      "Train Epoch: 4 [32640/60000 (54%)]\tLoss: 0.022965\n",
      "Train Epoch: 4 [33280/60000 (55%)]\tLoss: 0.023497\n",
      "Train Epoch: 4 [33920/60000 (57%)]\tLoss: 0.043522\n",
      "Train Epoch: 4 [34560/60000 (58%)]\tLoss: 0.046702\n",
      "Train Epoch: 4 [35200/60000 (59%)]\tLoss: 0.049107\n",
      "Train Epoch: 4 [35840/60000 (60%)]\tLoss: 0.025678\n",
      "Train Epoch: 4 [36480/60000 (61%)]\tLoss: 0.090866\n",
      "Train Epoch: 4 [37120/60000 (62%)]\tLoss: 0.098699\n",
      "Train Epoch: 4 [37760/60000 (63%)]\tLoss: 0.012737\n",
      "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 0.040444\n",
      "Train Epoch: 4 [39040/60000 (65%)]\tLoss: 0.015757\n",
      "Train Epoch: 4 [39680/60000 (66%)]\tLoss: 0.067173\n",
      "Train Epoch: 4 [40320/60000 (67%)]\tLoss: 0.087648\n",
      "Train Epoch: 4 [40960/60000 (68%)]\tLoss: 0.058417\n",
      "Train Epoch: 4 [41600/60000 (69%)]\tLoss: 0.047354\n",
      "Train Epoch: 4 [42240/60000 (70%)]\tLoss: 0.041724\n",
      "Train Epoch: 4 [42880/60000 (71%)]\tLoss: 0.022536\n",
      "Train Epoch: 4 [43520/60000 (72%)]\tLoss: 0.007708\n",
      "Train Epoch: 4 [44160/60000 (74%)]\tLoss: 0.021058\n",
      "Train Epoch: 4 [44800/60000 (75%)]\tLoss: 0.083364\n",
      "Train Epoch: 4 [45440/60000 (76%)]\tLoss: 0.042719\n",
      "Train Epoch: 4 [46080/60000 (77%)]\tLoss: 0.015403\n",
      "Train Epoch: 4 [46720/60000 (78%)]\tLoss: 0.141230\n",
      "Train Epoch: 4 [47360/60000 (79%)]\tLoss: 0.026307\n",
      "Train Epoch: 4 [48000/60000 (80%)]\tLoss: 0.086925\n",
      "Train Epoch: 4 [48640/60000 (81%)]\tLoss: 0.002818\n",
      "Train Epoch: 4 [49280/60000 (82%)]\tLoss: 0.015857\n",
      "Train Epoch: 4 [49920/60000 (83%)]\tLoss: 0.006021\n",
      "Train Epoch: 4 [50560/60000 (84%)]\tLoss: 0.035658\n",
      "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.080237\n",
      "Train Epoch: 4 [51840/60000 (86%)]\tLoss: 0.041696\n",
      "Train Epoch: 4 [52480/60000 (87%)]\tLoss: 0.012326\n",
      "Train Epoch: 4 [53120/60000 (88%)]\tLoss: 0.013428\n",
      "Train Epoch: 4 [53760/60000 (90%)]\tLoss: 0.006367\n",
      "Train Epoch: 4 [54400/60000 (91%)]\tLoss: 0.045797\n",
      "Train Epoch: 4 [55040/60000 (92%)]\tLoss: 0.014699\n",
      "Train Epoch: 4 [55680/60000 (93%)]\tLoss: 0.022386\n",
      "Train Epoch: 4 [56320/60000 (94%)]\tLoss: 0.057727\n",
      "Train Epoch: 4 [56960/60000 (95%)]\tLoss: 0.002484\n",
      "Train Epoch: 4 [57600/60000 (96%)]\tLoss: 0.007333\n",
      "Train Epoch: 4 [58240/60000 (97%)]\tLoss: 0.051251\n",
      "Train Epoch: 4 [58880/60000 (98%)]\tLoss: 0.008489\n",
      "Train Epoch: 4 [59520/60000 (99%)]\tLoss: 0.003036\n",
      "\n",
      "Test set: Avg. loss: 0.0420, Accuracy: 9875/10000 (99%)\n",
      "\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.117862\n",
      "Train Epoch: 5 [640/60000 (1%)]\tLoss: 0.009033\n",
      "Train Epoch: 5 [1280/60000 (2%)]\tLoss: 0.006634\n",
      "Train Epoch: 5 [1920/60000 (3%)]\tLoss: 0.004104\n",
      "Train Epoch: 5 [2560/60000 (4%)]\tLoss: 0.012951\n",
      "Train Epoch: 5 [3200/60000 (5%)]\tLoss: 0.017902\n",
      "Train Epoch: 5 [3840/60000 (6%)]\tLoss: 0.005856\n",
      "Train Epoch: 5 [4480/60000 (7%)]\tLoss: 0.068515\n",
      "Train Epoch: 5 [5120/60000 (9%)]\tLoss: 0.063185\n",
      "Train Epoch: 5 [5760/60000 (10%)]\tLoss: 0.016986\n",
      "Train Epoch: 5 [6400/60000 (11%)]\tLoss: 0.036966\n",
      "Train Epoch: 5 [7040/60000 (12%)]\tLoss: 0.003092\n",
      "Train Epoch: 5 [7680/60000 (13%)]\tLoss: 0.082840\n",
      "Train Epoch: 5 [8320/60000 (14%)]\tLoss: 0.065069\n",
      "Train Epoch: 5 [8960/60000 (15%)]\tLoss: 0.064540\n",
      "Train Epoch: 5 [9600/60000 (16%)]\tLoss: 0.049550\n",
      "Train Epoch: 5 [10240/60000 (17%)]\tLoss: 0.018213\n",
      "Train Epoch: 5 [10880/60000 (18%)]\tLoss: 0.030294\n",
      "Train Epoch: 5 [11520/60000 (19%)]\tLoss: 0.039423\n",
      "Train Epoch: 5 [12160/60000 (20%)]\tLoss: 0.006191\n",
      "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 0.038911\n",
      "Train Epoch: 5 [13440/60000 (22%)]\tLoss: 0.018526\n",
      "Train Epoch: 5 [14080/60000 (23%)]\tLoss: 0.004769\n",
      "Train Epoch: 5 [14720/60000 (25%)]\tLoss: 0.056270\n",
      "Train Epoch: 5 [15360/60000 (26%)]\tLoss: 0.003082\n",
      "Train Epoch: 5 [16000/60000 (27%)]\tLoss: 0.064755\n",
      "Train Epoch: 5 [16640/60000 (28%)]\tLoss: 0.005692\n",
      "Train Epoch: 5 [17280/60000 (29%)]\tLoss: 0.028947\n",
      "Train Epoch: 5 [17920/60000 (30%)]\tLoss: 0.015394\n",
      "Train Epoch: 5 [18560/60000 (31%)]\tLoss: 0.080645\n",
      "Train Epoch: 5 [19200/60000 (32%)]\tLoss: 0.040442\n",
      "Train Epoch: 5 [19840/60000 (33%)]\tLoss: 0.092185\n",
      "Train Epoch: 5 [20480/60000 (34%)]\tLoss: 0.044189\n",
      "Train Epoch: 5 [21120/60000 (35%)]\tLoss: 0.070163\n",
      "Train Epoch: 5 [21760/60000 (36%)]\tLoss: 0.056006\n",
      "Train Epoch: 5 [22400/60000 (37%)]\tLoss: 0.026150\n",
      "Train Epoch: 5 [23040/60000 (38%)]\tLoss: 0.056841\n",
      "Train Epoch: 5 [23680/60000 (39%)]\tLoss: 0.109417\n",
      "Train Epoch: 5 [24320/60000 (41%)]\tLoss: 0.007976\n",
      "Train Epoch: 5 [24960/60000 (42%)]\tLoss: 0.046588\n",
      "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 0.004227\n",
      "Train Epoch: 5 [26240/60000 (44%)]\tLoss: 0.023529\n",
      "Train Epoch: 5 [26880/60000 (45%)]\tLoss: 0.122846\n",
      "Train Epoch: 5 [27520/60000 (46%)]\tLoss: 0.014759\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 5 [28160/60000 (47%)]\tLoss: 0.118735\n",
      "Train Epoch: 5 [28800/60000 (48%)]\tLoss: 0.069006\n",
      "Train Epoch: 5 [29440/60000 (49%)]\tLoss: 0.009543\n",
      "Train Epoch: 5 [30080/60000 (50%)]\tLoss: 0.039947\n",
      "Train Epoch: 5 [30720/60000 (51%)]\tLoss: 0.019479\n",
      "Train Epoch: 5 [31360/60000 (52%)]\tLoss: 0.153849\n",
      "Train Epoch: 5 [32000/60000 (53%)]\tLoss: 0.045214\n",
      "Train Epoch: 5 [32640/60000 (54%)]\tLoss: 0.025490\n",
      "Train Epoch: 5 [33280/60000 (55%)]\tLoss: 0.033629\n",
      "Train Epoch: 5 [33920/60000 (57%)]\tLoss: 0.015742\n",
      "Train Epoch: 5 [34560/60000 (58%)]\tLoss: 0.043036\n",
      "Train Epoch: 5 [35200/60000 (59%)]\tLoss: 0.034043\n",
      "Train Epoch: 5 [35840/60000 (60%)]\tLoss: 0.030966\n",
      "Train Epoch: 5 [36480/60000 (61%)]\tLoss: 0.002069\n",
      "Train Epoch: 5 [37120/60000 (62%)]\tLoss: 0.185441\n",
      "Train Epoch: 5 [37760/60000 (63%)]\tLoss: 0.028906\n",
      "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 0.001360\n",
      "Train Epoch: 5 [39040/60000 (65%)]\tLoss: 0.013534\n",
      "Train Epoch: 5 [39680/60000 (66%)]\tLoss: 0.009507\n",
      "Train Epoch: 5 [40320/60000 (67%)]\tLoss: 0.067391\n",
      "Train Epoch: 5 [40960/60000 (68%)]\tLoss: 0.011375\n",
      "Train Epoch: 5 [41600/60000 (69%)]\tLoss: 0.060619\n",
      "Train Epoch: 5 [42240/60000 (70%)]\tLoss: 0.031344\n",
      "Train Epoch: 5 [42880/60000 (71%)]\tLoss: 0.003144\n",
      "Train Epoch: 5 [43520/60000 (72%)]\tLoss: 0.006965\n",
      "Train Epoch: 5 [44160/60000 (74%)]\tLoss: 0.009983\n",
      "Train Epoch: 5 [44800/60000 (75%)]\tLoss: 0.006394\n",
      "Train Epoch: 5 [45440/60000 (76%)]\tLoss: 0.002483\n",
      "Train Epoch: 5 [46080/60000 (77%)]\tLoss: 0.008559\n",
      "Train Epoch: 5 [46720/60000 (78%)]\tLoss: 0.022479\n",
      "Train Epoch: 5 [47360/60000 (79%)]\tLoss: 0.010795\n",
      "Train Epoch: 5 [48000/60000 (80%)]\tLoss: 0.003619\n",
      "Train Epoch: 5 [48640/60000 (81%)]\tLoss: 0.011996\n",
      "Train Epoch: 5 [49280/60000 (82%)]\tLoss: 0.100613\n",
      "Train Epoch: 5 [49920/60000 (83%)]\tLoss: 0.010505\n",
      "Train Epoch: 5 [50560/60000 (84%)]\tLoss: 0.054624\n",
      "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 0.153324\n",
      "Train Epoch: 5 [51840/60000 (86%)]\tLoss: 0.064332\n",
      "Train Epoch: 5 [52480/60000 (87%)]\tLoss: 0.036599\n",
      "Train Epoch: 5 [53120/60000 (88%)]\tLoss: 0.061883\n",
      "Train Epoch: 5 [53760/60000 (90%)]\tLoss: 0.117998\n",
      "Train Epoch: 5 [54400/60000 (91%)]\tLoss: 0.003498\n",
      "Train Epoch: 5 [55040/60000 (92%)]\tLoss: 0.008335\n",
      "Train Epoch: 5 [55680/60000 (93%)]\tLoss: 0.070837\n",
      "Train Epoch: 5 [56320/60000 (94%)]\tLoss: 0.134646\n",
      "Train Epoch: 5 [56960/60000 (95%)]\tLoss: 0.009611\n",
      "Train Epoch: 5 [57600/60000 (96%)]\tLoss: 0.020219\n",
      "Train Epoch: 5 [58240/60000 (97%)]\tLoss: 0.034991\n",
      "Train Epoch: 5 [58880/60000 (98%)]\tLoss: 0.012028\n",
      "Train Epoch: 5 [59520/60000 (99%)]\tLoss: 0.004360\n",
      "\n",
      "Test set: Avg. loss: 0.0387, Accuracy: 9873/10000 (99%)\n",
      "\n",
      "Train Epoch: 6 [0/60000 (0%)]\tLoss: 0.058432\n",
      "Train Epoch: 6 [640/60000 (1%)]\tLoss: 0.005513\n",
      "Train Epoch: 6 [1280/60000 (2%)]\tLoss: 0.013206\n",
      "Train Epoch: 6 [1920/60000 (3%)]\tLoss: 0.038073\n",
      "Train Epoch: 6 [2560/60000 (4%)]\tLoss: 0.003844\n",
      "Train Epoch: 6 [3200/60000 (5%)]\tLoss: 0.000714\n",
      "Train Epoch: 6 [3840/60000 (6%)]\tLoss: 0.016196\n",
      "Train Epoch: 6 [4480/60000 (7%)]\tLoss: 0.030816\n",
      "Train Epoch: 6 [5120/60000 (9%)]\tLoss: 0.046312\n",
      "Train Epoch: 6 [5760/60000 (10%)]\tLoss: 0.066042\n",
      "Train Epoch: 6 [6400/60000 (11%)]\tLoss: 0.012971\n",
      "Train Epoch: 6 [7040/60000 (12%)]\tLoss: 0.037644\n",
      "Train Epoch: 6 [7680/60000 (13%)]\tLoss: 0.059500\n",
      "Train Epoch: 6 [8320/60000 (14%)]\tLoss: 0.011758\n",
      "Train Epoch: 6 [8960/60000 (15%)]\tLoss: 0.014879\n",
      "Train Epoch: 6 [9600/60000 (16%)]\tLoss: 0.023542\n",
      "Train Epoch: 6 [10240/60000 (17%)]\tLoss: 0.016906\n",
      "Train Epoch: 6 [10880/60000 (18%)]\tLoss: 0.013949\n",
      "Train Epoch: 6 [11520/60000 (19%)]\tLoss: 0.097419\n",
      "Train Epoch: 6 [12160/60000 (20%)]\tLoss: 0.031363\n",
      "Train Epoch: 6 [12800/60000 (21%)]\tLoss: 0.005995\n",
      "Train Epoch: 6 [13440/60000 (22%)]\tLoss: 0.027844\n",
      "Train Epoch: 6 [14080/60000 (23%)]\tLoss: 0.092079\n",
      "Train Epoch: 6 [14720/60000 (25%)]\tLoss: 0.052729\n",
      "Train Epoch: 6 [15360/60000 (26%)]\tLoss: 0.002887\n",
      "Train Epoch: 6 [16000/60000 (27%)]\tLoss: 0.013912\n",
      "Train Epoch: 6 [16640/60000 (28%)]\tLoss: 0.072982\n",
      "Train Epoch: 6 [17280/60000 (29%)]\tLoss: 0.075738\n",
      "Train Epoch: 6 [17920/60000 (30%)]\tLoss: 0.002826\n",
      "Train Epoch: 6 [18560/60000 (31%)]\tLoss: 0.024698\n",
      "Train Epoch: 6 [19200/60000 (32%)]\tLoss: 0.001615\n",
      "Train Epoch: 6 [19840/60000 (33%)]\tLoss: 0.085668\n",
      "Train Epoch: 6 [20480/60000 (34%)]\tLoss: 0.002764\n",
      "Train Epoch: 6 [21120/60000 (35%)]\tLoss: 0.008675\n",
      "Train Epoch: 6 [21760/60000 (36%)]\tLoss: 0.052658\n",
      "Train Epoch: 6 [22400/60000 (37%)]\tLoss: 0.000532\n",
      "Train Epoch: 6 [23040/60000 (38%)]\tLoss: 0.073582\n",
      "Train Epoch: 6 [23680/60000 (39%)]\tLoss: 0.006533\n",
      "Train Epoch: 6 [24320/60000 (41%)]\tLoss: 0.001184\n",
      "Train Epoch: 6 [24960/60000 (42%)]\tLoss: 0.029980\n",
      "Train Epoch: 6 [25600/60000 (43%)]\tLoss: 0.075904\n",
      "Train Epoch: 6 [26240/60000 (44%)]\tLoss: 0.019034\n",
      "Train Epoch: 6 [26880/60000 (45%)]\tLoss: 0.034488\n",
      "Train Epoch: 6 [27520/60000 (46%)]\tLoss: 0.040137\n",
      "Train Epoch: 6 [28160/60000 (47%)]\tLoss: 0.063129\n",
      "Train Epoch: 6 [28800/60000 (48%)]\tLoss: 0.029351\n",
      "Train Epoch: 6 [29440/60000 (49%)]\tLoss: 0.067162\n",
      "Train Epoch: 6 [30080/60000 (50%)]\tLoss: 0.007318\n",
      "Train Epoch: 6 [30720/60000 (51%)]\tLoss: 0.094218\n",
      "Train Epoch: 6 [31360/60000 (52%)]\tLoss: 0.001681\n",
      "Train Epoch: 6 [32000/60000 (53%)]\tLoss: 0.000807\n",
      "Train Epoch: 6 [32640/60000 (54%)]\tLoss: 0.014041\n",
      "Train Epoch: 6 [33280/60000 (55%)]\tLoss: 0.001370\n",
      "Train Epoch: 6 [33920/60000 (57%)]\tLoss: 0.013567\n",
      "Train Epoch: 6 [34560/60000 (58%)]\tLoss: 0.019962\n",
      "Train Epoch: 6 [35200/60000 (59%)]\tLoss: 0.107514\n",
      "Train Epoch: 6 [35840/60000 (60%)]\tLoss: 0.017398\n",
      "Train Epoch: 6 [36480/60000 (61%)]\tLoss: 0.006777\n",
      "Train Epoch: 6 [37120/60000 (62%)]\tLoss: 0.029449\n",
      "Train Epoch: 6 [37760/60000 (63%)]\tLoss: 0.001455\n",
      "Train Epoch: 6 [38400/60000 (64%)]\tLoss: 0.018017\n",
      "Train Epoch: 6 [39040/60000 (65%)]\tLoss: 0.007709\n",
      "Train Epoch: 6 [39680/60000 (66%)]\tLoss: 0.003315\n",
      "Train Epoch: 6 [40320/60000 (67%)]\tLoss: 0.026490\n",
      "Train Epoch: 6 [40960/60000 (68%)]\tLoss: 0.028783\n",
      "Train Epoch: 6 [41600/60000 (69%)]\tLoss: 0.012708\n",
      "Train Epoch: 6 [42240/60000 (70%)]\tLoss: 0.030485\n",
      "Train Epoch: 6 [42880/60000 (71%)]\tLoss: 0.012265\n",
      "Train Epoch: 6 [43520/60000 (72%)]\tLoss: 0.006320\n",
      "Train Epoch: 6 [44160/60000 (74%)]\tLoss: 0.002674\n",
      "Train Epoch: 6 [44800/60000 (75%)]\tLoss: 0.048793\n",
      "Train Epoch: 6 [45440/60000 (76%)]\tLoss: 0.006765\n",
      "Train Epoch: 6 [46080/60000 (77%)]\tLoss: 0.063923\n",
      "Train Epoch: 6 [46720/60000 (78%)]\tLoss: 0.016458\n",
      "Train Epoch: 6 [47360/60000 (79%)]\tLoss: 0.046097\n",
      "Train Epoch: 6 [48000/60000 (80%)]\tLoss: 0.002096\n",
      "Train Epoch: 6 [48640/60000 (81%)]\tLoss: 0.008643\n",
      "Train Epoch: 6 [49280/60000 (82%)]\tLoss: 0.003712\n",
      "Train Epoch: 6 [49920/60000 (83%)]\tLoss: 0.017983\n",
      "Train Epoch: 6 [50560/60000 (84%)]\tLoss: 0.014361\n",
      "Train Epoch: 6 [51200/60000 (85%)]\tLoss: 0.014233\n",
      "Train Epoch: 6 [51840/60000 (86%)]\tLoss: 0.189342\n",
      "Train Epoch: 6 [52480/60000 (87%)]\tLoss: 0.018178\n",
      "Train Epoch: 6 [53120/60000 (88%)]\tLoss: 0.005115\n",
      "Train Epoch: 6 [53760/60000 (90%)]\tLoss: 0.042759\n",
      "Train Epoch: 6 [54400/60000 (91%)]\tLoss: 0.002611\n",
      "Train Epoch: 6 [55040/60000 (92%)]\tLoss: 0.011897\n",
      "Train Epoch: 6 [55680/60000 (93%)]\tLoss: 0.014631\n",
      "Train Epoch: 6 [56320/60000 (94%)]\tLoss: 0.006167\n",
      "Train Epoch: 6 [56960/60000 (95%)]\tLoss: 0.002293\n",
      "Train Epoch: 6 [57600/60000 (96%)]\tLoss: 0.000879\n",
      "Train Epoch: 6 [58240/60000 (97%)]\tLoss: 0.003207\n",
      "Train Epoch: 6 [58880/60000 (98%)]\tLoss: 0.028981\n",
      "Train Epoch: 6 [59520/60000 (99%)]\tLoss: 0.004011\n",
      "\n",
      "Test set: Avg. loss: 0.0404, Accuracy: 9880/10000 (99%)\n",
      "\n",
      "Train Epoch: 7 [0/60000 (0%)]\tLoss: 0.049139\n",
      "Train Epoch: 7 [640/60000 (1%)]\tLoss: 0.006759\n",
      "Train Epoch: 7 [1280/60000 (2%)]\tLoss: 0.023759\n",
      "Train Epoch: 7 [1920/60000 (3%)]\tLoss: 0.142132\n",
      "Train Epoch: 7 [2560/60000 (4%)]\tLoss: 0.049596\n",
      "Train Epoch: 7 [3200/60000 (5%)]\tLoss: 0.012562\n",
      "Train Epoch: 7 [3840/60000 (6%)]\tLoss: 0.041533\n",
      "Train Epoch: 7 [4480/60000 (7%)]\tLoss: 0.071731\n",
      "Train Epoch: 7 [5120/60000 (9%)]\tLoss: 0.015793\n",
      "Train Epoch: 7 [5760/60000 (10%)]\tLoss: 0.011064\n",
      "Train Epoch: 7 [6400/60000 (11%)]\tLoss: 0.040173\n",
      "Train Epoch: 7 [7040/60000 (12%)]\tLoss: 0.051027\n",
      "Train Epoch: 7 [7680/60000 (13%)]\tLoss: 0.002617\n",
      "Train Epoch: 7 [8320/60000 (14%)]\tLoss: 0.046315\n",
      "Train Epoch: 7 [8960/60000 (15%)]\tLoss: 0.013437\n",
      "Train Epoch: 7 [9600/60000 (16%)]\tLoss: 0.012732\n",
      "Train Epoch: 7 [10240/60000 (17%)]\tLoss: 0.019096\n",
      "Train Epoch: 7 [10880/60000 (18%)]\tLoss: 0.022754\n",
      "Train Epoch: 7 [11520/60000 (19%)]\tLoss: 0.000137\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 7 [12160/60000 (20%)]\tLoss: 0.070689\n",
      "Train Epoch: 7 [12800/60000 (21%)]\tLoss: 0.007173\n",
      "Train Epoch: 7 [13440/60000 (22%)]\tLoss: 0.006463\n",
      "Train Epoch: 7 [14080/60000 (23%)]\tLoss: 0.001186\n",
      "Train Epoch: 7 [14720/60000 (25%)]\tLoss: 0.004810\n",
      "Train Epoch: 7 [15360/60000 (26%)]\tLoss: 0.009431\n",
      "Train Epoch: 7 [16000/60000 (27%)]\tLoss: 0.043009\n",
      "Train Epoch: 7 [16640/60000 (28%)]\tLoss: 0.015097\n",
      "Train Epoch: 7 [17280/60000 (29%)]\tLoss: 0.006939\n",
      "Train Epoch: 7 [17920/60000 (30%)]\tLoss: 0.007240\n",
      "Train Epoch: 7 [18560/60000 (31%)]\tLoss: 0.043933\n",
      "Train Epoch: 7 [19200/60000 (32%)]\tLoss: 0.043092\n",
      "Train Epoch: 7 [19840/60000 (33%)]\tLoss: 0.012888\n",
      "Train Epoch: 7 [20480/60000 (34%)]\tLoss: 0.022453\n",
      "Train Epoch: 7 [21120/60000 (35%)]\tLoss: 0.095615\n",
      "Train Epoch: 7 [21760/60000 (36%)]\tLoss: 0.040605\n",
      "Train Epoch: 7 [22400/60000 (37%)]\tLoss: 0.008959\n",
      "Train Epoch: 7 [23040/60000 (38%)]\tLoss: 0.035197\n",
      "Train Epoch: 7 [23680/60000 (39%)]\tLoss: 0.025741\n",
      "Train Epoch: 7 [24320/60000 (41%)]\tLoss: 0.003391\n",
      "Train Epoch: 7 [24960/60000 (42%)]\tLoss: 0.008793\n",
      "Train Epoch: 7 [25600/60000 (43%)]\tLoss: 0.018030\n",
      "Train Epoch: 7 [26240/60000 (44%)]\tLoss: 0.242459\n",
      "Train Epoch: 7 [26880/60000 (45%)]\tLoss: 0.001721\n",
      "Train Epoch: 7 [27520/60000 (46%)]\tLoss: 0.004424\n",
      "Train Epoch: 7 [28160/60000 (47%)]\tLoss: 0.062510\n",
      "Train Epoch: 7 [28800/60000 (48%)]\tLoss: 0.011540\n",
      "Train Epoch: 7 [29440/60000 (49%)]\tLoss: 0.018939\n",
      "Train Epoch: 7 [30080/60000 (50%)]\tLoss: 0.003234\n",
      "Train Epoch: 7 [30720/60000 (51%)]\tLoss: 0.055790\n",
      "Train Epoch: 7 [31360/60000 (52%)]\tLoss: 0.017027\n",
      "Train Epoch: 7 [32000/60000 (53%)]\tLoss: 0.016825\n",
      "Train Epoch: 7 [32640/60000 (54%)]\tLoss: 0.029505\n",
      "Train Epoch: 7 [33280/60000 (55%)]\tLoss: 0.006999\n",
      "Train Epoch: 7 [33920/60000 (57%)]\tLoss: 0.002163\n",
      "Train Epoch: 7 [34560/60000 (58%)]\tLoss: 0.003938\n",
      "Train Epoch: 7 [35200/60000 (59%)]\tLoss: 0.017969\n",
      "Train Epoch: 7 [35840/60000 (60%)]\tLoss: 0.051615\n",
      "Train Epoch: 7 [36480/60000 (61%)]\tLoss: 0.020955\n",
      "Train Epoch: 7 [37120/60000 (62%)]\tLoss: 0.034557\n",
      "Train Epoch: 7 [37760/60000 (63%)]\tLoss: 0.014651\n",
      "Train Epoch: 7 [38400/60000 (64%)]\tLoss: 0.055358\n",
      "Train Epoch: 7 [39040/60000 (65%)]\tLoss: 0.057988\n",
      "Train Epoch: 7 [39680/60000 (66%)]\tLoss: 0.022971\n",
      "Train Epoch: 7 [40320/60000 (67%)]\tLoss: 0.013182\n",
      "Train Epoch: 7 [40960/60000 (68%)]\tLoss: 0.014575\n",
      "Train Epoch: 7 [41600/60000 (69%)]\tLoss: 0.017028\n",
      "Train Epoch: 7 [42240/60000 (70%)]\tLoss: 0.001677\n",
      "Train Epoch: 7 [42880/60000 (71%)]\tLoss: 0.065012\n",
      "Train Epoch: 7 [43520/60000 (72%)]\tLoss: 0.026638\n",
      "Train Epoch: 7 [44160/60000 (74%)]\tLoss: 0.131492\n",
      "Train Epoch: 7 [44800/60000 (75%)]\tLoss: 0.002275\n",
      "Train Epoch: 7 [45440/60000 (76%)]\tLoss: 0.003228\n",
      "Train Epoch: 7 [46080/60000 (77%)]\tLoss: 0.038169\n",
      "Train Epoch: 7 [46720/60000 (78%)]\tLoss: 0.018413\n",
      "Train Epoch: 7 [47360/60000 (79%)]\tLoss: 0.002679\n",
      "Train Epoch: 7 [48000/60000 (80%)]\tLoss: 0.009935\n",
      "Train Epoch: 7 [48640/60000 (81%)]\tLoss: 0.017553\n",
      "Train Epoch: 7 [49280/60000 (82%)]\tLoss: 0.053168\n",
      "Train Epoch: 7 [49920/60000 (83%)]\tLoss: 0.004327\n",
      "Train Epoch: 7 [50560/60000 (84%)]\tLoss: 0.018693\n",
      "Train Epoch: 7 [51200/60000 (85%)]\tLoss: 0.195181\n",
      "Train Epoch: 7 [51840/60000 (86%)]\tLoss: 0.005008\n",
      "Train Epoch: 7 [52480/60000 (87%)]\tLoss: 0.015034\n",
      "Train Epoch: 7 [53120/60000 (88%)]\tLoss: 0.071875\n",
      "Train Epoch: 7 [53760/60000 (90%)]\tLoss: 0.026558\n",
      "Train Epoch: 7 [54400/60000 (91%)]\tLoss: 0.001668\n",
      "Train Epoch: 7 [55040/60000 (92%)]\tLoss: 0.032928\n",
      "Train Epoch: 7 [55680/60000 (93%)]\tLoss: 0.009238\n",
      "Train Epoch: 7 [56320/60000 (94%)]\tLoss: 0.105305\n",
      "Train Epoch: 7 [56960/60000 (95%)]\tLoss: 0.008241\n",
      "Train Epoch: 7 [57600/60000 (96%)]\tLoss: 0.024515\n",
      "Train Epoch: 7 [58240/60000 (97%)]\tLoss: 0.148441\n",
      "Train Epoch: 7 [58880/60000 (98%)]\tLoss: 0.008150\n",
      "Train Epoch: 7 [59520/60000 (99%)]\tLoss: 0.006053\n",
      "\n",
      "Test set: Avg. loss: 0.0360, Accuracy: 9883/10000 (99%)\n",
      "\n",
      "Train Epoch: 8 [0/60000 (0%)]\tLoss: 0.001264\n",
      "Train Epoch: 8 [640/60000 (1%)]\tLoss: 0.006372\n",
      "Train Epoch: 8 [1280/60000 (2%)]\tLoss: 0.020135\n",
      "Train Epoch: 8 [1920/60000 (3%)]\tLoss: 0.009061\n",
      "Train Epoch: 8 [2560/60000 (4%)]\tLoss: 0.023003\n",
      "Train Epoch: 8 [3200/60000 (5%)]\tLoss: 0.006556\n",
      "Train Epoch: 8 [3840/60000 (6%)]\tLoss: 0.003331\n",
      "Train Epoch: 8 [4480/60000 (7%)]\tLoss: 0.016395\n",
      "Train Epoch: 8 [5120/60000 (9%)]\tLoss: 0.009371\n",
      "Train Epoch: 8 [5760/60000 (10%)]\tLoss: 0.004313\n",
      "Train Epoch: 8 [6400/60000 (11%)]\tLoss: 0.005411\n",
      "Train Epoch: 8 [7040/60000 (12%)]\tLoss: 0.000388\n",
      "Train Epoch: 8 [7680/60000 (13%)]\tLoss: 0.060639\n",
      "Train Epoch: 8 [8320/60000 (14%)]\tLoss: 0.040836\n",
      "Train Epoch: 8 [8960/60000 (15%)]\tLoss: 0.008276\n",
      "Train Epoch: 8 [9600/60000 (16%)]\tLoss: 0.000893\n",
      "Train Epoch: 8 [10240/60000 (17%)]\tLoss: 0.001070\n",
      "Train Epoch: 8 [10880/60000 (18%)]\tLoss: 0.001000\n",
      "Train Epoch: 8 [11520/60000 (19%)]\tLoss: 0.003436\n",
      "Train Epoch: 8 [12160/60000 (20%)]\tLoss: 0.005615\n",
      "Train Epoch: 8 [12800/60000 (21%)]\tLoss: 0.022498\n",
      "Train Epoch: 8 [13440/60000 (22%)]\tLoss: 0.043878\n",
      "Train Epoch: 8 [14080/60000 (23%)]\tLoss: 0.061153\n",
      "Train Epoch: 8 [14720/60000 (25%)]\tLoss: 0.007017\n",
      "Train Epoch: 8 [15360/60000 (26%)]\tLoss: 0.001506\n",
      "Train Epoch: 8 [16000/60000 (27%)]\tLoss: 0.004104\n",
      "Train Epoch: 8 [16640/60000 (28%)]\tLoss: 0.001957\n",
      "Train Epoch: 8 [17280/60000 (29%)]\tLoss: 0.007274\n",
      "Train Epoch: 8 [17920/60000 (30%)]\tLoss: 0.002448\n",
      "Train Epoch: 8 [18560/60000 (31%)]\tLoss: 0.032924\n",
      "Train Epoch: 8 [19200/60000 (32%)]\tLoss: 0.088238\n",
      "Train Epoch: 8 [19840/60000 (33%)]\tLoss: 0.005421\n",
      "Train Epoch: 8 [20480/60000 (34%)]\tLoss: 0.006815\n",
      "Train Epoch: 8 [21120/60000 (35%)]\tLoss: 0.009046\n",
      "Train Epoch: 8 [21760/60000 (36%)]\tLoss: 0.010034\n",
      "Train Epoch: 8 [22400/60000 (37%)]\tLoss: 0.035779\n",
      "Train Epoch: 8 [23040/60000 (38%)]\tLoss: 0.094430\n",
      "Train Epoch: 8 [23680/60000 (39%)]\tLoss: 0.030796\n",
      "Train Epoch: 8 [24320/60000 (41%)]\tLoss: 0.009026\n",
      "Train Epoch: 8 [24960/60000 (42%)]\tLoss: 0.070652\n",
      "Train Epoch: 8 [25600/60000 (43%)]\tLoss: 0.000829\n",
      "Train Epoch: 8 [26240/60000 (44%)]\tLoss: 0.008819\n",
      "Train Epoch: 8 [26880/60000 (45%)]\tLoss: 0.017738\n",
      "Train Epoch: 8 [27520/60000 (46%)]\tLoss: 0.028596\n",
      "Train Epoch: 8 [28160/60000 (47%)]\tLoss: 0.001441\n",
      "Train Epoch: 8 [28800/60000 (48%)]\tLoss: 0.010557\n",
      "Train Epoch: 8 [29440/60000 (49%)]\tLoss: 0.025236\n",
      "Train Epoch: 8 [30080/60000 (50%)]\tLoss: 0.000983\n",
      "Train Epoch: 8 [30720/60000 (51%)]\tLoss: 0.015570\n",
      "Train Epoch: 8 [31360/60000 (52%)]\tLoss: 0.031242\n",
      "Train Epoch: 8 [32000/60000 (53%)]\tLoss: 0.005941\n",
      "Train Epoch: 8 [32640/60000 (54%)]\tLoss: 0.000905\n",
      "Train Epoch: 8 [33280/60000 (55%)]\tLoss: 0.001603\n",
      "Train Epoch: 8 [33920/60000 (57%)]\tLoss: 0.005885\n",
      "Train Epoch: 8 [34560/60000 (58%)]\tLoss: 0.052976\n",
      "Train Epoch: 8 [35200/60000 (59%)]\tLoss: 0.287615\n",
      "Train Epoch: 8 [35840/60000 (60%)]\tLoss: 0.015688\n",
      "Train Epoch: 8 [36480/60000 (61%)]\tLoss: 0.010771\n",
      "Train Epoch: 8 [37120/60000 (62%)]\tLoss: 0.009931\n",
      "Train Epoch: 8 [37760/60000 (63%)]\tLoss: 0.073587\n",
      "Train Epoch: 8 [38400/60000 (64%)]\tLoss: 0.036360\n",
      "Train Epoch: 8 [39040/60000 (65%)]\tLoss: 0.018364\n",
      "Train Epoch: 8 [39680/60000 (66%)]\tLoss: 0.012808\n",
      "Train Epoch: 8 [40320/60000 (67%)]\tLoss: 0.045782\n",
      "Train Epoch: 8 [40960/60000 (68%)]\tLoss: 0.052265\n",
      "Train Epoch: 8 [41600/60000 (69%)]\tLoss: 0.025135\n",
      "Train Epoch: 8 [42240/60000 (70%)]\tLoss: 0.022079\n",
      "Train Epoch: 8 [42880/60000 (71%)]\tLoss: 0.025322\n",
      "Train Epoch: 8 [43520/60000 (72%)]\tLoss: 0.045270\n",
      "Train Epoch: 8 [44160/60000 (74%)]\tLoss: 0.010450\n",
      "Train Epoch: 8 [44800/60000 (75%)]\tLoss: 0.050841\n",
      "Train Epoch: 8 [45440/60000 (76%)]\tLoss: 0.002756\n",
      "Train Epoch: 8 [46080/60000 (77%)]\tLoss: 0.043181\n",
      "Train Epoch: 8 [46720/60000 (78%)]\tLoss: 0.058282\n",
      "Train Epoch: 8 [47360/60000 (79%)]\tLoss: 0.003471\n",
      "Train Epoch: 8 [48000/60000 (80%)]\tLoss: 0.004317\n",
      "Train Epoch: 8 [48640/60000 (81%)]\tLoss: 0.010013\n",
      "Train Epoch: 8 [49280/60000 (82%)]\tLoss: 0.007011\n",
      "Train Epoch: 8 [49920/60000 (83%)]\tLoss: 0.002986\n",
      "Train Epoch: 8 [50560/60000 (84%)]\tLoss: 0.049271\n",
      "Train Epoch: 8 [51200/60000 (85%)]\tLoss: 0.178726\n",
      "Train Epoch: 8 [51840/60000 (86%)]\tLoss: 0.005395\n",
      "Train Epoch: 8 [52480/60000 (87%)]\tLoss: 0.001199\n",
      "Train Epoch: 8 [53120/60000 (88%)]\tLoss: 0.121124\n",
      "Train Epoch: 8 [53760/60000 (90%)]\tLoss: 0.028363\n",
      "Train Epoch: 8 [54400/60000 (91%)]\tLoss: 0.003660\n",
      "Train Epoch: 8 [55040/60000 (92%)]\tLoss: 0.011637\n",
      "Train Epoch: 8 [55680/60000 (93%)]\tLoss: 0.000530\n",
      "Train Epoch: 8 [56320/60000 (94%)]\tLoss: 0.036358\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 8 [56960/60000 (95%)]\tLoss: 0.015157\n",
      "Train Epoch: 8 [57600/60000 (96%)]\tLoss: 0.036630\n",
      "Train Epoch: 8 [58240/60000 (97%)]\tLoss: 0.001377\n",
      "Train Epoch: 8 [58880/60000 (98%)]\tLoss: 0.001245\n",
      "Train Epoch: 8 [59520/60000 (99%)]\tLoss: 0.000321\n",
      "\n",
      "Test set: Avg. loss: 0.0310, Accuracy: 9908/10000 (99%)\n",
      "\n",
      "Train Epoch: 9 [0/60000 (0%)]\tLoss: 0.013247\n",
      "Train Epoch: 9 [640/60000 (1%)]\tLoss: 0.000807\n",
      "Train Epoch: 9 [1280/60000 (2%)]\tLoss: 0.002100\n",
      "Train Epoch: 9 [1920/60000 (3%)]\tLoss: 0.006460\n",
      "Train Epoch: 9 [2560/60000 (4%)]\tLoss: 0.016230\n",
      "Train Epoch: 9 [3200/60000 (5%)]\tLoss: 0.003121\n",
      "Train Epoch: 9 [3840/60000 (6%)]\tLoss: 0.041203\n",
      "Train Epoch: 9 [4480/60000 (7%)]\tLoss: 0.003430\n",
      "Train Epoch: 9 [5120/60000 (9%)]\tLoss: 0.007468\n",
      "Train Epoch: 9 [5760/60000 (10%)]\tLoss: 0.015485\n",
      "Train Epoch: 9 [6400/60000 (11%)]\tLoss: 0.024107\n",
      "Train Epoch: 9 [7040/60000 (12%)]\tLoss: 0.001069\n",
      "Train Epoch: 9 [7680/60000 (13%)]\tLoss: 0.009967\n",
      "Train Epoch: 9 [8320/60000 (14%)]\tLoss: 0.015089\n",
      "Train Epoch: 9 [8960/60000 (15%)]\tLoss: 0.001598\n",
      "Train Epoch: 9 [9600/60000 (16%)]\tLoss: 0.020854\n",
      "Train Epoch: 9 [10240/60000 (17%)]\tLoss: 0.002793\n",
      "Train Epoch: 9 [10880/60000 (18%)]\tLoss: 0.000847\n",
      "Train Epoch: 9 [11520/60000 (19%)]\tLoss: 0.047412\n",
      "Train Epoch: 9 [12160/60000 (20%)]\tLoss: 0.014882\n",
      "Train Epoch: 9 [12800/60000 (21%)]\tLoss: 0.005475\n",
      "Train Epoch: 9 [13440/60000 (22%)]\tLoss: 0.003113\n",
      "Train Epoch: 9 [14080/60000 (23%)]\tLoss: 0.065146\n",
      "Train Epoch: 9 [14720/60000 (25%)]\tLoss: 0.001473\n",
      "Train Epoch: 9 [15360/60000 (26%)]\tLoss: 0.010134\n",
      "Train Epoch: 9 [16000/60000 (27%)]\tLoss: 0.002617\n",
      "Train Epoch: 9 [16640/60000 (28%)]\tLoss: 0.001145\n",
      "Train Epoch: 9 [17280/60000 (29%)]\tLoss: 0.012047\n",
      "Train Epoch: 9 [17920/60000 (30%)]\tLoss: 0.009037\n",
      "Train Epoch: 9 [18560/60000 (31%)]\tLoss: 0.001231\n",
      "Train Epoch: 9 [19200/60000 (32%)]\tLoss: 0.034166\n",
      "Train Epoch: 9 [19840/60000 (33%)]\tLoss: 0.092521\n",
      "Train Epoch: 9 [20480/60000 (34%)]\tLoss: 0.008375\n",
      "Train Epoch: 9 [21120/60000 (35%)]\tLoss: 0.087617\n",
      "Train Epoch: 9 [21760/60000 (36%)]\tLoss: 0.004727\n",
      "Train Epoch: 9 [22400/60000 (37%)]\tLoss: 0.117588\n",
      "Train Epoch: 9 [23040/60000 (38%)]\tLoss: 0.016855\n",
      "Train Epoch: 9 [23680/60000 (39%)]\tLoss: 0.002812\n",
      "Train Epoch: 9 [24320/60000 (41%)]\tLoss: 0.000839\n",
      "Train Epoch: 9 [24960/60000 (42%)]\tLoss: 0.010868\n",
      "Train Epoch: 9 [25600/60000 (43%)]\tLoss: 0.012643\n",
      "Train Epoch: 9 [26240/60000 (44%)]\tLoss: 0.000201\n",
      "Train Epoch: 9 [26880/60000 (45%)]\tLoss: 0.002526\n",
      "Train Epoch: 9 [27520/60000 (46%)]\tLoss: 0.001929\n",
      "Train Epoch: 9 [28160/60000 (47%)]\tLoss: 0.023651\n",
      "Train Epoch: 9 [28800/60000 (48%)]\tLoss: 0.054682\n",
      "Train Epoch: 9 [29440/60000 (49%)]\tLoss: 0.003446\n",
      "Train Epoch: 9 [30080/60000 (50%)]\tLoss: 0.052644\n",
      "Train Epoch: 9 [30720/60000 (51%)]\tLoss: 0.003369\n",
      "Train Epoch: 9 [31360/60000 (52%)]\tLoss: 0.018560\n",
      "Train Epoch: 9 [32000/60000 (53%)]\tLoss: 0.011145\n",
      "Train Epoch: 9 [32640/60000 (54%)]\tLoss: 0.057053\n",
      "Train Epoch: 9 [33280/60000 (55%)]\tLoss: 0.006504\n",
      "Train Epoch: 9 [33920/60000 (57%)]\tLoss: 0.006378\n",
      "Train Epoch: 9 [34560/60000 (58%)]\tLoss: 0.004714\n",
      "Train Epoch: 9 [35200/60000 (59%)]\tLoss: 0.007303\n",
      "Train Epoch: 9 [35840/60000 (60%)]\tLoss: 0.000380\n",
      "Train Epoch: 9 [36480/60000 (61%)]\tLoss: 0.010052\n",
      "Train Epoch: 9 [37120/60000 (62%)]\tLoss: 0.003911\n",
      "Train Epoch: 9 [37760/60000 (63%)]\tLoss: 0.002607\n",
      "Train Epoch: 9 [38400/60000 (64%)]\tLoss: 0.000290\n",
      "Train Epoch: 9 [39040/60000 (65%)]\tLoss: 0.019464\n",
      "Train Epoch: 9 [39680/60000 (66%)]\tLoss: 0.002758\n",
      "Train Epoch: 9 [40320/60000 (67%)]\tLoss: 0.005957\n",
      "Train Epoch: 9 [40960/60000 (68%)]\tLoss: 0.051038\n",
      "Train Epoch: 9 [41600/60000 (69%)]\tLoss: 0.002664\n",
      "Train Epoch: 9 [42240/60000 (70%)]\tLoss: 0.030785\n",
      "Train Epoch: 9 [42880/60000 (71%)]\tLoss: 0.031801\n",
      "Train Epoch: 9 [43520/60000 (72%)]\tLoss: 0.008304\n",
      "Train Epoch: 9 [44160/60000 (74%)]\tLoss: 0.002189\n",
      "Train Epoch: 9 [44800/60000 (75%)]\tLoss: 0.009664\n",
      "Train Epoch: 9 [45440/60000 (76%)]\tLoss: 0.002684\n",
      "Train Epoch: 9 [46080/60000 (77%)]\tLoss: 0.030084\n",
      "Train Epoch: 9 [46720/60000 (78%)]\tLoss: 0.355742\n",
      "Train Epoch: 9 [47360/60000 (79%)]\tLoss: 0.028951\n",
      "Train Epoch: 9 [48000/60000 (80%)]\tLoss: 0.094048\n",
      "Train Epoch: 9 [48640/60000 (81%)]\tLoss: 0.008684\n",
      "Train Epoch: 9 [49280/60000 (82%)]\tLoss: 0.005121\n",
      "Train Epoch: 9 [49920/60000 (83%)]\tLoss: 0.030072\n",
      "Train Epoch: 9 [50560/60000 (84%)]\tLoss: 0.042921\n",
      "Train Epoch: 9 [51200/60000 (85%)]\tLoss: 0.020773\n",
      "Train Epoch: 9 [51840/60000 (86%)]\tLoss: 0.000405\n",
      "Train Epoch: 9 [52480/60000 (87%)]\tLoss: 0.061771\n",
      "Train Epoch: 9 [53120/60000 (88%)]\tLoss: 0.000731\n",
      "Train Epoch: 9 [53760/60000 (90%)]\tLoss: 0.022709\n",
      "Train Epoch: 9 [54400/60000 (91%)]\tLoss: 0.014235\n",
      "Train Epoch: 9 [55040/60000 (92%)]\tLoss: 0.008029\n",
      "Train Epoch: 9 [55680/60000 (93%)]\tLoss: 0.022205\n",
      "Train Epoch: 9 [56320/60000 (94%)]\tLoss: 0.005005\n",
      "Train Epoch: 9 [56960/60000 (95%)]\tLoss: 0.094075\n",
      "Train Epoch: 9 [57600/60000 (96%)]\tLoss: 0.078922\n",
      "Train Epoch: 9 [58240/60000 (97%)]\tLoss: 0.046176\n",
      "Train Epoch: 9 [58880/60000 (98%)]\tLoss: 0.026676\n",
      "Train Epoch: 9 [59520/60000 (99%)]\tLoss: 0.001877\n",
      "\n",
      "Test set: Avg. loss: 0.0282, Accuracy: 9910/10000 (99%)\n",
      "\n",
      "Train Epoch: 10 [0/60000 (0%)]\tLoss: 0.002930\n",
      "Train Epoch: 10 [640/60000 (1%)]\tLoss: 0.007288\n",
      "Train Epoch: 10 [1280/60000 (2%)]\tLoss: 0.002717\n",
      "Train Epoch: 10 [1920/60000 (3%)]\tLoss: 0.004921\n",
      "Train Epoch: 10 [2560/60000 (4%)]\tLoss: 0.001715\n",
      "Train Epoch: 10 [3200/60000 (5%)]\tLoss: 0.062913\n",
      "Train Epoch: 10 [3840/60000 (6%)]\tLoss: 0.007613\n",
      "Train Epoch: 10 [4480/60000 (7%)]\tLoss: 0.007060\n",
      "Train Epoch: 10 [5120/60000 (9%)]\tLoss: 0.001541\n",
      "Train Epoch: 10 [5760/60000 (10%)]\tLoss: 0.021709\n",
      "Train Epoch: 10 [6400/60000 (11%)]\tLoss: 0.006533\n",
      "Train Epoch: 10 [7040/60000 (12%)]\tLoss: 0.006041\n",
      "Train Epoch: 10 [7680/60000 (13%)]\tLoss: 0.000895\n",
      "Train Epoch: 10 [8320/60000 (14%)]\tLoss: 0.006316\n",
      "Train Epoch: 10 [8960/60000 (15%)]\tLoss: 0.025740\n",
      "Train Epoch: 10 [9600/60000 (16%)]\tLoss: 0.032834\n",
      "Train Epoch: 10 [10240/60000 (17%)]\tLoss: 0.009452\n",
      "Train Epoch: 10 [10880/60000 (18%)]\tLoss: 0.008747\n",
      "Train Epoch: 10 [11520/60000 (19%)]\tLoss: 0.000777\n",
      "Train Epoch: 10 [12160/60000 (20%)]\tLoss: 0.000218\n",
      "Train Epoch: 10 [12800/60000 (21%)]\tLoss: 0.002115\n",
      "Train Epoch: 10 [13440/60000 (22%)]\tLoss: 0.031850\n",
      "Train Epoch: 10 [14080/60000 (23%)]\tLoss: 0.001129\n",
      "Train Epoch: 10 [14720/60000 (25%)]\tLoss: 0.000541\n",
      "Train Epoch: 10 [15360/60000 (26%)]\tLoss: 0.020368\n",
      "Train Epoch: 10 [16000/60000 (27%)]\tLoss: 0.005221\n",
      "Train Epoch: 10 [16640/60000 (28%)]\tLoss: 0.025974\n",
      "Train Epoch: 10 [17280/60000 (29%)]\tLoss: 0.017219\n",
      "Train Epoch: 10 [17920/60000 (30%)]\tLoss: 0.000357\n",
      "Train Epoch: 10 [18560/60000 (31%)]\tLoss: 0.006159\n",
      "Train Epoch: 10 [19200/60000 (32%)]\tLoss: 0.000941\n",
      "Train Epoch: 10 [19840/60000 (33%)]\tLoss: 0.004437\n",
      "Train Epoch: 10 [20480/60000 (34%)]\tLoss: 0.066262\n",
      "Train Epoch: 10 [21120/60000 (35%)]\tLoss: 0.076885\n",
      "Train Epoch: 10 [21760/60000 (36%)]\tLoss: 0.000959\n",
      "Train Epoch: 10 [22400/60000 (37%)]\tLoss: 0.011231\n",
      "Train Epoch: 10 [23040/60000 (38%)]\tLoss: 0.009510\n",
      "Train Epoch: 10 [23680/60000 (39%)]\tLoss: 0.055194\n",
      "Train Epoch: 10 [24320/60000 (41%)]\tLoss: 0.000709\n",
      "Train Epoch: 10 [24960/60000 (42%)]\tLoss: 0.005928\n",
      "Train Epoch: 10 [25600/60000 (43%)]\tLoss: 0.000463\n",
      "Train Epoch: 10 [26240/60000 (44%)]\tLoss: 0.000668\n",
      "Train Epoch: 10 [26880/60000 (45%)]\tLoss: 0.024506\n",
      "Train Epoch: 10 [27520/60000 (46%)]\tLoss: 0.115957\n",
      "Train Epoch: 10 [28160/60000 (47%)]\tLoss: 0.001673\n",
      "Train Epoch: 10 [28800/60000 (48%)]\tLoss: 0.009367\n",
      "Train Epoch: 10 [29440/60000 (49%)]\tLoss: 0.020757\n",
      "Train Epoch: 10 [30080/60000 (50%)]\tLoss: 0.000258\n",
      "Train Epoch: 10 [30720/60000 (51%)]\tLoss: 0.029609\n",
      "Train Epoch: 10 [31360/60000 (52%)]\tLoss: 0.005314\n",
      "Train Epoch: 10 [32000/60000 (53%)]\tLoss: 0.061361\n",
      "Train Epoch: 10 [32640/60000 (54%)]\tLoss: 0.005168\n",
      "Train Epoch: 10 [33280/60000 (55%)]\tLoss: 0.001125\n",
      "Train Epoch: 10 [33920/60000 (57%)]\tLoss: 0.003653\n",
      "Train Epoch: 10 [34560/60000 (58%)]\tLoss: 0.003753\n",
      "Train Epoch: 10 [35200/60000 (59%)]\tLoss: 0.053134\n",
      "Train Epoch: 10 [35840/60000 (60%)]\tLoss: 0.001130\n",
      "Train Epoch: 10 [36480/60000 (61%)]\tLoss: 0.009282\n",
      "Train Epoch: 10 [37120/60000 (62%)]\tLoss: 0.023048\n",
      "Train Epoch: 10 [37760/60000 (63%)]\tLoss: 0.009423\n",
      "Train Epoch: 10 [38400/60000 (64%)]\tLoss: 0.001990\n",
      "Train Epoch: 10 [39040/60000 (65%)]\tLoss: 0.001830\n",
      "Train Epoch: 10 [39680/60000 (66%)]\tLoss: 0.005311\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 10 [40320/60000 (67%)]\tLoss: 0.000062\n",
      "Train Epoch: 10 [40960/60000 (68%)]\tLoss: 0.013111\n",
      "Train Epoch: 10 [41600/60000 (69%)]\tLoss: 0.000368\n",
      "Train Epoch: 10 [42240/60000 (70%)]\tLoss: 0.003764\n",
      "Train Epoch: 10 [42880/60000 (71%)]\tLoss: 0.020873\n",
      "Train Epoch: 10 [43520/60000 (72%)]\tLoss: 0.006176\n",
      "Train Epoch: 10 [44160/60000 (74%)]\tLoss: 0.000547\n",
      "Train Epoch: 10 [44800/60000 (75%)]\tLoss: 0.002414\n",
      "Train Epoch: 10 [45440/60000 (76%)]\tLoss: 0.008838\n",
      "Train Epoch: 10 [46080/60000 (77%)]\tLoss: 0.003223\n",
      "Train Epoch: 10 [46720/60000 (78%)]\tLoss: 0.011136\n",
      "Train Epoch: 10 [47360/60000 (79%)]\tLoss: 0.058269\n",
      "Train Epoch: 10 [48000/60000 (80%)]\tLoss: 0.027688\n",
      "Train Epoch: 10 [48640/60000 (81%)]\tLoss: 0.008120\n",
      "Train Epoch: 10 [49280/60000 (82%)]\tLoss: 0.003647\n",
      "Train Epoch: 10 [49920/60000 (83%)]\tLoss: 0.011353\n",
      "Train Epoch: 10 [50560/60000 (84%)]\tLoss: 0.007313\n",
      "Train Epoch: 10 [51200/60000 (85%)]\tLoss: 0.027752\n",
      "Train Epoch: 10 [51840/60000 (86%)]\tLoss: 0.000550\n",
      "Train Epoch: 10 [52480/60000 (87%)]\tLoss: 0.011938\n",
      "Train Epoch: 10 [53120/60000 (88%)]\tLoss: 0.002103\n",
      "Train Epoch: 10 [53760/60000 (90%)]\tLoss: 0.011934\n",
      "Train Epoch: 10 [54400/60000 (91%)]\tLoss: 0.000367\n",
      "Train Epoch: 10 [55040/60000 (92%)]\tLoss: 0.013675\n",
      "Train Epoch: 10 [55680/60000 (93%)]\tLoss: 0.068897\n",
      "Train Epoch: 10 [56320/60000 (94%)]\tLoss: 0.006523\n",
      "Train Epoch: 10 [56960/60000 (95%)]\tLoss: 0.125359\n",
      "Train Epoch: 10 [57600/60000 (96%)]\tLoss: 0.073391\n",
      "Train Epoch: 10 [58240/60000 (97%)]\tLoss: 0.003393\n",
      "Train Epoch: 10 [58880/60000 (98%)]\tLoss: 0.000945\n",
      "Train Epoch: 10 [59520/60000 (99%)]\tLoss: 0.000381\n",
      "\n",
      "Test set: Avg. loss: 0.0357, Accuracy: 9891/10000 (99%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, n_epochs + 1):\n",
    "  \n",
    "  train(epoch)\n",
    "  test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 18 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def visualize_attention(att_net, test_loader):\n",
    "    \n",
    "    for (inputs, labels) in test_loader:\n",
    "        \n",
    "        plt.figure(figsize=[10, 5])\n",
    "        \n",
    "        for i in range(2):\n",
    "            plt.subplot(2, 9, 1 + 9*i)\n",
    "            if i == 0:\n",
    "                plt.title('input')\n",
    "        \n",
    "            plt.axis('off')\n",
    "            plt.imshow(inputs[i, 0].data.cpu().numpy(), cmap='Greys')\n",
    "            \n",
    "            oris, atts = get_attention(att_net, inputs[i:(i+1)])\n",
    "            \n",
    "            for j, (ori, att) in enumerate(zip(oris, atts)):\n",
    "                \n",
    "                plt.subplot(2, 9, 2*j + 9 * i + 2)\n",
    "                if i == 0:\n",
    "                    plt.title('Original')\n",
    "                \n",
    "                tmp = ori.data.cpu().numpy()\n",
    "                plt.axis('off')\n",
    "                plt.imshow(tmp[0, 0], cmap='Greys')\n",
    "                \n",
    "                plt.subplot(2, 9, 2*j + 9 * i + 3)\n",
    "                \n",
    "                if i == 0:\n",
    "                    plt.title('Attention')\n",
    "                    \n",
    "                tmp = att.data.cpu().numpy()\n",
    "                \n",
    "                plt.axis('off')\n",
    "                plt.imshow(tmp[0, 0], cmap='Greys')\n",
    "       \n",
    "        break\n",
    "        \n",
    "def get_attention(att_net, x):\n",
    "        \n",
    "    attention1 = F.sigmoid(att_net.attention1(x))\n",
    "    x1_ori = att_net.conv1(x)\n",
    "    x1 = x1_ori * attention1\n",
    "    x = F.relu(F.max_pool2d(x1, 2))\n",
    "\n",
    "    attention2 = F.sigmoid(att_net.attention2(x))\n",
    "    x2_ori = att_net.conv2(x)\n",
    "    x2 = x2_ori * attention2\n",
    "    x = F.relu(F.max_pool2d(x2, 2))\n",
    "\n",
    "    attention3 = F.sigmoid(att_net.attention3(x))\n",
    "    x3_ori = att_net.conv3(x)\n",
    "    x3 = x3_ori * attention3\n",
    "    x = F.relu(F.max_pool2d(x3, 2))\n",
    "\n",
    "    attention4 = F.sigmoid(att_net.attention4(x))\n",
    "    x4_ori = att_net.conv4(x)\n",
    "    x4 = x4_ori * attention4\n",
    "    x = F.relu(F.max_pool2d(x4, 2))\n",
    "    \n",
    "    return [x1_ori, x2_ori, x3_ori, x4_ori], [attention1, attention2, attention3, attention4]\n",
    "\n",
    "\n",
    "visualize_attention(network, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
