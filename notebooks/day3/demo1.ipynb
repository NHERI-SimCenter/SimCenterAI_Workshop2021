{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single-layer Perceptron Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hand-written digit classification with single-layer perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this demo, we will show how to use single-layer perceptron for hand-written digit classification. We will use MNIST as the dataset and build a single-layer perceptron. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set random seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fe5b6804d98>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_seed = 9999\n",
    "torch.backends.cudnn.enabled = False\n",
    "torch.manual_seed(random_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the dataset using Pytorch API. First we load the training set. The training set contains 60000 images and the test set contains 10000 images. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000\n"
     ]
    }
   ],
   "source": [
    "batch_size_train = 64\n",
    "batch_size_test = 1000\n",
    "\n",
    "\n",
    "trainset = torchvision.datasets.MNIST('./', train=True, download=True,\n",
    "                             transform=torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor(),\n",
    "                               torchvision.transforms.Normalize(\n",
    "                                 (0.1307,), (0.3081,))\n",
    "                             ]))\n",
    "\n",
    "print (len(trainset))\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size_train, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n"
     ]
    }
   ],
   "source": [
    "testset = torchvision.datasets.MNIST('./', train=False, download=True,\n",
    "                             transform=torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor(),\n",
    "                               torchvision.transforms.Normalize(\n",
    "                                 (0.1307,), (0.3081,))\n",
    "                             ]))\n",
    "\n",
    "print (len(testset))\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(testset, batch_size=batch_size_test, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's show some example images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = enumerate(test_loader)\n",
    "batch_idx, (example_data, example_targets) = next(examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig = plt.figure()\n",
    "\n",
    "for i in range(5):\n",
    "  plt.subplot(1,5,i+1)\n",
    "  plt.tight_layout()\n",
    "  plt.imshow(example_data[i][0], cmap='gray', interpolation='none')\n",
    "  plt.xticks([])\n",
    "  plt.yticks([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's build a single-layer perceptron With Pytorch, we can use nn.Linear to construct one fully-connected layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(784, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc1(x)\n",
    "\n",
    "        return F.log_softmax(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SLP(\n",
      "  (fc1): Linear(in_features=784, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "network = SLP()\n",
    "\n",
    "print (network)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For training the network, we need to specify the optimizer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 10\n",
    "learning_rate = 0.01\n",
    "momentum = 0.9\n",
    "log_interval = 10\n",
    "\n",
    "optimizer = optim.SGD(network.parameters(), lr=learning_rate,\n",
    "                      momentum=momentum)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses = []\n",
    "test_losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "  network.train()\n",
    "   \n",
    "  train_loss = 0\n",
    "\n",
    "  for batch_idx, (data, target) in enumerate(train_loader):\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    output = network(data)\n",
    "    loss = F.nll_loss(output, target)\n",
    "    \n",
    "    train_loss += loss.item()\n",
    "    \n",
    "    loss.backward()\n",
    "    \n",
    "    optimizer.step()\n",
    "    \n",
    "    if batch_idx % log_interval == 0:\n",
    "      print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "        epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "        100. * batch_idx / len(train_loader), loss.item()))\n",
    "    \n",
    "  \n",
    "  train_loss /= len(train_loader.dataset)\n",
    "  train_losses.append(train_loss)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "  network.eval()\n",
    "\n",
    "  test_loss = 0\n",
    "  correct = 0\n",
    "  with torch.no_grad():\n",
    "    for data, target in test_loader:\n",
    "      output = network(data)\n",
    "      test_loss += F.nll_loss(output, target, size_average=False).item()\n",
    "      pred = output.data.max(1, keepdim=True)[1]\n",
    "      correct += pred.eq(target.data.view_as(pred)).sum()\n",
    "  \n",
    "  test_loss /= len(test_loader.dataset)\n",
    "  test_losses.append(test_loss)\n",
    "\n",
    "  print('\\nTest set: Avg. loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "    test_loss, correct, len(test_loader.dataset),\n",
    "    100. * correct / len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/envs/env_pytorch/lib/python3.6/site-packages/ipykernel_launcher.py:10: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.371927\n",
      "Train Epoch: 1 [640/60000 (1%)]\tLoss: 0.950957\n",
      "Train Epoch: 1 [1280/60000 (2%)]\tLoss: 0.621171\n",
      "Train Epoch: 1 [1920/60000 (3%)]\tLoss: 0.517256\n",
      "Train Epoch: 1 [2560/60000 (4%)]\tLoss: 0.377511\n",
      "Train Epoch: 1 [3200/60000 (5%)]\tLoss: 0.270965\n",
      "Train Epoch: 1 [3840/60000 (6%)]\tLoss: 0.411616\n",
      "Train Epoch: 1 [4480/60000 (7%)]\tLoss: 0.516832\n",
      "Train Epoch: 1 [5120/60000 (9%)]\tLoss: 0.221167\n",
      "Train Epoch: 1 [5760/60000 (10%)]\tLoss: 0.634753\n",
      "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 0.288512\n",
      "Train Epoch: 1 [7040/60000 (12%)]\tLoss: 0.743134\n",
      "Train Epoch: 1 [7680/60000 (13%)]\tLoss: 0.454767\n",
      "Train Epoch: 1 [8320/60000 (14%)]\tLoss: 0.368022\n",
      "Train Epoch: 1 [8960/60000 (15%)]\tLoss: 0.445334\n",
      "Train Epoch: 1 [9600/60000 (16%)]\tLoss: 0.705600\n",
      "Train Epoch: 1 [10240/60000 (17%)]\tLoss: 0.155121\n",
      "Train Epoch: 1 [10880/60000 (18%)]\tLoss: 0.325756\n",
      "Train Epoch: 1 [11520/60000 (19%)]\tLoss: 0.407378\n",
      "Train Epoch: 1 [12160/60000 (20%)]\tLoss: 0.278202\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.296417\n",
      "Train Epoch: 1 [13440/60000 (22%)]\tLoss: 0.199690\n",
      "Train Epoch: 1 [14080/60000 (23%)]\tLoss: 0.213993\n",
      "Train Epoch: 1 [14720/60000 (25%)]\tLoss: 0.427253\n",
      "Train Epoch: 1 [15360/60000 (26%)]\tLoss: 0.185388\n",
      "Train Epoch: 1 [16000/60000 (27%)]\tLoss: 0.406336\n",
      "Train Epoch: 1 [16640/60000 (28%)]\tLoss: 0.248475\n",
      "Train Epoch: 1 [17280/60000 (29%)]\tLoss: 0.514689\n",
      "Train Epoch: 1 [17920/60000 (30%)]\tLoss: 0.450773\n",
      "Train Epoch: 1 [18560/60000 (31%)]\tLoss: 0.297135\n",
      "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 0.207207\n",
      "Train Epoch: 1 [19840/60000 (33%)]\tLoss: 0.273851\n",
      "Train Epoch: 1 [20480/60000 (34%)]\tLoss: 0.399163\n",
      "Train Epoch: 1 [21120/60000 (35%)]\tLoss: 0.455132\n",
      "Train Epoch: 1 [21760/60000 (36%)]\tLoss: 0.236943\n",
      "Train Epoch: 1 [22400/60000 (37%)]\tLoss: 0.427078\n",
      "Train Epoch: 1 [23040/60000 (38%)]\tLoss: 0.203549\n",
      "Train Epoch: 1 [23680/60000 (39%)]\tLoss: 0.343638\n",
      "Train Epoch: 1 [24320/60000 (41%)]\tLoss: 0.626699\n",
      "Train Epoch: 1 [24960/60000 (42%)]\tLoss: 0.533097\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.264225\n",
      "Train Epoch: 1 [26240/60000 (44%)]\tLoss: 0.233988\n",
      "Train Epoch: 1 [26880/60000 (45%)]\tLoss: 0.165909\n",
      "Train Epoch: 1 [27520/60000 (46%)]\tLoss: 0.285304\n",
      "Train Epoch: 1 [28160/60000 (47%)]\tLoss: 0.566390\n",
      "Train Epoch: 1 [28800/60000 (48%)]\tLoss: 0.175187\n",
      "Train Epoch: 1 [29440/60000 (49%)]\tLoss: 0.390240\n",
      "Train Epoch: 1 [30080/60000 (50%)]\tLoss: 0.332457\n",
      "Train Epoch: 1 [30720/60000 (51%)]\tLoss: 0.478713\n",
      "Train Epoch: 1 [31360/60000 (52%)]\tLoss: 0.395661\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.342867\n",
      "Train Epoch: 1 [32640/60000 (54%)]\tLoss: 0.454866\n",
      "Train Epoch: 1 [33280/60000 (55%)]\tLoss: 0.560547\n",
      "Train Epoch: 1 [33920/60000 (57%)]\tLoss: 0.424467\n",
      "Train Epoch: 1 [34560/60000 (58%)]\tLoss: 0.170450\n",
      "Train Epoch: 1 [35200/60000 (59%)]\tLoss: 0.234848\n",
      "Train Epoch: 1 [35840/60000 (60%)]\tLoss: 0.222648\n",
      "Train Epoch: 1 [36480/60000 (61%)]\tLoss: 0.308090\n",
      "Train Epoch: 1 [37120/60000 (62%)]\tLoss: 0.400350\n",
      "Train Epoch: 1 [37760/60000 (63%)]\tLoss: 0.317063\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.365110\n",
      "Train Epoch: 1 [39040/60000 (65%)]\tLoss: 0.183586\n",
      "Train Epoch: 1 [39680/60000 (66%)]\tLoss: 0.429989\n",
      "Train Epoch: 1 [40320/60000 (67%)]\tLoss: 0.359937\n",
      "Train Epoch: 1 [40960/60000 (68%)]\tLoss: 0.440310\n",
      "Train Epoch: 1 [41600/60000 (69%)]\tLoss: 0.343495\n",
      "Train Epoch: 1 [42240/60000 (70%)]\tLoss: 0.122780\n",
      "Train Epoch: 1 [42880/60000 (71%)]\tLoss: 0.385473\n",
      "Train Epoch: 1 [43520/60000 (72%)]\tLoss: 0.280955\n",
      "Train Epoch: 1 [44160/60000 (74%)]\tLoss: 0.155159\n",
      "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.716768\n",
      "Train Epoch: 1 [45440/60000 (76%)]\tLoss: 0.602397\n",
      "Train Epoch: 1 [46080/60000 (77%)]\tLoss: 0.323437\n",
      "Train Epoch: 1 [46720/60000 (78%)]\tLoss: 0.184033\n",
      "Train Epoch: 1 [47360/60000 (79%)]\tLoss: 0.196319\n",
      "Train Epoch: 1 [48000/60000 (80%)]\tLoss: 0.389258\n",
      "Train Epoch: 1 [48640/60000 (81%)]\tLoss: 0.301810\n",
      "Train Epoch: 1 [49280/60000 (82%)]\tLoss: 0.417607\n",
      "Train Epoch: 1 [49920/60000 (83%)]\tLoss: 0.150836\n",
      "Train Epoch: 1 [50560/60000 (84%)]\tLoss: 0.426514\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.229711\n",
      "Train Epoch: 1 [51840/60000 (86%)]\tLoss: 0.211200\n",
      "Train Epoch: 1 [52480/60000 (87%)]\tLoss: 0.276702\n",
      "Train Epoch: 1 [53120/60000 (88%)]\tLoss: 0.141683\n",
      "Train Epoch: 1 [53760/60000 (90%)]\tLoss: 0.369555\n",
      "Train Epoch: 1 [54400/60000 (91%)]\tLoss: 0.587090\n",
      "Train Epoch: 1 [55040/60000 (92%)]\tLoss: 0.270868\n",
      "Train Epoch: 1 [55680/60000 (93%)]\tLoss: 0.380043\n",
      "Train Epoch: 1 [56320/60000 (94%)]\tLoss: 0.185689\n",
      "Train Epoch: 1 [56960/60000 (95%)]\tLoss: 0.220300\n",
      "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.156264\n",
      "Train Epoch: 1 [58240/60000 (97%)]\tLoss: 0.315529\n",
      "Train Epoch: 1 [58880/60000 (98%)]\tLoss: 0.298360\n",
      "Train Epoch: 1 [59520/60000 (99%)]\tLoss: 0.119479\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yunhui.guo/.local/lib/python3.6/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.2975, Accuracy: 9168/10000 (92%)\n",
      "\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.328479\n",
      "Train Epoch: 2 [640/60000 (1%)]\tLoss: 0.185679\n",
      "Train Epoch: 2 [1280/60000 (2%)]\tLoss: 0.199018\n",
      "Train Epoch: 2 [1920/60000 (3%)]\tLoss: 0.175905\n",
      "Train Epoch: 2 [2560/60000 (4%)]\tLoss: 0.194434\n",
      "Train Epoch: 2 [3200/60000 (5%)]\tLoss: 0.256664\n",
      "Train Epoch: 2 [3840/60000 (6%)]\tLoss: 0.298762\n",
      "Train Epoch: 2 [4480/60000 (7%)]\tLoss: 0.306421\n",
      "Train Epoch: 2 [5120/60000 (9%)]\tLoss: 0.339928\n",
      "Train Epoch: 2 [5760/60000 (10%)]\tLoss: 0.370670\n",
      "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 0.237032\n",
      "Train Epoch: 2 [7040/60000 (12%)]\tLoss: 0.249052\n",
      "Train Epoch: 2 [7680/60000 (13%)]\tLoss: 0.229336\n",
      "Train Epoch: 2 [8320/60000 (14%)]\tLoss: 0.244482\n",
      "Train Epoch: 2 [8960/60000 (15%)]\tLoss: 0.462189\n",
      "Train Epoch: 2 [9600/60000 (16%)]\tLoss: 0.253406\n",
      "Train Epoch: 2 [10240/60000 (17%)]\tLoss: 0.114009\n",
      "Train Epoch: 2 [10880/60000 (18%)]\tLoss: 0.447618\n",
      "Train Epoch: 2 [11520/60000 (19%)]\tLoss: 0.278281\n",
      "Train Epoch: 2 [12160/60000 (20%)]\tLoss: 0.413684\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.288123\n",
      "Train Epoch: 2 [13440/60000 (22%)]\tLoss: 0.178571\n",
      "Train Epoch: 2 [14080/60000 (23%)]\tLoss: 0.320176\n",
      "Train Epoch: 2 [14720/60000 (25%)]\tLoss: 0.324275\n",
      "Train Epoch: 2 [15360/60000 (26%)]\tLoss: 0.218144\n",
      "Train Epoch: 2 [16000/60000 (27%)]\tLoss: 0.293800\n",
      "Train Epoch: 2 [16640/60000 (28%)]\tLoss: 0.468451\n",
      "Train Epoch: 2 [17280/60000 (29%)]\tLoss: 0.262314\n",
      "Train Epoch: 2 [17920/60000 (30%)]\tLoss: 0.416451\n",
      "Train Epoch: 2 [18560/60000 (31%)]\tLoss: 0.595173\n",
      "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 0.236066\n",
      "Train Epoch: 2 [19840/60000 (33%)]\tLoss: 0.347495\n",
      "Train Epoch: 2 [20480/60000 (34%)]\tLoss: 0.197101\n",
      "Train Epoch: 2 [21120/60000 (35%)]\tLoss: 0.118248\n",
      "Train Epoch: 2 [21760/60000 (36%)]\tLoss: 0.065765\n",
      "Train Epoch: 2 [22400/60000 (37%)]\tLoss: 0.196262\n",
      "Train Epoch: 2 [23040/60000 (38%)]\tLoss: 0.238425\n",
      "Train Epoch: 2 [23680/60000 (39%)]\tLoss: 0.253096\n",
      "Train Epoch: 2 [24320/60000 (41%)]\tLoss: 0.457371\n",
      "Train Epoch: 2 [24960/60000 (42%)]\tLoss: 0.302615\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.357421\n",
      "Train Epoch: 2 [26240/60000 (44%)]\tLoss: 0.657818\n",
      "Train Epoch: 2 [26880/60000 (45%)]\tLoss: 0.178178\n",
      "Train Epoch: 2 [27520/60000 (46%)]\tLoss: 0.228278\n",
      "Train Epoch: 2 [28160/60000 (47%)]\tLoss: 0.184616\n",
      "Train Epoch: 2 [28800/60000 (48%)]\tLoss: 0.348446\n",
      "Train Epoch: 2 [29440/60000 (49%)]\tLoss: 0.546409\n",
      "Train Epoch: 2 [30080/60000 (50%)]\tLoss: 0.606295\n",
      "Train Epoch: 2 [30720/60000 (51%)]\tLoss: 0.257907\n",
      "Train Epoch: 2 [31360/60000 (52%)]\tLoss: 0.311898\n",
      "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.218283\n",
      "Train Epoch: 2 [32640/60000 (54%)]\tLoss: 0.416763\n",
      "Train Epoch: 2 [33280/60000 (55%)]\tLoss: 0.314339\n",
      "Train Epoch: 2 [33920/60000 (57%)]\tLoss: 0.425515\n",
      "Train Epoch: 2 [34560/60000 (58%)]\tLoss: 0.188736\n",
      "Train Epoch: 2 [35200/60000 (59%)]\tLoss: 0.276382\n",
      "Train Epoch: 2 [35840/60000 (60%)]\tLoss: 0.197661\n",
      "Train Epoch: 2 [36480/60000 (61%)]\tLoss: 0.300432\n",
      "Train Epoch: 2 [37120/60000 (62%)]\tLoss: 0.201725\n",
      "Train Epoch: 2 [37760/60000 (63%)]\tLoss: 0.389495\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.159507\n",
      "Train Epoch: 2 [39040/60000 (65%)]\tLoss: 0.542740\n",
      "Train Epoch: 2 [39680/60000 (66%)]\tLoss: 0.465079\n",
      "Train Epoch: 2 [40320/60000 (67%)]\tLoss: 0.377516\n",
      "Train Epoch: 2 [40960/60000 (68%)]\tLoss: 0.340034\n",
      "Train Epoch: 2 [41600/60000 (69%)]\tLoss: 0.197535\n",
      "Train Epoch: 2 [42240/60000 (70%)]\tLoss: 0.239817\n",
      "Train Epoch: 2 [42880/60000 (71%)]\tLoss: 0.359234\n",
      "Train Epoch: 2 [43520/60000 (72%)]\tLoss: 0.210670\n",
      "Train Epoch: 2 [44160/60000 (74%)]\tLoss: 0.274267\n",
      "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 0.163590\n",
      "Train Epoch: 2 [45440/60000 (76%)]\tLoss: 0.403036\n",
      "Train Epoch: 2 [46080/60000 (77%)]\tLoss: 0.279507\n",
      "Train Epoch: 2 [46720/60000 (78%)]\tLoss: 0.165975\n",
      "Train Epoch: 2 [47360/60000 (79%)]\tLoss: 0.382262\n",
      "Train Epoch: 2 [48000/60000 (80%)]\tLoss: 0.306926\n",
      "Train Epoch: 2 [48640/60000 (81%)]\tLoss: 0.566607\n",
      "Train Epoch: 2 [49280/60000 (82%)]\tLoss: 0.215321\n",
      "Train Epoch: 2 [49920/60000 (83%)]\tLoss: 0.252860\n",
      "Train Epoch: 2 [50560/60000 (84%)]\tLoss: 0.598978\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.187940\n",
      "Train Epoch: 2 [51840/60000 (86%)]\tLoss: 0.393542\n",
      "Train Epoch: 2 [52480/60000 (87%)]\tLoss: 0.453803\n",
      "Train Epoch: 2 [53120/60000 (88%)]\tLoss: 0.215712\n",
      "Train Epoch: 2 [53760/60000 (90%)]\tLoss: 0.423921\n",
      "Train Epoch: 2 [54400/60000 (91%)]\tLoss: 0.206992\n",
      "Train Epoch: 2 [55040/60000 (92%)]\tLoss: 0.228558\n",
      "Train Epoch: 2 [55680/60000 (93%)]\tLoss: 0.333027\n",
      "Train Epoch: 2 [56320/60000 (94%)]\tLoss: 0.393352\n",
      "Train Epoch: 2 [56960/60000 (95%)]\tLoss: 0.170040\n",
      "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 0.174376\n",
      "Train Epoch: 2 [58240/60000 (97%)]\tLoss: 0.227932\n",
      "Train Epoch: 2 [58880/60000 (98%)]\tLoss: 0.395568\n",
      "Train Epoch: 2 [59520/60000 (99%)]\tLoss: 0.252942\n",
      "\n",
      "Test set: Avg. loss: 0.3085, Accuracy: 9144/10000 (91%)\n",
      "\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.219274\n",
      "Train Epoch: 3 [640/60000 (1%)]\tLoss: 0.228602\n",
      "Train Epoch: 3 [1280/60000 (2%)]\tLoss: 0.385268\n",
      "Train Epoch: 3 [1920/60000 (3%)]\tLoss: 0.246790\n",
      "Train Epoch: 3 [2560/60000 (4%)]\tLoss: 0.396218\n",
      "Train Epoch: 3 [3200/60000 (5%)]\tLoss: 0.313637\n",
      "Train Epoch: 3 [3840/60000 (6%)]\tLoss: 0.124544\n",
      "Train Epoch: 3 [4480/60000 (7%)]\tLoss: 0.289874\n",
      "Train Epoch: 3 [5120/60000 (9%)]\tLoss: 0.101460\n",
      "Train Epoch: 3 [5760/60000 (10%)]\tLoss: 0.277182\n",
      "Train Epoch: 3 [6400/60000 (11%)]\tLoss: 0.195054\n",
      "Train Epoch: 3 [7040/60000 (12%)]\tLoss: 0.169559\n",
      "Train Epoch: 3 [7680/60000 (13%)]\tLoss: 0.392474\n",
      "Train Epoch: 3 [8320/60000 (14%)]\tLoss: 0.196267\n",
      "Train Epoch: 3 [8960/60000 (15%)]\tLoss: 0.429681\n",
      "Train Epoch: 3 [9600/60000 (16%)]\tLoss: 0.423261\n",
      "Train Epoch: 3 [10240/60000 (17%)]\tLoss: 0.275126\n",
      "Train Epoch: 3 [10880/60000 (18%)]\tLoss: 0.610633\n",
      "Train Epoch: 3 [11520/60000 (19%)]\tLoss: 0.295835\n",
      "Train Epoch: 3 [12160/60000 (20%)]\tLoss: 0.670872\n",
      "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.452594\n",
      "Train Epoch: 3 [13440/60000 (22%)]\tLoss: 0.277812\n",
      "Train Epoch: 3 [14080/60000 (23%)]\tLoss: 0.294934\n",
      "Train Epoch: 3 [14720/60000 (25%)]\tLoss: 0.158016\n",
      "Train Epoch: 3 [15360/60000 (26%)]\tLoss: 0.367057\n",
      "Train Epoch: 3 [16000/60000 (27%)]\tLoss: 0.398302\n",
      "Train Epoch: 3 [16640/60000 (28%)]\tLoss: 0.472751\n",
      "Train Epoch: 3 [17280/60000 (29%)]\tLoss: 0.259628\n",
      "Train Epoch: 3 [17920/60000 (30%)]\tLoss: 0.339218\n",
      "Train Epoch: 3 [18560/60000 (31%)]\tLoss: 0.195677\n",
      "Train Epoch: 3 [19200/60000 (32%)]\tLoss: 0.174125\n",
      "Train Epoch: 3 [19840/60000 (33%)]\tLoss: 0.087226\n",
      "Train Epoch: 3 [20480/60000 (34%)]\tLoss: 0.187332\n",
      "Train Epoch: 3 [21120/60000 (35%)]\tLoss: 0.274680\n",
      "Train Epoch: 3 [21760/60000 (36%)]\tLoss: 0.410313\n",
      "Train Epoch: 3 [22400/60000 (37%)]\tLoss: 0.452312\n",
      "Train Epoch: 3 [23040/60000 (38%)]\tLoss: 0.176466\n",
      "Train Epoch: 3 [23680/60000 (39%)]\tLoss: 0.203590\n",
      "Train Epoch: 3 [24320/60000 (41%)]\tLoss: 0.334763\n",
      "Train Epoch: 3 [24960/60000 (42%)]\tLoss: 0.303070\n",
      "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.583028\n",
      "Train Epoch: 3 [26240/60000 (44%)]\tLoss: 0.147893\n",
      "Train Epoch: 3 [26880/60000 (45%)]\tLoss: 0.487914\n",
      "Train Epoch: 3 [27520/60000 (46%)]\tLoss: 0.219316\n",
      "Train Epoch: 3 [28160/60000 (47%)]\tLoss: 0.048817\n",
      "Train Epoch: 3 [28800/60000 (48%)]\tLoss: 0.264374\n",
      "Train Epoch: 3 [29440/60000 (49%)]\tLoss: 0.367597\n",
      "Train Epoch: 3 [30080/60000 (50%)]\tLoss: 0.307323\n",
      "Train Epoch: 3 [30720/60000 (51%)]\tLoss: 0.229073\n",
      "Train Epoch: 3 [31360/60000 (52%)]\tLoss: 0.348907\n",
      "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.187792\n",
      "Train Epoch: 3 [32640/60000 (54%)]\tLoss: 0.406313\n",
      "Train Epoch: 3 [33280/60000 (55%)]\tLoss: 0.822572\n",
      "Train Epoch: 3 [33920/60000 (57%)]\tLoss: 0.250625\n",
      "Train Epoch: 3 [34560/60000 (58%)]\tLoss: 0.330129\n",
      "Train Epoch: 3 [35200/60000 (59%)]\tLoss: 0.394170\n",
      "Train Epoch: 3 [35840/60000 (60%)]\tLoss: 0.418911\n",
      "Train Epoch: 3 [36480/60000 (61%)]\tLoss: 0.364813\n",
      "Train Epoch: 3 [37120/60000 (62%)]\tLoss: 0.399220\n",
      "Train Epoch: 3 [37760/60000 (63%)]\tLoss: 0.198428\n",
      "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.209327\n",
      "Train Epoch: 3 [39040/60000 (65%)]\tLoss: 0.265123\n",
      "Train Epoch: 3 [39680/60000 (66%)]\tLoss: 0.242674\n",
      "Train Epoch: 3 [40320/60000 (67%)]\tLoss: 0.272180\n",
      "Train Epoch: 3 [40960/60000 (68%)]\tLoss: 0.107372\n",
      "Train Epoch: 3 [41600/60000 (69%)]\tLoss: 0.598663\n",
      "Train Epoch: 3 [42240/60000 (70%)]\tLoss: 0.123535\n",
      "Train Epoch: 3 [42880/60000 (71%)]\tLoss: 0.378440\n",
      "Train Epoch: 3 [43520/60000 (72%)]\tLoss: 0.136997\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 3 [44160/60000 (74%)]\tLoss: 0.396832\n",
      "Train Epoch: 3 [44800/60000 (75%)]\tLoss: 0.494096\n",
      "Train Epoch: 3 [45440/60000 (76%)]\tLoss: 0.249208\n",
      "Train Epoch: 3 [46080/60000 (77%)]\tLoss: 0.402332\n",
      "Train Epoch: 3 [46720/60000 (78%)]\tLoss: 0.120111\n",
      "Train Epoch: 3 [47360/60000 (79%)]\tLoss: 0.153164\n",
      "Train Epoch: 3 [48000/60000 (80%)]\tLoss: 0.499972\n",
      "Train Epoch: 3 [48640/60000 (81%)]\tLoss: 0.505379\n",
      "Train Epoch: 3 [49280/60000 (82%)]\tLoss: 0.239145\n",
      "Train Epoch: 3 [49920/60000 (83%)]\tLoss: 0.503950\n",
      "Train Epoch: 3 [50560/60000 (84%)]\tLoss: 0.334602\n",
      "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.230572\n",
      "Train Epoch: 3 [51840/60000 (86%)]\tLoss: 0.235243\n",
      "Train Epoch: 3 [52480/60000 (87%)]\tLoss: 0.256618\n",
      "Train Epoch: 3 [53120/60000 (88%)]\tLoss: 0.170759\n",
      "Train Epoch: 3 [53760/60000 (90%)]\tLoss: 0.256494\n",
      "Train Epoch: 3 [54400/60000 (91%)]\tLoss: 0.179507\n",
      "Train Epoch: 3 [55040/60000 (92%)]\tLoss: 0.245169\n",
      "Train Epoch: 3 [55680/60000 (93%)]\tLoss: 0.317535\n",
      "Train Epoch: 3 [56320/60000 (94%)]\tLoss: 0.403283\n",
      "Train Epoch: 3 [56960/60000 (95%)]\tLoss: 0.301435\n",
      "Train Epoch: 3 [57600/60000 (96%)]\tLoss: 0.318029\n",
      "Train Epoch: 3 [58240/60000 (97%)]\tLoss: 0.133642\n",
      "Train Epoch: 3 [58880/60000 (98%)]\tLoss: 0.461910\n",
      "Train Epoch: 3 [59520/60000 (99%)]\tLoss: 0.457806\n",
      "\n",
      "Test set: Avg. loss: 0.3362, Accuracy: 9072/10000 (91%)\n",
      "\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.409815\n",
      "Train Epoch: 4 [640/60000 (1%)]\tLoss: 0.211733\n",
      "Train Epoch: 4 [1280/60000 (2%)]\tLoss: 0.399991\n",
      "Train Epoch: 4 [1920/60000 (3%)]\tLoss: 0.613075\n",
      "Train Epoch: 4 [2560/60000 (4%)]\tLoss: 0.203205\n",
      "Train Epoch: 4 [3200/60000 (5%)]\tLoss: 0.194542\n",
      "Train Epoch: 4 [3840/60000 (6%)]\tLoss: 0.303405\n",
      "Train Epoch: 4 [4480/60000 (7%)]\tLoss: 0.176874\n",
      "Train Epoch: 4 [5120/60000 (9%)]\tLoss: 0.265551\n",
      "Train Epoch: 4 [5760/60000 (10%)]\tLoss: 0.137295\n",
      "Train Epoch: 4 [6400/60000 (11%)]\tLoss: 0.131621\n",
      "Train Epoch: 4 [7040/60000 (12%)]\tLoss: 0.215562\n",
      "Train Epoch: 4 [7680/60000 (13%)]\tLoss: 0.215691\n",
      "Train Epoch: 4 [8320/60000 (14%)]\tLoss: 0.185415\n",
      "Train Epoch: 4 [8960/60000 (15%)]\tLoss: 0.210448\n",
      "Train Epoch: 4 [9600/60000 (16%)]\tLoss: 0.163018\n",
      "Train Epoch: 4 [10240/60000 (17%)]\tLoss: 0.200009\n",
      "Train Epoch: 4 [10880/60000 (18%)]\tLoss: 0.111602\n",
      "Train Epoch: 4 [11520/60000 (19%)]\tLoss: 0.485386\n",
      "Train Epoch: 4 [12160/60000 (20%)]\tLoss: 0.173830\n",
      "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 0.327658\n",
      "Train Epoch: 4 [13440/60000 (22%)]\tLoss: 0.494418\n",
      "Train Epoch: 4 [14080/60000 (23%)]\tLoss: 0.184725\n",
      "Train Epoch: 4 [14720/60000 (25%)]\tLoss: 0.405817\n",
      "Train Epoch: 4 [15360/60000 (26%)]\tLoss: 0.153359\n",
      "Train Epoch: 4 [16000/60000 (27%)]\tLoss: 0.300225\n",
      "Train Epoch: 4 [16640/60000 (28%)]\tLoss: 0.192372\n",
      "Train Epoch: 4 [17280/60000 (29%)]\tLoss: 0.325098\n",
      "Train Epoch: 4 [17920/60000 (30%)]\tLoss: 0.153453\n",
      "Train Epoch: 4 [18560/60000 (31%)]\tLoss: 0.183498\n",
      "Train Epoch: 4 [19200/60000 (32%)]\tLoss: 0.292623\n",
      "Train Epoch: 4 [19840/60000 (33%)]\tLoss: 0.210822\n",
      "Train Epoch: 4 [20480/60000 (34%)]\tLoss: 0.391382\n",
      "Train Epoch: 4 [21120/60000 (35%)]\tLoss: 0.174992\n",
      "Train Epoch: 4 [21760/60000 (36%)]\tLoss: 0.254910\n",
      "Train Epoch: 4 [22400/60000 (37%)]\tLoss: 0.157634\n",
      "Train Epoch: 4 [23040/60000 (38%)]\tLoss: 0.103248\n",
      "Train Epoch: 4 [23680/60000 (39%)]\tLoss: 0.466849\n",
      "Train Epoch: 4 [24320/60000 (41%)]\tLoss: 0.453928\n",
      "Train Epoch: 4 [24960/60000 (42%)]\tLoss: 0.145301\n",
      "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 0.209148\n",
      "Train Epoch: 4 [26240/60000 (44%)]\tLoss: 0.266339\n",
      "Train Epoch: 4 [26880/60000 (45%)]\tLoss: 0.273915\n",
      "Train Epoch: 4 [27520/60000 (46%)]\tLoss: 0.140862\n",
      "Train Epoch: 4 [28160/60000 (47%)]\tLoss: 0.367522\n",
      "Train Epoch: 4 [28800/60000 (48%)]\tLoss: 0.310814\n",
      "Train Epoch: 4 [29440/60000 (49%)]\tLoss: 0.392451\n",
      "Train Epoch: 4 [30080/60000 (50%)]\tLoss: 0.142071\n",
      "Train Epoch: 4 [30720/60000 (51%)]\tLoss: 0.139553\n",
      "Train Epoch: 4 [31360/60000 (52%)]\tLoss: 0.346173\n",
      "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 0.255870\n",
      "Train Epoch: 4 [32640/60000 (54%)]\tLoss: 0.190447\n",
      "Train Epoch: 4 [33280/60000 (55%)]\tLoss: 0.334981\n",
      "Train Epoch: 4 [33920/60000 (57%)]\tLoss: 0.398797\n",
      "Train Epoch: 4 [34560/60000 (58%)]\tLoss: 0.290364\n",
      "Train Epoch: 4 [35200/60000 (59%)]\tLoss: 0.131953\n",
      "Train Epoch: 4 [35840/60000 (60%)]\tLoss: 0.158675\n",
      "Train Epoch: 4 [36480/60000 (61%)]\tLoss: 0.394824\n",
      "Train Epoch: 4 [37120/60000 (62%)]\tLoss: 0.202981\n",
      "Train Epoch: 4 [37760/60000 (63%)]\tLoss: 0.178843\n",
      "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 0.300079\n",
      "Train Epoch: 4 [39040/60000 (65%)]\tLoss: 0.156383\n",
      "Train Epoch: 4 [39680/60000 (66%)]\tLoss: 0.172569\n",
      "Train Epoch: 4 [40320/60000 (67%)]\tLoss: 0.246462\n",
      "Train Epoch: 4 [40960/60000 (68%)]\tLoss: 0.304706\n",
      "Train Epoch: 4 [41600/60000 (69%)]\tLoss: 0.258250\n",
      "Train Epoch: 4 [42240/60000 (70%)]\tLoss: 0.109664\n",
      "Train Epoch: 4 [42880/60000 (71%)]\tLoss: 0.235861\n",
      "Train Epoch: 4 [43520/60000 (72%)]\tLoss: 0.413676\n",
      "Train Epoch: 4 [44160/60000 (74%)]\tLoss: 0.144970\n",
      "Train Epoch: 4 [44800/60000 (75%)]\tLoss: 0.213427\n",
      "Train Epoch: 4 [45440/60000 (76%)]\tLoss: 0.456825\n",
      "Train Epoch: 4 [46080/60000 (77%)]\tLoss: 0.346338\n",
      "Train Epoch: 4 [46720/60000 (78%)]\tLoss: 0.236917\n",
      "Train Epoch: 4 [47360/60000 (79%)]\tLoss: 0.320251\n",
      "Train Epoch: 4 [48000/60000 (80%)]\tLoss: 0.342869\n",
      "Train Epoch: 4 [48640/60000 (81%)]\tLoss: 0.544009\n",
      "Train Epoch: 4 [49280/60000 (82%)]\tLoss: 0.209216\n",
      "Train Epoch: 4 [49920/60000 (83%)]\tLoss: 0.156829\n",
      "Train Epoch: 4 [50560/60000 (84%)]\tLoss: 0.303489\n",
      "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.279098\n",
      "Train Epoch: 4 [51840/60000 (86%)]\tLoss: 0.661923\n",
      "Train Epoch: 4 [52480/60000 (87%)]\tLoss: 0.266104\n",
      "Train Epoch: 4 [53120/60000 (88%)]\tLoss: 0.267805\n",
      "Train Epoch: 4 [53760/60000 (90%)]\tLoss: 0.185505\n",
      "Train Epoch: 4 [54400/60000 (91%)]\tLoss: 0.505831\n",
      "Train Epoch: 4 [55040/60000 (92%)]\tLoss: 0.406869\n",
      "Train Epoch: 4 [55680/60000 (93%)]\tLoss: 0.238133\n",
      "Train Epoch: 4 [56320/60000 (94%)]\tLoss: 0.217478\n",
      "Train Epoch: 4 [56960/60000 (95%)]\tLoss: 0.516800\n",
      "Train Epoch: 4 [57600/60000 (96%)]\tLoss: 0.595562\n",
      "Train Epoch: 4 [58240/60000 (97%)]\tLoss: 0.272248\n",
      "Train Epoch: 4 [58880/60000 (98%)]\tLoss: 0.338692\n",
      "Train Epoch: 4 [59520/60000 (99%)]\tLoss: 0.316451\n",
      "\n",
      "Test set: Avg. loss: 0.2985, Accuracy: 9197/10000 (92%)\n",
      "\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.243716\n",
      "Train Epoch: 5 [640/60000 (1%)]\tLoss: 0.185246\n",
      "Train Epoch: 5 [1280/60000 (2%)]\tLoss: 0.438245\n",
      "Train Epoch: 5 [1920/60000 (3%)]\tLoss: 0.208149\n",
      "Train Epoch: 5 [2560/60000 (4%)]\tLoss: 0.193755\n",
      "Train Epoch: 5 [3200/60000 (5%)]\tLoss: 0.326508\n",
      "Train Epoch: 5 [3840/60000 (6%)]\tLoss: 0.381654\n",
      "Train Epoch: 5 [4480/60000 (7%)]\tLoss: 0.132272\n",
      "Train Epoch: 5 [5120/60000 (9%)]\tLoss: 0.141285\n",
      "Train Epoch: 5 [5760/60000 (10%)]\tLoss: 0.336952\n",
      "Train Epoch: 5 [6400/60000 (11%)]\tLoss: 0.316923\n",
      "Train Epoch: 5 [7040/60000 (12%)]\tLoss: 0.321510\n",
      "Train Epoch: 5 [7680/60000 (13%)]\tLoss: 0.376778\n",
      "Train Epoch: 5 [8320/60000 (14%)]\tLoss: 0.270511\n",
      "Train Epoch: 5 [8960/60000 (15%)]\tLoss: 0.243857\n",
      "Train Epoch: 5 [9600/60000 (16%)]\tLoss: 0.486659\n",
      "Train Epoch: 5 [10240/60000 (17%)]\tLoss: 0.122635\n",
      "Train Epoch: 5 [10880/60000 (18%)]\tLoss: 0.130627\n",
      "Train Epoch: 5 [11520/60000 (19%)]\tLoss: 0.182772\n",
      "Train Epoch: 5 [12160/60000 (20%)]\tLoss: 0.171413\n",
      "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 0.221187\n",
      "Train Epoch: 5 [13440/60000 (22%)]\tLoss: 0.221913\n",
      "Train Epoch: 5 [14080/60000 (23%)]\tLoss: 0.218725\n",
      "Train Epoch: 5 [14720/60000 (25%)]\tLoss: 0.542248\n",
      "Train Epoch: 5 [15360/60000 (26%)]\tLoss: 0.490723\n",
      "Train Epoch: 5 [16000/60000 (27%)]\tLoss: 0.340446\n",
      "Train Epoch: 5 [16640/60000 (28%)]\tLoss: 0.271672\n",
      "Train Epoch: 5 [17280/60000 (29%)]\tLoss: 0.194386\n",
      "Train Epoch: 5 [17920/60000 (30%)]\tLoss: 0.572403\n",
      "Train Epoch: 5 [18560/60000 (31%)]\tLoss: 0.623359\n",
      "Train Epoch: 5 [19200/60000 (32%)]\tLoss: 0.242575\n",
      "Train Epoch: 5 [19840/60000 (33%)]\tLoss: 0.634330\n",
      "Train Epoch: 5 [20480/60000 (34%)]\tLoss: 0.197919\n",
      "Train Epoch: 5 [21120/60000 (35%)]\tLoss: 0.456591\n",
      "Train Epoch: 5 [21760/60000 (36%)]\tLoss: 0.355299\n",
      "Train Epoch: 5 [22400/60000 (37%)]\tLoss: 0.150123\n",
      "Train Epoch: 5 [23040/60000 (38%)]\tLoss: 0.256395\n",
      "Train Epoch: 5 [23680/60000 (39%)]\tLoss: 0.182720\n",
      "Train Epoch: 5 [24320/60000 (41%)]\tLoss: 0.091615\n",
      "Train Epoch: 5 [24960/60000 (42%)]\tLoss: 0.291499\n",
      "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 0.378260\n",
      "Train Epoch: 5 [26240/60000 (44%)]\tLoss: 0.291093\n",
      "Train Epoch: 5 [26880/60000 (45%)]\tLoss: 0.263293\n",
      "Train Epoch: 5 [27520/60000 (46%)]\tLoss: 0.664705\n",
      "Train Epoch: 5 [28160/60000 (47%)]\tLoss: 0.583617\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 5 [28800/60000 (48%)]\tLoss: 0.342276\n",
      "Train Epoch: 5 [29440/60000 (49%)]\tLoss: 0.328392\n",
      "Train Epoch: 5 [30080/60000 (50%)]\tLoss: 0.161274\n",
      "Train Epoch: 5 [30720/60000 (51%)]\tLoss: 0.152726\n",
      "Train Epoch: 5 [31360/60000 (52%)]\tLoss: 0.255858\n",
      "Train Epoch: 5 [32000/60000 (53%)]\tLoss: 0.484618\n",
      "Train Epoch: 5 [32640/60000 (54%)]\tLoss: 0.550561\n",
      "Train Epoch: 5 [33280/60000 (55%)]\tLoss: 0.279930\n",
      "Train Epoch: 5 [33920/60000 (57%)]\tLoss: 0.198227\n",
      "Train Epoch: 5 [34560/60000 (58%)]\tLoss: 0.260355\n",
      "Train Epoch: 5 [35200/60000 (59%)]\tLoss: 0.331112\n",
      "Train Epoch: 5 [35840/60000 (60%)]\tLoss: 0.253040\n",
      "Train Epoch: 5 [36480/60000 (61%)]\tLoss: 0.175776\n",
      "Train Epoch: 5 [37120/60000 (62%)]\tLoss: 0.305123\n",
      "Train Epoch: 5 [37760/60000 (63%)]\tLoss: 0.170347\n",
      "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 0.172111\n",
      "Train Epoch: 5 [39040/60000 (65%)]\tLoss: 0.188757\n",
      "Train Epoch: 5 [39680/60000 (66%)]\tLoss: 0.181922\n",
      "Train Epoch: 5 [40320/60000 (67%)]\tLoss: 0.346082\n",
      "Train Epoch: 5 [40960/60000 (68%)]\tLoss: 0.385594\n",
      "Train Epoch: 5 [41600/60000 (69%)]\tLoss: 0.257639\n",
      "Train Epoch: 5 [42240/60000 (70%)]\tLoss: 0.207624\n",
      "Train Epoch: 5 [42880/60000 (71%)]\tLoss: 0.368924\n",
      "Train Epoch: 5 [43520/60000 (72%)]\tLoss: 0.533581\n",
      "Train Epoch: 5 [44160/60000 (74%)]\tLoss: 0.547389\n",
      "Train Epoch: 5 [44800/60000 (75%)]\tLoss: 0.344554\n",
      "Train Epoch: 5 [45440/60000 (76%)]\tLoss: 0.171534\n",
      "Train Epoch: 5 [46080/60000 (77%)]\tLoss: 0.159374\n",
      "Train Epoch: 5 [46720/60000 (78%)]\tLoss: 0.176005\n",
      "Train Epoch: 5 [47360/60000 (79%)]\tLoss: 0.275941\n",
      "Train Epoch: 5 [48000/60000 (80%)]\tLoss: 0.369325\n",
      "Train Epoch: 5 [48640/60000 (81%)]\tLoss: 0.327446\n",
      "Train Epoch: 5 [49280/60000 (82%)]\tLoss: 0.286658\n",
      "Train Epoch: 5 [49920/60000 (83%)]\tLoss: 0.164557\n",
      "Train Epoch: 5 [50560/60000 (84%)]\tLoss: 0.120252\n",
      "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 0.246021\n",
      "Train Epoch: 5 [51840/60000 (86%)]\tLoss: 0.195232\n",
      "Train Epoch: 5 [52480/60000 (87%)]\tLoss: 0.205321\n",
      "Train Epoch: 5 [53120/60000 (88%)]\tLoss: 0.171032\n",
      "Train Epoch: 5 [53760/60000 (90%)]\tLoss: 0.361152\n",
      "Train Epoch: 5 [54400/60000 (91%)]\tLoss: 0.473504\n",
      "Train Epoch: 5 [55040/60000 (92%)]\tLoss: 0.238539\n",
      "Train Epoch: 5 [55680/60000 (93%)]\tLoss: 0.224167\n",
      "Train Epoch: 5 [56320/60000 (94%)]\tLoss: 0.251867\n",
      "Train Epoch: 5 [56960/60000 (95%)]\tLoss: 0.307040\n",
      "Train Epoch: 5 [57600/60000 (96%)]\tLoss: 0.286501\n",
      "Train Epoch: 5 [58240/60000 (97%)]\tLoss: 0.386921\n",
      "Train Epoch: 5 [58880/60000 (98%)]\tLoss: 0.286900\n",
      "Train Epoch: 5 [59520/60000 (99%)]\tLoss: 0.416592\n",
      "\n",
      "Test set: Avg. loss: 0.2971, Accuracy: 9180/10000 (92%)\n",
      "\n",
      "Train Epoch: 6 [0/60000 (0%)]\tLoss: 0.184306\n",
      "Train Epoch: 6 [640/60000 (1%)]\tLoss: 0.130904\n",
      "Train Epoch: 6 [1280/60000 (2%)]\tLoss: 0.112938\n",
      "Train Epoch: 6 [1920/60000 (3%)]\tLoss: 0.280753\n",
      "Train Epoch: 6 [2560/60000 (4%)]\tLoss: 0.382169\n",
      "Train Epoch: 6 [3200/60000 (5%)]\tLoss: 0.635454\n",
      "Train Epoch: 6 [3840/60000 (6%)]\tLoss: 0.204883\n",
      "Train Epoch: 6 [4480/60000 (7%)]\tLoss: 0.271758\n",
      "Train Epoch: 6 [5120/60000 (9%)]\tLoss: 0.178462\n",
      "Train Epoch: 6 [5760/60000 (10%)]\tLoss: 0.337989\n",
      "Train Epoch: 6 [6400/60000 (11%)]\tLoss: 0.188374\n",
      "Train Epoch: 6 [7040/60000 (12%)]\tLoss: 0.112032\n",
      "Train Epoch: 6 [7680/60000 (13%)]\tLoss: 0.283210\n",
      "Train Epoch: 6 [8320/60000 (14%)]\tLoss: 0.402366\n",
      "Train Epoch: 6 [8960/60000 (15%)]\tLoss: 0.169472\n",
      "Train Epoch: 6 [9600/60000 (16%)]\tLoss: 0.201657\n",
      "Train Epoch: 6 [10240/60000 (17%)]\tLoss: 0.344869\n",
      "Train Epoch: 6 [10880/60000 (18%)]\tLoss: 0.350587\n",
      "Train Epoch: 6 [11520/60000 (19%)]\tLoss: 0.400481\n",
      "Train Epoch: 6 [12160/60000 (20%)]\tLoss: 0.182398\n",
      "Train Epoch: 6 [12800/60000 (21%)]\tLoss: 0.386619\n",
      "Train Epoch: 6 [13440/60000 (22%)]\tLoss: 0.147437\n",
      "Train Epoch: 6 [14080/60000 (23%)]\tLoss: 0.316374\n",
      "Train Epoch: 6 [14720/60000 (25%)]\tLoss: 0.211390\n",
      "Train Epoch: 6 [15360/60000 (26%)]\tLoss: 0.164036\n",
      "Train Epoch: 6 [16000/60000 (27%)]\tLoss: 0.341789\n",
      "Train Epoch: 6 [16640/60000 (28%)]\tLoss: 0.201176\n",
      "Train Epoch: 6 [17280/60000 (29%)]\tLoss: 0.193476\n",
      "Train Epoch: 6 [17920/60000 (30%)]\tLoss: 0.335158\n",
      "Train Epoch: 6 [18560/60000 (31%)]\tLoss: 0.275530\n",
      "Train Epoch: 6 [19200/60000 (32%)]\tLoss: 0.119877\n",
      "Train Epoch: 6 [19840/60000 (33%)]\tLoss: 0.329243\n",
      "Train Epoch: 6 [20480/60000 (34%)]\tLoss: 0.522354\n",
      "Train Epoch: 6 [21120/60000 (35%)]\tLoss: 0.169152\n",
      "Train Epoch: 6 [21760/60000 (36%)]\tLoss: 0.415024\n",
      "Train Epoch: 6 [22400/60000 (37%)]\tLoss: 0.149746\n",
      "Train Epoch: 6 [23040/60000 (38%)]\tLoss: 0.247913\n",
      "Train Epoch: 6 [23680/60000 (39%)]\tLoss: 0.295695\n",
      "Train Epoch: 6 [24320/60000 (41%)]\tLoss: 0.194574\n",
      "Train Epoch: 6 [24960/60000 (42%)]\tLoss: 0.256710\n",
      "Train Epoch: 6 [25600/60000 (43%)]\tLoss: 0.160186\n",
      "Train Epoch: 6 [26240/60000 (44%)]\tLoss: 0.159603\n",
      "Train Epoch: 6 [26880/60000 (45%)]\tLoss: 0.138664\n",
      "Train Epoch: 6 [27520/60000 (46%)]\tLoss: 0.214008\n",
      "Train Epoch: 6 [28160/60000 (47%)]\tLoss: 0.295402\n",
      "Train Epoch: 6 [28800/60000 (48%)]\tLoss: 0.214521\n",
      "Train Epoch: 6 [29440/60000 (49%)]\tLoss: 0.503536\n",
      "Train Epoch: 6 [30080/60000 (50%)]\tLoss: 0.412792\n",
      "Train Epoch: 6 [30720/60000 (51%)]\tLoss: 0.275666\n",
      "Train Epoch: 6 [31360/60000 (52%)]\tLoss: 0.459066\n",
      "Train Epoch: 6 [32000/60000 (53%)]\tLoss: 0.252558\n",
      "Train Epoch: 6 [32640/60000 (54%)]\tLoss: 0.234406\n",
      "Train Epoch: 6 [33280/60000 (55%)]\tLoss: 0.420025\n",
      "Train Epoch: 6 [33920/60000 (57%)]\tLoss: 0.222526\n",
      "Train Epoch: 6 [34560/60000 (58%)]\tLoss: 0.206976\n",
      "Train Epoch: 6 [35200/60000 (59%)]\tLoss: 0.620973\n",
      "Train Epoch: 6 [35840/60000 (60%)]\tLoss: 0.715224\n",
      "Train Epoch: 6 [36480/60000 (61%)]\tLoss: 0.469408\n",
      "Train Epoch: 6 [37120/60000 (62%)]\tLoss: 0.159837\n",
      "Train Epoch: 6 [37760/60000 (63%)]\tLoss: 0.232576\n",
      "Train Epoch: 6 [38400/60000 (64%)]\tLoss: 0.068066\n",
      "Train Epoch: 6 [39040/60000 (65%)]\tLoss: 0.288175\n",
      "Train Epoch: 6 [39680/60000 (66%)]\tLoss: 0.434289\n",
      "Train Epoch: 6 [40320/60000 (67%)]\tLoss: 0.189277\n",
      "Train Epoch: 6 [40960/60000 (68%)]\tLoss: 0.297202\n",
      "Train Epoch: 6 [41600/60000 (69%)]\tLoss: 0.393658\n",
      "Train Epoch: 6 [42240/60000 (70%)]\tLoss: 0.220953\n",
      "Train Epoch: 6 [42880/60000 (71%)]\tLoss: 0.153768\n",
      "Train Epoch: 6 [43520/60000 (72%)]\tLoss: 0.462496\n",
      "Train Epoch: 6 [44160/60000 (74%)]\tLoss: 0.490100\n",
      "Train Epoch: 6 [44800/60000 (75%)]\tLoss: 0.318284\n",
      "Train Epoch: 6 [45440/60000 (76%)]\tLoss: 0.387068\n",
      "Train Epoch: 6 [46080/60000 (77%)]\tLoss: 0.359918\n",
      "Train Epoch: 6 [46720/60000 (78%)]\tLoss: 0.162425\n",
      "Train Epoch: 6 [47360/60000 (79%)]\tLoss: 0.532547\n",
      "Train Epoch: 6 [48000/60000 (80%)]\tLoss: 0.110720\n",
      "Train Epoch: 6 [48640/60000 (81%)]\tLoss: 0.286696\n",
      "Train Epoch: 6 [49280/60000 (82%)]\tLoss: 0.253954\n",
      "Train Epoch: 6 [49920/60000 (83%)]\tLoss: 0.339113\n",
      "Train Epoch: 6 [50560/60000 (84%)]\tLoss: 0.452904\n",
      "Train Epoch: 6 [51200/60000 (85%)]\tLoss: 0.233655\n",
      "Train Epoch: 6 [51840/60000 (86%)]\tLoss: 0.222707\n",
      "Train Epoch: 6 [52480/60000 (87%)]\tLoss: 0.470684\n",
      "Train Epoch: 6 [53120/60000 (88%)]\tLoss: 0.266399\n",
      "Train Epoch: 6 [53760/60000 (90%)]\tLoss: 0.406812\n",
      "Train Epoch: 6 [54400/60000 (91%)]\tLoss: 0.260704\n",
      "Train Epoch: 6 [55040/60000 (92%)]\tLoss: 0.266867\n",
      "Train Epoch: 6 [55680/60000 (93%)]\tLoss: 0.154948\n",
      "Train Epoch: 6 [56320/60000 (94%)]\tLoss: 0.349680\n",
      "Train Epoch: 6 [56960/60000 (95%)]\tLoss: 0.352129\n",
      "Train Epoch: 6 [57600/60000 (96%)]\tLoss: 0.187762\n",
      "Train Epoch: 6 [58240/60000 (97%)]\tLoss: 0.458352\n",
      "Train Epoch: 6 [58880/60000 (98%)]\tLoss: 0.319589\n",
      "Train Epoch: 6 [59520/60000 (99%)]\tLoss: 0.356715\n",
      "\n",
      "Test set: Avg. loss: 0.2906, Accuracy: 9190/10000 (92%)\n",
      "\n",
      "Train Epoch: 7 [0/60000 (0%)]\tLoss: 0.190915\n",
      "Train Epoch: 7 [640/60000 (1%)]\tLoss: 0.249273\n",
      "Train Epoch: 7 [1280/60000 (2%)]\tLoss: 0.092274\n",
      "Train Epoch: 7 [1920/60000 (3%)]\tLoss: 0.265386\n",
      "Train Epoch: 7 [2560/60000 (4%)]\tLoss: 0.281139\n",
      "Train Epoch: 7 [3200/60000 (5%)]\tLoss: 0.189917\n",
      "Train Epoch: 7 [3840/60000 (6%)]\tLoss: 0.286789\n",
      "Train Epoch: 7 [4480/60000 (7%)]\tLoss: 0.294973\n",
      "Train Epoch: 7 [5120/60000 (9%)]\tLoss: 0.287783\n",
      "Train Epoch: 7 [5760/60000 (10%)]\tLoss: 0.288122\n",
      "Train Epoch: 7 [6400/60000 (11%)]\tLoss: 0.089560\n",
      "Train Epoch: 7 [7040/60000 (12%)]\tLoss: 0.206680\n",
      "Train Epoch: 7 [7680/60000 (13%)]\tLoss: 0.158000\n",
      "Train Epoch: 7 [8320/60000 (14%)]\tLoss: 0.276338\n",
      "Train Epoch: 7 [8960/60000 (15%)]\tLoss: 0.424666\n",
      "Train Epoch: 7 [9600/60000 (16%)]\tLoss: 0.160396\n",
      "Train Epoch: 7 [10240/60000 (17%)]\tLoss: 0.574107\n",
      "Train Epoch: 7 [10880/60000 (18%)]\tLoss: 0.234431\n",
      "Train Epoch: 7 [11520/60000 (19%)]\tLoss: 0.376580\n",
      "Train Epoch: 7 [12160/60000 (20%)]\tLoss: 0.254515\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 7 [12800/60000 (21%)]\tLoss: 0.358114\n",
      "Train Epoch: 7 [13440/60000 (22%)]\tLoss: 0.570680\n",
      "Train Epoch: 7 [14080/60000 (23%)]\tLoss: 0.170161\n",
      "Train Epoch: 7 [14720/60000 (25%)]\tLoss: 0.174116\n",
      "Train Epoch: 7 [15360/60000 (26%)]\tLoss: 0.156341\n",
      "Train Epoch: 7 [16000/60000 (27%)]\tLoss: 0.409457\n",
      "Train Epoch: 7 [16640/60000 (28%)]\tLoss: 0.667586\n",
      "Train Epoch: 7 [17280/60000 (29%)]\tLoss: 0.112270\n",
      "Train Epoch: 7 [17920/60000 (30%)]\tLoss: 0.055875\n",
      "Train Epoch: 7 [18560/60000 (31%)]\tLoss: 0.302569\n",
      "Train Epoch: 7 [19200/60000 (32%)]\tLoss: 0.352787\n",
      "Train Epoch: 7 [19840/60000 (33%)]\tLoss: 0.229075\n",
      "Train Epoch: 7 [20480/60000 (34%)]\tLoss: 0.148720\n",
      "Train Epoch: 7 [21120/60000 (35%)]\tLoss: 0.287969\n",
      "Train Epoch: 7 [21760/60000 (36%)]\tLoss: 0.251461\n",
      "Train Epoch: 7 [22400/60000 (37%)]\tLoss: 0.242021\n",
      "Train Epoch: 7 [23040/60000 (38%)]\tLoss: 0.191270\n",
      "Train Epoch: 7 [23680/60000 (39%)]\tLoss: 0.338086\n",
      "Train Epoch: 7 [24320/60000 (41%)]\tLoss: 0.305600\n",
      "Train Epoch: 7 [24960/60000 (42%)]\tLoss: 0.282112\n",
      "Train Epoch: 7 [25600/60000 (43%)]\tLoss: 0.367395\n",
      "Train Epoch: 7 [26240/60000 (44%)]\tLoss: 0.209959\n",
      "Train Epoch: 7 [26880/60000 (45%)]\tLoss: 0.374657\n",
      "Train Epoch: 7 [27520/60000 (46%)]\tLoss: 0.234999\n",
      "Train Epoch: 7 [28160/60000 (47%)]\tLoss: 0.533630\n",
      "Train Epoch: 7 [28800/60000 (48%)]\tLoss: 0.216281\n",
      "Train Epoch: 7 [29440/60000 (49%)]\tLoss: 0.351477\n",
      "Train Epoch: 7 [30080/60000 (50%)]\tLoss: 0.227377\n",
      "Train Epoch: 7 [30720/60000 (51%)]\tLoss: 0.238083\n",
      "Train Epoch: 7 [31360/60000 (52%)]\tLoss: 0.336067\n",
      "Train Epoch: 7 [32000/60000 (53%)]\tLoss: 0.102224\n",
      "Train Epoch: 7 [32640/60000 (54%)]\tLoss: 0.641315\n",
      "Train Epoch: 7 [33280/60000 (55%)]\tLoss: 0.279016\n",
      "Train Epoch: 7 [33920/60000 (57%)]\tLoss: 0.263077\n",
      "Train Epoch: 7 [34560/60000 (58%)]\tLoss: 0.287653\n",
      "Train Epoch: 7 [35200/60000 (59%)]\tLoss: 0.379888\n",
      "Train Epoch: 7 [35840/60000 (60%)]\tLoss: 0.311261\n",
      "Train Epoch: 7 [36480/60000 (61%)]\tLoss: 0.264311\n",
      "Train Epoch: 7 [37120/60000 (62%)]\tLoss: 0.453854\n",
      "Train Epoch: 7 [37760/60000 (63%)]\tLoss: 0.254280\n",
      "Train Epoch: 7 [38400/60000 (64%)]\tLoss: 0.357016\n",
      "Train Epoch: 7 [39040/60000 (65%)]\tLoss: 0.128134\n",
      "Train Epoch: 7 [39680/60000 (66%)]\tLoss: 0.244124\n",
      "Train Epoch: 7 [40320/60000 (67%)]\tLoss: 0.522945\n",
      "Train Epoch: 7 [40960/60000 (68%)]\tLoss: 0.192237\n",
      "Train Epoch: 7 [41600/60000 (69%)]\tLoss: 0.531923\n",
      "Train Epoch: 7 [42240/60000 (70%)]\tLoss: 0.352130\n",
      "Train Epoch: 7 [42880/60000 (71%)]\tLoss: 0.378465\n",
      "Train Epoch: 7 [43520/60000 (72%)]\tLoss: 0.162970\n",
      "Train Epoch: 7 [44160/60000 (74%)]\tLoss: 0.382789\n",
      "Train Epoch: 7 [44800/60000 (75%)]\tLoss: 0.322268\n",
      "Train Epoch: 7 [45440/60000 (76%)]\tLoss: 0.166199\n",
      "Train Epoch: 7 [46080/60000 (77%)]\tLoss: 0.199120\n",
      "Train Epoch: 7 [46720/60000 (78%)]\tLoss: 0.295956\n",
      "Train Epoch: 7 [47360/60000 (79%)]\tLoss: 0.238018\n",
      "Train Epoch: 7 [48000/60000 (80%)]\tLoss: 0.556879\n",
      "Train Epoch: 7 [48640/60000 (81%)]\tLoss: 0.195984\n",
      "Train Epoch: 7 [49280/60000 (82%)]\tLoss: 0.354464\n",
      "Train Epoch: 7 [49920/60000 (83%)]\tLoss: 0.417531\n",
      "Train Epoch: 7 [50560/60000 (84%)]\tLoss: 0.200006\n",
      "Train Epoch: 7 [51200/60000 (85%)]\tLoss: 0.257371\n",
      "Train Epoch: 7 [51840/60000 (86%)]\tLoss: 0.192704\n",
      "Train Epoch: 7 [52480/60000 (87%)]\tLoss: 0.611496\n",
      "Train Epoch: 7 [53120/60000 (88%)]\tLoss: 0.158527\n",
      "Train Epoch: 7 [53760/60000 (90%)]\tLoss: 0.261802\n",
      "Train Epoch: 7 [54400/60000 (91%)]\tLoss: 0.328021\n",
      "Train Epoch: 7 [55040/60000 (92%)]\tLoss: 0.268318\n",
      "Train Epoch: 7 [55680/60000 (93%)]\tLoss: 0.235420\n",
      "Train Epoch: 7 [56320/60000 (94%)]\tLoss: 0.331931\n",
      "Train Epoch: 7 [56960/60000 (95%)]\tLoss: 0.402837\n",
      "Train Epoch: 7 [57600/60000 (96%)]\tLoss: 0.133278\n",
      "Train Epoch: 7 [58240/60000 (97%)]\tLoss: 0.242970\n",
      "Train Epoch: 7 [58880/60000 (98%)]\tLoss: 0.235765\n",
      "Train Epoch: 7 [59520/60000 (99%)]\tLoss: 0.240810\n",
      "\n",
      "Test set: Avg. loss: 0.3079, Accuracy: 9143/10000 (91%)\n",
      "\n",
      "Train Epoch: 8 [0/60000 (0%)]\tLoss: 0.253239\n",
      "Train Epoch: 8 [640/60000 (1%)]\tLoss: 0.332200\n",
      "Train Epoch: 8 [1280/60000 (2%)]\tLoss: 0.412868\n",
      "Train Epoch: 8 [1920/60000 (3%)]\tLoss: 0.174229\n",
      "Train Epoch: 8 [2560/60000 (4%)]\tLoss: 0.613341\n",
      "Train Epoch: 8 [3200/60000 (5%)]\tLoss: 0.449482\n",
      "Train Epoch: 8 [3840/60000 (6%)]\tLoss: 0.123620\n",
      "Train Epoch: 8 [4480/60000 (7%)]\tLoss: 0.118616\n",
      "Train Epoch: 8 [5120/60000 (9%)]\tLoss: 0.386199\n",
      "Train Epoch: 8 [5760/60000 (10%)]\tLoss: 0.307443\n",
      "Train Epoch: 8 [6400/60000 (11%)]\tLoss: 0.285631\n",
      "Train Epoch: 8 [7040/60000 (12%)]\tLoss: 0.107518\n",
      "Train Epoch: 8 [7680/60000 (13%)]\tLoss: 0.210678\n",
      "Train Epoch: 8 [8320/60000 (14%)]\tLoss: 0.207026\n",
      "Train Epoch: 8 [8960/60000 (15%)]\tLoss: 0.138919\n",
      "Train Epoch: 8 [9600/60000 (16%)]\tLoss: 0.279368\n",
      "Train Epoch: 8 [10240/60000 (17%)]\tLoss: 0.160924\n",
      "Train Epoch: 8 [10880/60000 (18%)]\tLoss: 0.201425\n",
      "Train Epoch: 8 [11520/60000 (19%)]\tLoss: 0.213386\n",
      "Train Epoch: 8 [12160/60000 (20%)]\tLoss: 0.318618\n",
      "Train Epoch: 8 [12800/60000 (21%)]\tLoss: 0.213841\n",
      "Train Epoch: 8 [13440/60000 (22%)]\tLoss: 0.319440\n",
      "Train Epoch: 8 [14080/60000 (23%)]\tLoss: 0.462789\n",
      "Train Epoch: 8 [14720/60000 (25%)]\tLoss: 0.329142\n",
      "Train Epoch: 8 [15360/60000 (26%)]\tLoss: 0.202945\n",
      "Train Epoch: 8 [16000/60000 (27%)]\tLoss: 0.137122\n",
      "Train Epoch: 8 [16640/60000 (28%)]\tLoss: 0.218022\n",
      "Train Epoch: 8 [17280/60000 (29%)]\tLoss: 0.260272\n",
      "Train Epoch: 8 [17920/60000 (30%)]\tLoss: 0.501528\n",
      "Train Epoch: 8 [18560/60000 (31%)]\tLoss: 0.312017\n",
      "Train Epoch: 8 [19200/60000 (32%)]\tLoss: 0.349380\n",
      "Train Epoch: 8 [19840/60000 (33%)]\tLoss: 0.206963\n",
      "Train Epoch: 8 [20480/60000 (34%)]\tLoss: 0.202898\n",
      "Train Epoch: 8 [21120/60000 (35%)]\tLoss: 0.337490\n",
      "Train Epoch: 8 [21760/60000 (36%)]\tLoss: 0.178671\n",
      "Train Epoch: 8 [22400/60000 (37%)]\tLoss: 0.187590\n",
      "Train Epoch: 8 [23040/60000 (38%)]\tLoss: 0.238523\n",
      "Train Epoch: 8 [23680/60000 (39%)]\tLoss: 0.499369\n",
      "Train Epoch: 8 [24320/60000 (41%)]\tLoss: 0.260813\n",
      "Train Epoch: 8 [24960/60000 (42%)]\tLoss: 0.229676\n",
      "Train Epoch: 8 [25600/60000 (43%)]\tLoss: 0.308753\n",
      "Train Epoch: 8 [26240/60000 (44%)]\tLoss: 0.180246\n",
      "Train Epoch: 8 [26880/60000 (45%)]\tLoss: 0.240203\n",
      "Train Epoch: 8 [27520/60000 (46%)]\tLoss: 0.361983\n",
      "Train Epoch: 8 [28160/60000 (47%)]\tLoss: 0.203682\n",
      "Train Epoch: 8 [28800/60000 (48%)]\tLoss: 0.259258\n",
      "Train Epoch: 8 [29440/60000 (49%)]\tLoss: 0.389724\n",
      "Train Epoch: 8 [30080/60000 (50%)]\tLoss: 0.185657\n",
      "Train Epoch: 8 [30720/60000 (51%)]\tLoss: 0.496013\n",
      "Train Epoch: 8 [31360/60000 (52%)]\tLoss: 0.464845\n",
      "Train Epoch: 8 [32000/60000 (53%)]\tLoss: 0.242867\n",
      "Train Epoch: 8 [32640/60000 (54%)]\tLoss: 0.427562\n",
      "Train Epoch: 8 [33280/60000 (55%)]\tLoss: 0.318273\n",
      "Train Epoch: 8 [33920/60000 (57%)]\tLoss: 0.300606\n",
      "Train Epoch: 8 [34560/60000 (58%)]\tLoss: 0.423765\n",
      "Train Epoch: 8 [35200/60000 (59%)]\tLoss: 0.147616\n",
      "Train Epoch: 8 [35840/60000 (60%)]\tLoss: 0.297708\n",
      "Train Epoch: 8 [36480/60000 (61%)]\tLoss: 0.256755\n",
      "Train Epoch: 8 [37120/60000 (62%)]\tLoss: 0.387465\n",
      "Train Epoch: 8 [37760/60000 (63%)]\tLoss: 0.216313\n",
      "Train Epoch: 8 [38400/60000 (64%)]\tLoss: 0.359757\n",
      "Train Epoch: 8 [39040/60000 (65%)]\tLoss: 0.346420\n",
      "Train Epoch: 8 [39680/60000 (66%)]\tLoss: 0.196036\n",
      "Train Epoch: 8 [40320/60000 (67%)]\tLoss: 0.295106\n",
      "Train Epoch: 8 [40960/60000 (68%)]\tLoss: 0.428906\n",
      "Train Epoch: 8 [41600/60000 (69%)]\tLoss: 0.357731\n",
      "Train Epoch: 8 [42240/60000 (70%)]\tLoss: 0.323431\n",
      "Train Epoch: 8 [42880/60000 (71%)]\tLoss: 0.322730\n",
      "Train Epoch: 8 [43520/60000 (72%)]\tLoss: 0.257603\n",
      "Train Epoch: 8 [44160/60000 (74%)]\tLoss: 0.250009\n",
      "Train Epoch: 8 [44800/60000 (75%)]\tLoss: 0.244212\n",
      "Train Epoch: 8 [45440/60000 (76%)]\tLoss: 0.228890\n",
      "Train Epoch: 8 [46080/60000 (77%)]\tLoss: 0.516548\n",
      "Train Epoch: 8 [46720/60000 (78%)]\tLoss: 0.546525\n",
      "Train Epoch: 8 [47360/60000 (79%)]\tLoss: 0.143586\n",
      "Train Epoch: 8 [48000/60000 (80%)]\tLoss: 0.218103\n",
      "Train Epoch: 8 [48640/60000 (81%)]\tLoss: 0.136378\n",
      "Train Epoch: 8 [49280/60000 (82%)]\tLoss: 0.382926\n",
      "Train Epoch: 8 [49920/60000 (83%)]\tLoss: 0.513631\n",
      "Train Epoch: 8 [50560/60000 (84%)]\tLoss: 0.150880\n",
      "Train Epoch: 8 [51200/60000 (85%)]\tLoss: 0.154864\n",
      "Train Epoch: 8 [51840/60000 (86%)]\tLoss: 0.467494\n",
      "Train Epoch: 8 [52480/60000 (87%)]\tLoss: 0.372948\n",
      "Train Epoch: 8 [53120/60000 (88%)]\tLoss: 0.196234\n",
      "Train Epoch: 8 [53760/60000 (90%)]\tLoss: 0.408489\n",
      "Train Epoch: 8 [54400/60000 (91%)]\tLoss: 0.164288\n",
      "Train Epoch: 8 [55040/60000 (92%)]\tLoss: 0.286256\n",
      "Train Epoch: 8 [55680/60000 (93%)]\tLoss: 0.419743\n",
      "Train Epoch: 8 [56320/60000 (94%)]\tLoss: 0.187898\n",
      "Train Epoch: 8 [56960/60000 (95%)]\tLoss: 0.100315\n",
      "Train Epoch: 8 [57600/60000 (96%)]\tLoss: 0.056140\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 8 [58240/60000 (97%)]\tLoss: 0.185374\n",
      "Train Epoch: 8 [58880/60000 (98%)]\tLoss: 0.345368\n",
      "Train Epoch: 8 [59520/60000 (99%)]\tLoss: 0.501104\n",
      "\n",
      "Test set: Avg. loss: 0.3018, Accuracy: 9121/10000 (91%)\n",
      "\n",
      "Train Epoch: 9 [0/60000 (0%)]\tLoss: 0.306298\n",
      "Train Epoch: 9 [640/60000 (1%)]\tLoss: 0.163202\n",
      "Train Epoch: 9 [1280/60000 (2%)]\tLoss: 0.214661\n",
      "Train Epoch: 9 [1920/60000 (3%)]\tLoss: 0.329615\n",
      "Train Epoch: 9 [2560/60000 (4%)]\tLoss: 0.144277\n",
      "Train Epoch: 9 [3200/60000 (5%)]\tLoss: 0.250707\n",
      "Train Epoch: 9 [3840/60000 (6%)]\tLoss: 0.129525\n",
      "Train Epoch: 9 [4480/60000 (7%)]\tLoss: 0.149520\n",
      "Train Epoch: 9 [5120/60000 (9%)]\tLoss: 0.401944\n",
      "Train Epoch: 9 [5760/60000 (10%)]\tLoss: 0.197084\n",
      "Train Epoch: 9 [6400/60000 (11%)]\tLoss: 0.172227\n",
      "Train Epoch: 9 [7040/60000 (12%)]\tLoss: 0.644778\n",
      "Train Epoch: 9 [7680/60000 (13%)]\tLoss: 0.241277\n",
      "Train Epoch: 9 [8320/60000 (14%)]\tLoss: 0.162113\n",
      "Train Epoch: 9 [8960/60000 (15%)]\tLoss: 0.347867\n",
      "Train Epoch: 9 [9600/60000 (16%)]\tLoss: 0.257464\n",
      "Train Epoch: 9 [10240/60000 (17%)]\tLoss: 0.464154\n",
      "Train Epoch: 9 [10880/60000 (18%)]\tLoss: 0.419979\n",
      "Train Epoch: 9 [11520/60000 (19%)]\tLoss: 0.501765\n",
      "Train Epoch: 9 [12160/60000 (20%)]\tLoss: 0.398727\n",
      "Train Epoch: 9 [12800/60000 (21%)]\tLoss: 0.240831\n",
      "Train Epoch: 9 [13440/60000 (22%)]\tLoss: 0.336410\n",
      "Train Epoch: 9 [14080/60000 (23%)]\tLoss: 0.240268\n",
      "Train Epoch: 9 [14720/60000 (25%)]\tLoss: 0.259829\n",
      "Train Epoch: 9 [15360/60000 (26%)]\tLoss: 0.220432\n",
      "Train Epoch: 9 [16000/60000 (27%)]\tLoss: 0.513211\n",
      "Train Epoch: 9 [16640/60000 (28%)]\tLoss: 0.270175\n",
      "Train Epoch: 9 [17280/60000 (29%)]\tLoss: 0.150912\n",
      "Train Epoch: 9 [17920/60000 (30%)]\tLoss: 0.148472\n",
      "Train Epoch: 9 [18560/60000 (31%)]\tLoss: 0.303457\n",
      "Train Epoch: 9 [19200/60000 (32%)]\tLoss: 0.251253\n",
      "Train Epoch: 9 [19840/60000 (33%)]\tLoss: 0.435695\n",
      "Train Epoch: 9 [20480/60000 (34%)]\tLoss: 0.339482\n",
      "Train Epoch: 9 [21120/60000 (35%)]\tLoss: 0.469467\n",
      "Train Epoch: 9 [21760/60000 (36%)]\tLoss: 0.164435\n",
      "Train Epoch: 9 [22400/60000 (37%)]\tLoss: 0.300927\n",
      "Train Epoch: 9 [23040/60000 (38%)]\tLoss: 0.374105\n",
      "Train Epoch: 9 [23680/60000 (39%)]\tLoss: 0.155893\n",
      "Train Epoch: 9 [24320/60000 (41%)]\tLoss: 0.115919\n",
      "Train Epoch: 9 [24960/60000 (42%)]\tLoss: 0.243766\n",
      "Train Epoch: 9 [25600/60000 (43%)]\tLoss: 0.312785\n",
      "Train Epoch: 9 [26240/60000 (44%)]\tLoss: 0.299761\n",
      "Train Epoch: 9 [26880/60000 (45%)]\tLoss: 0.082114\n",
      "Train Epoch: 9 [27520/60000 (46%)]\tLoss: 0.353561\n",
      "Train Epoch: 9 [28160/60000 (47%)]\tLoss: 0.121000\n",
      "Train Epoch: 9 [28800/60000 (48%)]\tLoss: 0.279418\n",
      "Train Epoch: 9 [29440/60000 (49%)]\tLoss: 0.259173\n",
      "Train Epoch: 9 [30080/60000 (50%)]\tLoss: 0.122330\n",
      "Train Epoch: 9 [30720/60000 (51%)]\tLoss: 0.217900\n",
      "Train Epoch: 9 [31360/60000 (52%)]\tLoss: 0.289749\n",
      "Train Epoch: 9 [32000/60000 (53%)]\tLoss: 0.319810\n",
      "Train Epoch: 9 [32640/60000 (54%)]\tLoss: 0.340883\n",
      "Train Epoch: 9 [33280/60000 (55%)]\tLoss: 0.238431\n",
      "Train Epoch: 9 [33920/60000 (57%)]\tLoss: 0.477568\n",
      "Train Epoch: 9 [34560/60000 (58%)]\tLoss: 0.265249\n",
      "Train Epoch: 9 [35200/60000 (59%)]\tLoss: 0.378214\n",
      "Train Epoch: 9 [35840/60000 (60%)]\tLoss: 0.232366\n",
      "Train Epoch: 9 [36480/60000 (61%)]\tLoss: 0.446975\n",
      "Train Epoch: 9 [37120/60000 (62%)]\tLoss: 0.234371\n",
      "Train Epoch: 9 [37760/60000 (63%)]\tLoss: 0.267530\n",
      "Train Epoch: 9 [38400/60000 (64%)]\tLoss: 0.131035\n",
      "Train Epoch: 9 [39040/60000 (65%)]\tLoss: 0.111167\n",
      "Train Epoch: 9 [39680/60000 (66%)]\tLoss: 0.223151\n",
      "Train Epoch: 9 [40320/60000 (67%)]\tLoss: 0.259745\n",
      "Train Epoch: 9 [40960/60000 (68%)]\tLoss: 0.170952\n",
      "Train Epoch: 9 [41600/60000 (69%)]\tLoss: 0.276635\n",
      "Train Epoch: 9 [42240/60000 (70%)]\tLoss: 0.233290\n",
      "Train Epoch: 9 [42880/60000 (71%)]\tLoss: 0.156048\n",
      "Train Epoch: 9 [43520/60000 (72%)]\tLoss: 0.851813\n",
      "Train Epoch: 9 [44160/60000 (74%)]\tLoss: 0.430499\n",
      "Train Epoch: 9 [44800/60000 (75%)]\tLoss: 0.335339\n",
      "Train Epoch: 9 [45440/60000 (76%)]\tLoss: 0.082749\n",
      "Train Epoch: 9 [46080/60000 (77%)]\tLoss: 0.118063\n",
      "Train Epoch: 9 [46720/60000 (78%)]\tLoss: 0.517546\n",
      "Train Epoch: 9 [47360/60000 (79%)]\tLoss: 0.218652\n",
      "Train Epoch: 9 [48000/60000 (80%)]\tLoss: 0.374774\n",
      "Train Epoch: 9 [48640/60000 (81%)]\tLoss: 0.152370\n",
      "Train Epoch: 9 [49280/60000 (82%)]\tLoss: 0.276693\n",
      "Train Epoch: 9 [49920/60000 (83%)]\tLoss: 0.241687\n",
      "Train Epoch: 9 [50560/60000 (84%)]\tLoss: 0.670969\n",
      "Train Epoch: 9 [51200/60000 (85%)]\tLoss: 0.291804\n",
      "Train Epoch: 9 [51840/60000 (86%)]\tLoss: 0.143440\n",
      "Train Epoch: 9 [52480/60000 (87%)]\tLoss: 0.292004\n",
      "Train Epoch: 9 [53120/60000 (88%)]\tLoss: 0.174349\n",
      "Train Epoch: 9 [53760/60000 (90%)]\tLoss: 0.403500\n",
      "Train Epoch: 9 [54400/60000 (91%)]\tLoss: 0.267706\n",
      "Train Epoch: 9 [55040/60000 (92%)]\tLoss: 0.304830\n",
      "Train Epoch: 9 [55680/60000 (93%)]\tLoss: 0.233141\n",
      "Train Epoch: 9 [56320/60000 (94%)]\tLoss: 0.136397\n",
      "Train Epoch: 9 [56960/60000 (95%)]\tLoss: 0.375882\n",
      "Train Epoch: 9 [57600/60000 (96%)]\tLoss: 0.100896\n",
      "Train Epoch: 9 [58240/60000 (97%)]\tLoss: 0.104001\n",
      "Train Epoch: 9 [58880/60000 (98%)]\tLoss: 0.257238\n",
      "Train Epoch: 9 [59520/60000 (99%)]\tLoss: 0.216197\n",
      "\n",
      "Test set: Avg. loss: 0.2899, Accuracy: 9203/10000 (92%)\n",
      "\n",
      "Train Epoch: 10 [0/60000 (0%)]\tLoss: 0.099412\n",
      "Train Epoch: 10 [640/60000 (1%)]\tLoss: 0.301100\n",
      "Train Epoch: 10 [1280/60000 (2%)]\tLoss: 0.255505\n",
      "Train Epoch: 10 [1920/60000 (3%)]\tLoss: 0.157561\n",
      "Train Epoch: 10 [2560/60000 (4%)]\tLoss: 0.282091\n",
      "Train Epoch: 10 [3200/60000 (5%)]\tLoss: 0.488541\n",
      "Train Epoch: 10 [3840/60000 (6%)]\tLoss: 0.267424\n",
      "Train Epoch: 10 [4480/60000 (7%)]\tLoss: 0.149098\n",
      "Train Epoch: 10 [5120/60000 (9%)]\tLoss: 0.192198\n",
      "Train Epoch: 10 [5760/60000 (10%)]\tLoss: 0.130637\n",
      "Train Epoch: 10 [6400/60000 (11%)]\tLoss: 0.379633\n",
      "Train Epoch: 10 [7040/60000 (12%)]\tLoss: 0.130096\n",
      "Train Epoch: 10 [7680/60000 (13%)]\tLoss: 0.347385\n",
      "Train Epoch: 10 [8320/60000 (14%)]\tLoss: 0.370072\n",
      "Train Epoch: 10 [8960/60000 (15%)]\tLoss: 0.238439\n",
      "Train Epoch: 10 [9600/60000 (16%)]\tLoss: 0.076204\n",
      "Train Epoch: 10 [10240/60000 (17%)]\tLoss: 0.152883\n",
      "Train Epoch: 10 [10880/60000 (18%)]\tLoss: 0.218232\n",
      "Train Epoch: 10 [11520/60000 (19%)]\tLoss: 0.416036\n",
      "Train Epoch: 10 [12160/60000 (20%)]\tLoss: 0.175687\n",
      "Train Epoch: 10 [12800/60000 (21%)]\tLoss: 0.368106\n",
      "Train Epoch: 10 [13440/60000 (22%)]\tLoss: 0.312543\n",
      "Train Epoch: 10 [14080/60000 (23%)]\tLoss: 0.489714\n",
      "Train Epoch: 10 [14720/60000 (25%)]\tLoss: 0.191069\n",
      "Train Epoch: 10 [15360/60000 (26%)]\tLoss: 0.382842\n",
      "Train Epoch: 10 [16000/60000 (27%)]\tLoss: 0.323389\n",
      "Train Epoch: 10 [16640/60000 (28%)]\tLoss: 0.118612\n",
      "Train Epoch: 10 [17280/60000 (29%)]\tLoss: 0.379196\n",
      "Train Epoch: 10 [17920/60000 (30%)]\tLoss: 0.226880\n",
      "Train Epoch: 10 [18560/60000 (31%)]\tLoss: 0.239465\n",
      "Train Epoch: 10 [19200/60000 (32%)]\tLoss: 0.310984\n",
      "Train Epoch: 10 [19840/60000 (33%)]\tLoss: 0.441856\n",
      "Train Epoch: 10 [20480/60000 (34%)]\tLoss: 0.359832\n",
      "Train Epoch: 10 [21120/60000 (35%)]\tLoss: 0.354863\n",
      "Train Epoch: 10 [21760/60000 (36%)]\tLoss: 0.402382\n",
      "Train Epoch: 10 [22400/60000 (37%)]\tLoss: 0.204163\n",
      "Train Epoch: 10 [23040/60000 (38%)]\tLoss: 0.069754\n",
      "Train Epoch: 10 [23680/60000 (39%)]\tLoss: 0.371768\n",
      "Train Epoch: 10 [24320/60000 (41%)]\tLoss: 0.203627\n",
      "Train Epoch: 10 [24960/60000 (42%)]\tLoss: 0.102109\n",
      "Train Epoch: 10 [25600/60000 (43%)]\tLoss: 0.119687\n",
      "Train Epoch: 10 [26240/60000 (44%)]\tLoss: 0.147668\n",
      "Train Epoch: 10 [26880/60000 (45%)]\tLoss: 0.136484\n",
      "Train Epoch: 10 [27520/60000 (46%)]\tLoss: 0.043271\n",
      "Train Epoch: 10 [28160/60000 (47%)]\tLoss: 0.464710\n",
      "Train Epoch: 10 [28800/60000 (48%)]\tLoss: 0.330501\n",
      "Train Epoch: 10 [29440/60000 (49%)]\tLoss: 0.307622\n",
      "Train Epoch: 10 [30080/60000 (50%)]\tLoss: 0.293661\n",
      "Train Epoch: 10 [30720/60000 (51%)]\tLoss: 0.446526\n",
      "Train Epoch: 10 [31360/60000 (52%)]\tLoss: 0.154664\n",
      "Train Epoch: 10 [32000/60000 (53%)]\tLoss: 0.197119\n",
      "Train Epoch: 10 [32640/60000 (54%)]\tLoss: 0.272939\n",
      "Train Epoch: 10 [33280/60000 (55%)]\tLoss: 0.470253\n",
      "Train Epoch: 10 [33920/60000 (57%)]\tLoss: 0.533797\n",
      "Train Epoch: 10 [34560/60000 (58%)]\tLoss: 0.607443\n",
      "Train Epoch: 10 [35200/60000 (59%)]\tLoss: 0.098518\n",
      "Train Epoch: 10 [35840/60000 (60%)]\tLoss: 0.281626\n",
      "Train Epoch: 10 [36480/60000 (61%)]\tLoss: 0.188029\n",
      "Train Epoch: 10 [37120/60000 (62%)]\tLoss: 0.210124\n",
      "Train Epoch: 10 [37760/60000 (63%)]\tLoss: 0.214928\n",
      "Train Epoch: 10 [38400/60000 (64%)]\tLoss: 0.087488\n",
      "Train Epoch: 10 [39040/60000 (65%)]\tLoss: 0.154434\n",
      "Train Epoch: 10 [39680/60000 (66%)]\tLoss: 0.218719\n",
      "Train Epoch: 10 [40320/60000 (67%)]\tLoss: 0.066826\n",
      "Train Epoch: 10 [40960/60000 (68%)]\tLoss: 0.396623\n",
      "Train Epoch: 10 [41600/60000 (69%)]\tLoss: 0.157140\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 10 [42240/60000 (70%)]\tLoss: 0.391476\n",
      "Train Epoch: 10 [42880/60000 (71%)]\tLoss: 0.188278\n",
      "Train Epoch: 10 [43520/60000 (72%)]\tLoss: 0.215247\n",
      "Train Epoch: 10 [44160/60000 (74%)]\tLoss: 0.264396\n",
      "Train Epoch: 10 [44800/60000 (75%)]\tLoss: 0.407886\n",
      "Train Epoch: 10 [45440/60000 (76%)]\tLoss: 0.380222\n",
      "Train Epoch: 10 [46080/60000 (77%)]\tLoss: 0.315006\n",
      "Train Epoch: 10 [46720/60000 (78%)]\tLoss: 0.609584\n",
      "Train Epoch: 10 [47360/60000 (79%)]\tLoss: 0.378667\n",
      "Train Epoch: 10 [48000/60000 (80%)]\tLoss: 0.204500\n",
      "Train Epoch: 10 [48640/60000 (81%)]\tLoss: 0.165561\n",
      "Train Epoch: 10 [49280/60000 (82%)]\tLoss: 0.435450\n",
      "Train Epoch: 10 [49920/60000 (83%)]\tLoss: 0.207189\n",
      "Train Epoch: 10 [50560/60000 (84%)]\tLoss: 0.266754\n",
      "Train Epoch: 10 [51200/60000 (85%)]\tLoss: 0.448375\n",
      "Train Epoch: 10 [51840/60000 (86%)]\tLoss: 0.126711\n",
      "Train Epoch: 10 [52480/60000 (87%)]\tLoss: 0.412059\n",
      "Train Epoch: 10 [53120/60000 (88%)]\tLoss: 0.329292\n",
      "Train Epoch: 10 [53760/60000 (90%)]\tLoss: 0.165055\n",
      "Train Epoch: 10 [54400/60000 (91%)]\tLoss: 0.252247\n",
      "Train Epoch: 10 [55040/60000 (92%)]\tLoss: 0.312859\n",
      "Train Epoch: 10 [55680/60000 (93%)]\tLoss: 0.147590\n",
      "Train Epoch: 10 [56320/60000 (94%)]\tLoss: 0.150502\n",
      "Train Epoch: 10 [56960/60000 (95%)]\tLoss: 0.395684\n",
      "Train Epoch: 10 [57600/60000 (96%)]\tLoss: 0.680102\n",
      "Train Epoch: 10 [58240/60000 (97%)]\tLoss: 0.296855\n",
      "Train Epoch: 10 [58880/60000 (98%)]\tLoss: 0.505312\n",
      "Train Epoch: 10 [59520/60000 (99%)]\tLoss: 0.211149\n",
      "\n",
      "Test set: Avg. loss: 0.2952, Accuracy: 9183/10000 (92%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, n_epochs + 1):\n",
    "  \n",
    "  train(epoch)\n",
    "  test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'negative log likelihood loss')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "plt.plot(train_losses, \"-*\", color='blue')\n",
    "plt.plot(test_losses, \"-^\", color='red')\n",
    "plt.legend(['Train Loss', 'Test Loss'], loc='upper right')\n",
    "plt.xlabel('number of training examples seen')\n",
    "plt.ylabel('negative log likelihood loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/envs/env_pytorch/lib/python3.6/site-packages/ipykernel_launcher.py:10: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "  output = network(example_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAbcAAABXCAYAAACHpAvdAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAATIUlEQVR4nO2de7jV07rHP+8WlVKLEKWLbohox5FLp5NKinLJbYd0ISrX0ONWcinKk1s2ds8WURxHbBG5xVNsJCdPJ4XcauniUikUoYzzx2++c8w1W7N5X3Ou33w/z7OetebvMn5jfn+/9RvjHe873iHOOQzDMAwjTPyl0BUwDMMwjFxjjZthGIYROqxxMwzDMEKHNW6GYRhG6LDGzTAMwwgd1rgZhmEYoaOgjZuITBWRsZG//1NElmVYzj9EZHRua1f9MX3zh2mbX0zf/FEq2iZt3ERkhYj8KiKbROQ7EXlUROrmuiLOubedcwekUJ+BIvLvuHOHOuduy3WdKrn230RkmYj8KCLfi8hjIlIvyzJN34rX3hbRQn+6ZFGeaeuvPUBEForITyKySkTuFJEaWZZp+vpr5/TdYNpWuHZNEblHRNaIyAYReVBEdk52XqqWWx/nXF2gA/AfwKhKKpDVP0o14R3gWOdcfaAFUAMYm4NyTV/Pe865ujE/c7Msz7QN2BW4EtgT6Ah0A67JQbmmb0A+3g2mbcB1wBHAIUAbAj220yKetIYlnXOrgZcjF0FEnIhcIiKfA59HtvUWkUUislFE3hWRQ/V8EfmriHwoIj+LyP8AtWL2dRGRVTGfm4jIv0RkrYisF5G/i8hBwD+AoyM9mo2RY6NmduTzEBH5QkR+EJEXRKRRzD4nIkNF5PNIL+ABEZEUv/9K59y6mE3bgFZpSJis/JLWN5+UurbOuYcivfTfI1o8ARybgZSJyi91ffP2bih1bYE+wCTn3A/OubXAJGBwKsLt8AdYAXSP/N0EWArcFvnsgNeBPYDaBC3q9wQ9w52AAZHzawK7AOXACGBn4AzgD2BspKwuwKrI3zsB/wfcA9QhuBmdIvsGAv+Oq+PUmHK6AusidakJ3A+8FXOsA14EyoCmwFqgZ2RfU2Aj0HQHenQCfoyUsxnokUxD0zc1fSPX3hwp/zNgNFDDtM3Nsxt33ZnAeHt2i/PdYNpWuM5C4KyYz+dGyqu/Qw1TFHlT5OLlwINA7ZgKd4059iG9ATHblgH/BXQG1gASs+/dBCIfHfny273YUhB5CnBnzL66kZvZPKbOnWL2Pw1cl8HD1xi4GWiTgxeE6Rsc2wLYn2BEoR3wMXC9aZvzZ3cQsArY057d4nw3mLYVrjOWYNh3L2Af4P1Iefvu6LxUx2tPdc7NSbBvZczfzYABInJZzLZdgEaRyqx2kdpGKE9QZhOg3Dm3NcX6xdII+FA/OOc2ich6ggduRWTztzHH/0JwI9LCObdaRF4BniLorWSD6RuU9VXMx49E5FZgJHBHBvVUTNsYRORUYDyBVbAuyeGpYPrGkcN3g2kbMI7A4lsE/Ab8E/grgbWakFxMBYgVbSUwzjlXFvOzq3Puv4FvgMZx46xNE5S5EmgqlTtLXSXbYllDcLMBEJE6QANgdbIvkgE1gJZ5KDeWUtbXAfn015WUtiLSk+DF0Mc591EuykxCSekbR77fDSWjrXPuV+fcpc65xs65FsB6YKFzbtuOzsv1PLd/AkNFpKME1BGRk0RkN+A9YCtwuYjUEJG+wJEJyllAcFPGR8qoJSLq/P4O2E9Edklw7pPAIBFpLyI1gduB951zK7L9ciJyrog0jXy3ZgQ9ijeyLTcNwq5vLxFpGPn7QAKf2/PZlpsiYde2K0EQyenOuQXZlpcBYde3kO+GsGvbWEQaRb7bUQTvhTHJzstp4+ac+19gCPB3YAPwBcFYLc6534G+kc8bgLOBfyUoZxtBhEwr4GsC/8DZkd1vEjhXvxWR7YZVnHNvEHz5ZwluVEvgb6nUP/JwbhKRRD2btgTj1ZsIxoCXRb5vlVAC+nYDFovIZmB2pP63p1J2tpSAtqOB+sBs8XMIX06l7FxQAvoW7N1QAtq2JNB2M/AYga/utaTlVhyKNQzDMIzqj+WWNAzDMEKHNW6GYRhG6LDGzTAMwwgd1rgZhmEYocMaN8MwDCN05CyjtIiENexynXNur0JWwLTNL6Zv/jBt84vpmxiz3JKTKFWNkT2mbX4xffOHaZtfstbXGjfDMAwjdFjjZhiGYYQOa9wMwzCM0GGNm2EYhhE6rHEzDMMwQkfOpgJkQufOnQHo27cvAIcddhgAXbp0AdBVWHnjjWDliAkTJgCwYsUKAL744ouqqqoRoaysDICbb74ZgIMPPpju3bsD8NprQaLuXr16AfDnn39Wef2qG7vsEqwgIpHltoYPHw5A165dAejdu3f02DvvvBOALVu2ADBmTNJVPwyjZDHLzTAMwwgdOVvyJt3JhNOmTeOcc87Rc9O61o8//gjA4MGDAXjuuefSOj9NFjrnjsjnBZJRiImaHTp0AKBTp06AtzAuueQSAJo1a1b5ifj7MnXq1GSXKbi2ULX67rrrrgAceOCBAMyePRuAvffeO+Uy5s2bB8Bxxx2X7NCC65sPbYcNGwbAbrvtBsCFF14IQOvWrQE/4lNJXQD46quvAJg8eXJU/yVLlqRbjYJrC/nR94EHHgD8KMJnn30GEB2hWblyZa4vWRlZ62uWm2EYhhE6Cma5vf7663Tr1q3CtjfffBOAxYsXR48B6NevHwBnnx0sCrvzzjsDMGvWLABOOeWUTKudCgXvoVWlZTFo0CAAJk6cCMDuu++edhkfffQR4H2oO6Dg2kJ+9dVntV69eoB/Zo866qgdnrdx48bo+XXq1Kmwr1Qst2OOOQaAyy67DCD6vtBn8i9/yb5v/t133wHQo0cPIC0LruDaQn6e3U8++QSANm3aVNiuFtwJJ5wAwNdff53rS8eStb4FCyjp2bMnAwcOBGDmzJkAbNiwAdg+EOHll18GvLi33npr1VSyBBkyZAiQXqP2ww8/AH7ospTRxmzPPfcE4MorrwRg5MiRlR6vwSH67D/44IMATJo0CYCDDjqIuXPnAlCrVq281LnYaNCgAeCHxw499NC0zl+6dCkAy5cvr3S/DrWXlZXRsGFDwN8nHeI0PE8++STgA/1eeeUVwAeOlZcXZyYyG5Y0DMMwQkfBLLdt27YxZcqUtM7JsxlckrRt2xaAyy+/HICOHTumdJ5Ow7j//vuZPHky4IMi1LFfSqjFpkOF2ruNRy01HQ4bNWoUAE888USlx3fr1m07i00DqsLK+vXrAXj66acBb7ktWLAA8AEj9913HwCrV6+ucL5abPHblQEDBgDwyCOPRLfpcHwpW2461aRly5aAD3ZSbQ455BAARo8eXWH/SSedBPgpWsWCWW6GYRhG6CjoJO50ufbaayt8TjSmbiSmRo3gll9wwQUA3HHHHYCfnB3PBx98APhACA360aCRn3/+OXrsqlWrKvwuJQ4//HAgscWmVsScOXMA3xtORPPmzQEYMWJEdJv65dRiCTsa1PTpp58C8PzzzwPpJweoX78+4P2g8YFs4K3FUuaMM84A/AiZ+om3bt0KwKJFiwC4++67AXjrrbcAorETmtihWDDLzTAMwwgd1cpya9y4cYXPJ554IgDz588H4KmnnqryOhU7NWvWBALfGPjJwxoxlgi1DmItByMxOuFVUd/al19+CfgoVH1Wk3HbbbcB3toAolGT2mMOO3/88QeQfpIGnaytk7zVSr7rrru2O1b9d2PHjs24nmFj7dq1gPcLJ9q/Zs0awE/FMsvNMAzDMPJMtbLcdD6VpjBq1aoV4KOetAehY8C//fZbFdew+NBovGRRYD/99BPg5/tMmzYtr/UKG/F+MLUe+vfvn1Y5Oscr1i/0/fffA0SjUrdt25ZxPcOM+tbUNx/vo68MjVLVeYWlzNVXXw3Ao48+CsD06dMB/wzr+1d/60iZpuTT8yuzkAuBWW6GYRhG6KhWlluLFi0AGDp0KOB7FEcffTTg03PVrl0b8D23ZcuWVWk9i4F9990XgIsuuiil45955hkA3nvvPcCsg3RZuHAhAOeff35G56tvTVNN7bPPPkDg9xg/fjzglxQyApo2bQp4f6eOOuicw0Ro5Grv3r2j2UyM7X2b+ixrBLD673XkTN/HikZgm+VmGIZhGHmiYImTc4H20E4++WTAz79o0qQJ4H0V/fv3jyZhzoCCJ0jNRNt7770X8JlHUkXnEGm03i233JLupdOh4NpCYZ7deDTLw+OPPw743J4LFiyIZj359ddf0y224Ppmo63+f+v8K0X9yHvttRfg/ZTJOPbYYwGfXWfdunWZVg2KQFuommdXI6zjE3graqntv//+gB9J02jKDLElbwzDMAwjnmrlc4tH58E8++yzgF8K5IYbbgD8GPzs2bNp164d4LMdhJ2HHnoIgPPOOw/wkWQ77bTTDs/TZUTGjBkDeGtB884ZuUWXvlF/cfxqDDNmzMjEYqvWqKWqow+a0zBb9H8gS4ut5Ej2ztTlmfbbbz/A379E+VKrCrPcDMMwjNBRrS23eLRHNmHCBMDPFWrXrl0091+pWG4aIapReNqr6tq1a4XjNEP6EUcEw9ua1UG56qqrAB+pp/nljOzQFRQuvvhiwFvYivqPNbNMKXHaaacB21tsmhlj2LBhgM9rqpmK3nnnHcCP3KjGjRo1AmDq1KmA13zevHmhX2GhlDHLzTAMwwgd1TpaMhm6DtSiRYui84d0dd80KHhUVFVoq3OGdA2tI488ssJ+jTbVJeZzRMG1hdzoq5avRuoq/fr1A3w2ncceewzwFvWNN95Y4XjVWS05tVYypOD6ZqJts2bNAK+F+n91NOLDDz9MqRxddyw+56GO3hx//PHZRPQVXFsojvfuzJkzgUBPgNNPPx1IvEJGili0pGEYhmHEUxQ+N7US1C+mc302b96cVbmxuSU172QGlltJoGs4qcWgGTfUBxdvyZUyHTp0oEOHDgBcccUVgPdpakReItq3b1/pdtVffaBZWmzVmvLycgDatGmTVTmvvvoqANdffz3gM2zo/Ncs52EZceh9y9JiyxlmuRmGYRihoygsN7XUtKem2TFeeuklAO655x7AIvUyQfPA/fLLLykdr70v/a0Ra7Vq1QKgbdu2AHz88cc5rWd1QEcWxo0bR48ePSrs08g91U39RqmiGf+//fbbbKtpRFiwYAHg58Oq5ab+5VatWkWzlRjpo3M09f9C/weKBbPcDMMwjNBRFJbb8uXLAZ+7TFfc1qz/Z555JuAtuilTpgB+7DwRsXO61IdUCtSoUSOa703zvN1+++2AX8W5c+fOlX7WOUPxc4y011uKllvHjh0B78OpV69edN/bb78NeH3V56Y5OQ844ICUrtG8efOc1LWUqVu3LuD9xvr/r9sVXRVgxYoVVVe5EKGjOLpahUb+Fls8g1luhmEYRugoqnlu8T2AU089Fdh+faZvvvkG8Ctwaw9C/Uqa/XvOnDlAkC9RrcEMotAKPp8lXW0ffvhhBg8eXOk+XXFbrY/4z4nQ1QKuueYawOf9y5KCawvJ9VX/WmwUmPqDdYVzXTdPI/O0d5sqW7ZsAbxlnCOrouD6JtNWLVZd3Vmfx3To1KkT4J/NPn36VHqcWmw6EvT++++nfa0YCq4tFGaeW69evQB48cUXAT+iFj+fMEuy1reoGrd4dIhHEyLrpOx4NHGnDhtpElqlvLw8uhxDBhT8IU5X28WLF+cs2ayiaYriE/tmScG1heT6auqx7t27R7fps6ZO9URTADRARBNPz507F4BZs2YBfghemT9/PuBfIFmmhyq4vom01e+pHdpNmzYBQfBYsoZd02tph0yXZInvoOn0Ci3vuuuuA7Ju1JSCawtV27iNHDkS8Mto6XtXOxM5Hua1SdyGYRiGEU9RBJQkQnutGhShUwU0RVTr1q0BKCsrA7a32DSRcs+ePfNe17CigTjaaytFJk2aBFS03BKlIXvhhRcAn+Jp+vTpACxZsgQIgn3AL8c0Y8aMCufXrl07R7UubnQ4UhccVdTVkAlbt24FYOLEiYCfYqRpu4z0UHfQiBEjAKIpDBs2bAjAwIEDgeINzDHLzTAMwwgdRe1zS4T6KYYMGQJA3759AT/2Pm3aNMAnqdVw9wwp+Nh6utq2b9+e4cOHAz6wIX5JlURoz3np0qWA1zJPCzwWXFtIrq8u8KoLucaiowbnnnsu4K08DcBJhJalASRnnXUW4Je4yVH6rYLrm0jbSy+9FIBRo0YBsMceewAVF9PVd1P8s6fTLuKDTzRdX7w1nCcKri3k9r2rwVA6WqNLA2lgn94PTWQ9bty4XF26MsznZhiGYRjxVEvLrYopeA/NtM0vpm/+SFXbQYMGAdCgQYPott9//x3w1nCRUXBtIbfPrlrTN910E+DTHWq6snfffRcg4TSjHGOWm2EYhmHEY5ZbcgreQzNt84vpmz9M2/xi+ibGLDfDMAwjdFjjZhiGYYQOa9wMwzCM0GGNm2EYhhE6rHEzDMMwQkcuc0uuA8pzWF6x0KzQFcC0zTemb/4wbfOL6ZuAnE0FMAzDMIxiwYYlDcMwjNBhjZthGIYROqxxMwzDMEKHNW6GYRhG6LDGzTAMwwgd1rgZhmEYocMaN8MwDCN0WONmGIZhhA5r3AzDMIzQ8f+77KcTmy2EkwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "for i in range(5):\n",
    "  plt.subplot(1,5,i+1)\n",
    "  plt.tight_layout()\n",
    "  plt.imshow(example_data[i][0], cmap='gray', interpolation='none')\n",
    "  plt.title(\"Prediction: {}\".format(\n",
    "    output.data.max(1, keepdim=True)[1][i].item()))\n",
    "  plt.xticks([])\n",
    "  plt.yticks([])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's show some examples that the network make wrong predictons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/envs/env_pytorch/lib/python3.6/site-packages/ipykernel_launcher.py:10: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "plt.tight_layout()\n",
    "\n",
    "for data, target in test_loader:\n",
    "      output = network(data)\n",
    "      pred = output.data.max(1, keepdim=True)[1].numpy()\n",
    "      \n",
    "      cnt = len(pred)\n",
    "      for i in range(cnt):\n",
    "            if pred[i].item() != target[i].item():\n",
    "                \n",
    "                plt.imshow(data[i][0], cmap='gray', interpolation='none')\n",
    "                plt.title(\"Prediction: {}, Label: {}\".format(pred[i].item(), target[i].item()))\n",
    "                break\n",
    "      break\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
